#!/usr/bin/env python

import argparse
import sys
import json
import os
import collections

import arrow

import deepy.daemons
import deepy.status
import deepy.event
import deepy.event.riemann_client as riemann_client
import deepy.metrics
import deepy.deploy
import deepy.cfg
import deepy.log as log
import deepy.util
import time

__dimensions_db = None
def _dimensions_db():
    global __dimensions_db
    if __dimensions_db is None:
        __dimensions_db = deepy.dimensions.DimensionsDB(redis_backed=True)
    return __dimensions_db

def publish_metrics(options):
    metrics = []
    if options.all:
        # captures logic about what should run
        # instead of running everything (like both bgps)
        metrics.extend(collect_5min())
        metrics.extend(collect_30min())
        metrics.extend(collect_1h())
    else:
        if options.cpu:
            metrics.append(deepy.metrics.CPUMetric())
        if options.ui:
            metrics.append(deepy.metrics.UIStatusMetric())
        if options.snmp:
            metrics.append(deepy.metrics.SNMPStatusMetric())
        if options.queue:
            metrics.append(deepy.metrics.QueueMetric())
        if options.git:
            metrics.append(deepy.metrics.GitStatusMetric())
        if options.sadf:
            metrics.append(deepy.metrics.SADFMetric())
        if options.h5flow:
            metrics.append(deepy.metrics.H5FlowMetric())
        if options.sysinfo:
            metrics.append(deepy.metrics.SystemInfoMetric())
        if options.heartbeat:
            metrics.append(deepy.metrics.HeartbeatMetric())
        if options.traffic:
            metrics.append(deepy.metrics.TrafficMetric())
        if options.bgp_bird:
            metrics.append(deepy.metrics.BGPMetric('bird'))
        if options.bgp_bgpd:
            metrics.append(deepy.metrics.BGPMetric('bgpd'))
        if options.dayt:
            metrics.append(deepy.metrics.DayTrafficMetric(_dimensions_db()))
        if options.hourt:
            metrics.append(deepy.metrics.HourTrafficMetric(_dimensions_db()))
        if options.router:
            metrics.append(deepy.metrics.RouterLookupMetric())
        if options.bundlesmissing:
            metrics.append(deepy.metrics.MissingBundlesMetric())
        if options.bundlesstatus:
            metrics.append(deepy.metrics.BundleStatusMetric())
        if options.flowsstats:
            metrics.append(deepy.metrics.FlowsStatsMetric())
        if options.syslog:
            metrics.append(deepy.metrics.SyslogMetric())
        if options.dir:
            metrics.append(deepy.metrics.DirMetric())
        if options.ip:
            metrics.append(deepy.metrics.IPMetric())
        if options.missingmappers:
            metrics.append(deepy.metrics.FindMissingMapperFilesMetric())
        if options.missingmines:
            metrics.append(deepy.metrics.FindMissingMineFilesMetric())
        if options.drillsmallago:
            metrics.append(deepy.metrics.DrillSmallAgoMetric())
        if options.bgpago:
            metrics.append(deepy.metrics.H5BGPAgoMetric())
        if options.drillsmallgaps:
            metrics.append(deepy.metrics.DrillSmallGapsMetric())
        if options.dns:
            metrics.append(deepy.metrics.DNSStatusMetric())
        if options.corefiles:
            metrics.append(deepy.metrics.CoreFilesMetric())
        if options.backboneerror:
            metrics.append(deepy.metrics.BackboneErrorMetric(_dimensions_db()))
        if options.backbonechange:
            metrics.append(deepy.metrics.BackboneChangeMetric(_dimensions_db()))
        if options.processes:
            metrics.append(deepy.metrics.ProcessesByMemoryMetric())
        if options.flowdstats:
            metrics.append(deepy.metrics.FlowdStatsMetric())
        if options.missingcubes:
            metrics.append(deepy.metrics.MissingCubesMetric())
        if options.uipage:
            metrics.append(deepy.metrics.UIPageMetric())
        if options.uilog:
            metrics.append(deepy.metrics.UILogMetric())
        if options.carp_master:
            carp_ip = deepy.util.vm_or_slice_config_get("carp_ip")
            metrics.append(deepy.metrics.CarpMasterMetric(carp_ip))
        if options.h5flowgaps:
            metrics.append(deepy.metrics.H5FlowGapsMetric())

    client = deepy.event.get_client(options.host, tcp=options.use_tcp)
    for metric in metrics:
        deepy.log.debug("Collecting {}".format(metric))
        if options.collect_periodic:
            data = metric.snapshot()
            continue
        else:
            data = metric.collect()
        if options.dry_run:
            print data
        else:
            if data is not None:
                metric.publish(data, client=client)
            else:
                log.warn("Failed to collect metric {}".format(metric))

def scheduling_jobs():
    '''
    Only one vm in a deployment can schedule jobs. Use that for deployment
    metrics.

    If cubes_5min is in jobs, we're scheduling jobs, and can therefore
    make decisions about targets that should/shouldn't exist.

    Status doesn't schedule jobs.
    '''
    return 'cubes_5min' in deepy.daemons.get_cron_jobs()

def classifying_flow():
    clas = lambda x: 'classify' in x
    return any(map(clas, deepy.cfg.vm_config.get('daemons', []) + list(deepy.daemons.get_cron_jobs())))

def collect_5min():
    heartbeat_config = deepy.status.get_heartbeat_config()

    metrics = []
    if deepy.util.vm_or_slice_config_get("ignore_alerts") and not deepy.util.vm_or_slice_config_get("get_metrics"): #don't collect metrics from deployments we're ignoring
        return metrics

    metrics.append(deepy.metrics.CPUMetric())
    metrics.append(deepy.metrics.HeartbeatMetric())

    if classifying_flow():
        metrics.append(deepy.metrics.H5FlowGapsMetric())
        if not heartbeat_config.get('ignore_drill_small_ago'):
            metrics.append(deepy.metrics.H5FlowAgoMetric())

    if scheduling_jobs():
        if not heartbeat_config.get('ignore_drill_small_ago'):
            metrics.append(deepy.metrics.DrillSmallAgoMetric())
            metrics.append(deepy.metrics.Drill1AgoMetric())
            metrics.append(deepy.metrics.H5BGPAgoMetric())

            if deepy.cfg.has_backbone:
                metrics.append(deepy.metrics.BackboneSmallAgoMetric())

        metrics.append(deepy.metrics.DrillSmallGapsMetric())
        metrics.append(deepy.metrics.Drill1GapsMetric())
        metrics.append(deepy.metrics.MissingCubesMetric())
        metrics.append(deepy.metrics.TrafficMetric())

        if deepy.cfg.has_backbone:
            metrics.append(deepy.metrics.BackboneSmallGapsMetric())

    if deepy.metrics.is_vm_running_daemon("flowd") and not heartbeat_config.get("ignore_flowd"):
        metrics.append(deepy.metrics.H5FlowMetric())
        metrics.append(deepy.metrics.FlowsStatsMetric())
        metrics.append(deepy.metrics.DNSStatusMetric())

    metrics.append(deepy.metrics.QueueMetric())
    metrics.append(deepy.metrics.SystemInfoMetric())
    metrics.append(deepy.metrics.SyslogMetric())

    # Collected metrics that do not go to status

    daemon = None
    if deepy.metrics.is_vm_running_daemon('bgpd'):
        daemon = 'bgpd'
    elif deepy.metrics.is_vm_running_daemon('bird'):
        daemon = 'bird'
    if daemon and not heartbeat_config.get('ignore_bgp'):
        metrics.append(deepy.metrics.BGPMetric(daemon))
        metrics.append(deepy.metrics.H5BGPMetric())

    metrics.append(deepy.metrics.DirMetric())

    return metrics

def collect_30min():
    metrics = []

    if scheduling_jobs():
        metrics.append(deepy.metrics.HourTrafficMetric(_dimensions_db()))
        metrics.append(deepy.metrics.MissingBundlesMetric())
        metrics.append(deepy.metrics.BundleStatusMetric())

    return metrics

def collect_1h():
    heartbeat_config = deepy.status.get_heartbeat_config()
    metrics = []

    if scheduling_jobs():
        metrics.append(deepy.metrics.DayTrafficMetric(_dimensions_db()))

    if not heartbeat_config.get('ignore_router_lookup'):
        metrics.append(deepy.metrics.RouterLookupMetric())

    metrics.append(deepy.metrics.IPMetric())

    return metrics

def snapshot_index(options, filename=None):
    try:
        client = deepy.event.get_client(options.host, transport=riemann_client.TCPTransport)
        now = arrow.get()
        timestamp = deepy.timerange.floor_timestamp_to(now.datetime, '5T')

        if filename is None:
            filename = 'snapshot-%Y-%m-%d-%H-%M.json.gz'
            snapshot = deepy.event.snapshot_index(client, tags=options.tag)
            if options.dry_run:
                print json.dumps(snapshot, indent=2, cls=deepy.util.PipedreamJSONEncoder)
            else:
                local_path = timestamp.strftime(os.path.join(deepy.cfg.cache_dir, 'metrics', 'snapshot-%Y-%m-%d-%H-%M.json.gz'))
                deepy.log.info("Writing snapshot to {}".format(local_path))
                deepy.store.simple_save_json(snapshot, local_path, force_remote='local')

        else:
            snapshot = deepy.event.snapshot_periodic(client, options.time, tags=options.tag)
            heartbeat = {}

            grouped_list = collections.defaultdict(list)
            for k, j in snapshot.iteritems():
                grouped_list[j['meta']['uuid']].append(j)

            for key in grouped_list:
                for event in grouped_list[key]:
                    heartbeat[event['service']] = event['data']

                local_path = timestamp.strftime(os.path.join(deepy.cfg.cache_dir, 'riemann-heartbeat', filename + '-' + grouped_list[key][0]['meta']['deployment_id'] + '.json.gz'))
                heartbeat['time'] = time.time()

                deepy.log.info("Writing snapshot to {}".format(local_path))
                deepy.store.simple_save_json(heartbeat, local_path, force_remote='local')

    finally:
        client.disconnect()



def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('-l', '--log-level', action='store', choices=deepy.log.LEVELS, help='Set log level')
    parser.add_argument('-n', '--dry-run', action='store_true', default=False, help="Dry run")
    parser.add_argument('-a', '--all', action='store_true', default=False, help="Collect all metrics")
    parser.add_argument('-d', '--deployment', action='store', default=None, help="Override deployment id")
    parser.add_argument('--cpu', action='store_true', default=False, help="Collect CPU stats")
    parser.add_argument('--ui', action='store_true', default=False, help="Collect UI stats")
    parser.add_argument('--git', action='store_true', default=False, help="Collect git stats")
    parser.add_argument('--queue', action='store_true', default=False, help="Collect queue stats")
    parser.add_argument('--sadf', action='store_true', default=False, help="Collect sadf output")
    parser.add_argument('--h5flow', action='store_true', default=False, help="Collect h5flow status")
    parser.add_argument('--sysinfo', action='store_true', default=False, help="Collect system metrics (cpu, etc.)")
    parser.add_argument('--heartbeat', action='store_true', default=False, help="Collect simple heartbeat metric")
    parser.add_argument('--traffic', action='store_true', default=False, help='Collect traffic info')
    parser.add_argument('--bgp-bird', action ='store_true', default=False, help='Collect bgp status (bird)')
    parser.add_argument('--bgp-bgpd', action ='store_true', default=False, help='Collect bgp status (bgpd)')
    parser.add_argument('--snmp', action='store_true', default=False, help="Collect SNMP stats")
    parser.add_argument('--dayt', action='store_true', default=False, help='Collect day traffic stats')
    parser.add_argument('--hourt', action='store_true', default=False, help='Collect hour traffic stats')
    parser.add_argument('--router', action='store_true', default=False, help='Collect router lookup stats')
    parser.add_argument('--bundlesmissing', action='store_true', default=False, help='Collect missing bundles')
    parser.add_argument('--bundlesstatus', action='store_true', default=False, help='Collect bundles status')
    parser.add_argument('--flowsstats', action='store_true', default=False, help='Collect flows stats')
    parser.add_argument('--syslog', action='store_true', default=False, help='Collect syslog')
    parser.add_argument('--dir', action='store_true', default=False, help='Check dir size')
    parser.add_argument('--ip', action='store_true', default=False, help='Check ip status')
    parser.add_argument('--missingmappers', action='store_true', default=False, help='Find missing mapper files')
    parser.add_argument('--missingmines', action='store_true', default=False, help='Find missing mine files')
    parser.add_argument('--drillsmallago', action='store_true', default=False, help='Find how many seconds drill small is behind')
    parser.add_argument('--bgpago', action='store_true', default=False, help='Find how many seconds bgp is behind')
    parser.add_argument('--drillsmallgaps', action='store_true', default=False, help='Find how many gaps are in drill_small for the last day')
    parser.add_argument('--dns', action='store_true', default=False, help='Collect dns status')
    parser.add_argument('--corefiles', action='store_true', default=False, help='Collect core dumps')
    parser.add_argument('--backboneerror', action='store_true', default=False, help='Collect backbone traffic')
    parser.add_argument('--backbonechange', action='store_true', default=False, help='Collect backbone hour change')
    parser.add_argument('--processes', action='store_true', default=False, help='Collect processes by memory')
    parser.add_argument('--flowdstats', action='store_true', default=False, help='Collect flowd stats')
    parser.add_argument('--missingcubes', action='store_true', default=False, help='Collect missing cubes')
    parser.add_argument('--uipage', action='store_true', default=False, help='Check ui page')
    parser.add_argument('--uilog', action='store_true', default=False, help='Collect ui log')
    parser.add_argument('--host', action='store', default=None, help="Override target host for publication")
    parser.add_argument('--snapshot-index', action='store_true', default=False, help="Collect a snapshot of the index")
    parser.add_argument('--collect-periodic', action='store_true', default=False, help='Collect metric snapshots')
    parser.add_argument('--snapshot-periodic', action='store_true', default=False, help="Collect a snapshot of the index")
    parser.add_argument('--carp-master', action='store_true', default=False, help="Detect whether CARP master or not")
    parser.add_argument('--tag', action='append', default=[], help="Append a tag to snapshot query")
    parser.add_argument('--time', action='store', default=None, help="Query for the past '5min', '30min', or '1h'")
    parser.add_argument('--use-tcp', action='store_true', default=False, help="Use TCP to connect to riemann")
    parser.add_argument('--h5flowgaps', action='store_true', default=False, help='Find how many gaps are in h5flow')
    return parser.parse_args()

def main():
    options = parse_args()

    if options.log_level:
        deepy.log.init(level=options.log_level)

    if options.host is None:
        options.host = '127.0.0.1'

    if options.deployment:
        deepy.log.info("Initializing as deployment {}".format(options.deployment))
        deepy.cfg.init(options.deployment)

    if options.snapshot_index:
        snapshot_index(options)
        sys.exit(0)

    if options.collect_periodic and options.time:
        client = deepy.event.get_client(options.host)

        if options.time == '1h':
            deepy.util.lock("collect_metrics-1h.lock")
            metrics = collect_1h()
        elif options.time == '30min':
            deepy.util.lock("collect_metrics-30m.lock")
            metrics = collect_30min()
        else:
            deepy.util.lock("collect_metrics-5m.lock")
            metrics = collect_5min()

        for metric in metrics:
            deepy.log.debug("Collecting {}".format(metric))
            try:
                data = metric.collect()
                metric.publish(data, client=client)
            except Exception as e:
                deepy.log.warn("Metric-{}-failed".format(metric))
                raise e
                deepy.log.warn(e)


        sys.exit(0)

    if options.snapshot_periodic:
        snapshot_index(options, filename='riemann-heartbeat-%Y-%m-%d-%H-%M')
        sys.exit(0)

    publish_metrics(options)


if __name__ == "__main__":
    main()
