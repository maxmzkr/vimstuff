#! /usr/bin/env python

#
# Top-level of cube module.
#

import time
import funcy
import errno
import types
import sys
import os
import json
import re
import redis
import os.path
import stat
import copy
import fnmatch
import tempfile
import collections
import zipfile
import shutil
import uuid
import numexpr
import datetime
import calendar

from functools import partial
from collections import namedtuple, OrderedDict

import pandas as pd
import numpy as np
import tables
import tables.nodes.filenode

try:
    import ujson
except ImportError:
    import json as ujson

import deepy.cfg
import deepy.util
import deepy.store
import deepy.map
import deepy.geoip
import deepy.dimensions
import deepy.build.util
import deepy.query_rules
import deepy.cube_cy
import deepy.cube_apply
import deepy.timerange
import deepy.deepy_redis
import deepy.slice_def
import deepy.log as log
from deepy.stats import DeepStats
import deepy.context
from deepy.util import TrackTime, TrackTimes

prof_log = log.debug

def set_prof_logger(logger):
    # Consider expanding something like this into deepy.log to cover the
    # rest of the cube path.
    global prof_log
    prev = prof_log
    prof_log = logger
    return prev

#Cache the actual strings returned by dimension requests. The reasoning for this is as follows:
#    Dimensions are requested from all over the ui
#    Even with the dimensions db being lazy loaded we still load the dimension from redis,
#    unpack it into memory, and dump it into a string. We get around this by just caching
#    the value itself
def serve_dimensions(args, kwargs, params):
   indent = 2
   if 'uglify' in params:
       indent = None

   if 'dimension' in kwargs:
       dim = kwargs['dimension']
       dim_method = 'dim_by_name'

       # Test if dim is id
       try:
           int(dim)
           dim_method = 'dim_by_id'
       except ValueError:
           pass

       dim_db = deepy.dimensions.DimensionsDB(None, redis_backed=True)
       if 'position' in kwargs:
           pos = kwargs['position']
           pos_method = 'pos_by_name'

           # Test if pos is id
           try:
               int(pos)
               pos_method = 'pos_by_id'
           except ValueError:
               pass

           log.debug("Fetch {}={} and {}={}".format(dim_method, dim, pos_method, pos))

           if dim_method == 'dim_by_name':
               if pos_method == 'pos_by_name':
                   result = dim_db.get_pos_by_name(dim, pos)
               elif pos_method == 'pos_by_id':
                   result = dim_db.get_pos_by_name_and_id(dim, pos)
           elif dim_method == 'dim_by_id':
               if pos_method == 'pos_by_name':
                   result = dim_db.get_pos_by_id_and_name(dim, pos)
               elif pos_method == 'pos_by_id':
                   result = dim_db.get_pos_by_id(dim, pos)
           if result:
               result = json.dumps(result, indent=indent)
       else:
           log.debug("Fetch {}={}".format(dim_method, dim))
           if dim_method == 'dim_by_name':
               dim_id = dim_db.get_id_by_name(dim)
           else:
               dim_id = dim
           key = "serve_dimensions.%s" % (dim_id)
           conn = redis.Redis('localhost')
           if indent is None:
               #Cache the results if we can, but only for the uglified (i.e. requested by the ui)
               #Could cache the pretty-printed version as well but I don't know that the gains are
               #worth the memory footprint
               #Also, not worth it to cache the individual positions since those load quickly

               ret = deepy.deepy_redis.check_redis(key, conn)
               if ret:
                   return ret


           if dim_method == 'dim_by_name':
               result = dim_db.get_by_name(dim)
           elif dim_method == 'dim_by_id':
               result = dim_db.get_by_id(dim)

           if result:
               result = json.dumps(result, indent=indent)
           if indent is None:
               deepy.deepy_redis.r_set(conn, key, result, deepy.deepy_redis.DIM_TIMEOUT)


   else:
       key = "serve_dimensions"
       conn = redis.Redis('localhost')
       if indent is None:
           ret = deepy.deepy_redis.check_redis(key, conn)
           #Sanity check because this key can occasionally be set to an integer?
           if ret and type(ret) == str and len(ret) > 20:
               return ret
       #Since we are loading the entire dim_db just load it from disk
       dim_db = deepy.dimensions.DimensionsDB(None)
       result = dim_db.get_all()
       if result:
           result = json.dumps(result, indent=indent)
           #XXX Occasionally the result can come back as an integer? Sanity check
           if indent is None and type(result) == str and len(result) > 20:
               deepy.deepy_redis.r_set(conn, key, result, deepy.deepy_redis.DIM_TIMEOUT)

   return result


# Defines the time attribute of cubes.
# Dict with step, valid_seconds
class TimeMeta(dict):
    def __init__(self):
        super(TimeMeta, self).__init__()
        self['step'] = None
        # Each timestamp in a cube may have a different number of valid_seconds
        # behind it, e.g. a day with only 22 hours of data.
        # So, valid_seconds is keyed by the timestamps in the cube.
        # If timestamp has been rolled out (no timestamp dimension), 0 is used
        # as the key.
        self['valid_seconds'] = {}

    @classmethod
    def from_dict(cls, time_dict):
        time_obj = cls()
        time_obj.update(copy.deepcopy(time_dict))
        # Writing out as json changes the timestamp keys to strs. Change them
        # back to ints.
        vs = time_obj['valid_seconds']
        for ts, ts_vs in vs.items():
            del vs[ts]
            vs[int(ts)] = ts_vs
        return time_obj


####
# Cubes

# Standard measures that can be summed.
measures_sum_old = [
        'recv_bytes',
        'sent_bytes',
        'local_host_count', # XXX Actually, this can't be summed.
        'conv_count'
        ]

# Standard measures, e.g. from subflow.
measures_bytes = [
        'recv_bytes',
        'sent_bytes'
        ]

# Used as index values in position arrays.
position_internal_index_type = deepy.cube_cy.position_dtype
# Storing measures in arrays of floats.
measure_type = deepy.cube_cy.measure_dtype

def cube_axes(src_cube_id, time_step=3600, time_slices=None, axis_type='dimensions', dimensions_db=None):

    tt = TrackTimes()
    prof_log(tt.start('cube_axes', 'cube-axes-start {}'.format(axis_type)))

    if time_slices == None:
        time_slices = []

    # Find a matching src cube. Must match name and time_step.
    # Could maybe make this more automatic.
    target_expander = _find_cube_rule_match(src_cube_id, time_step)
    if target_expander is None:
        raise QueryError('matching cube not found: cube_id=%s time_step=%d' %
                (src_cube_id, time_step))

    timestamps = _timeslices_to_timestamps(time_slices, time_step)

    timestamps = list(timestamps)
    timestamps.sort()

    cube_files = []
    for ts in timestamps:
        expanded_targets = target_expander.expand(
            {
                "start_time": ts,
                "end_time": ts
            }
        )
        for expanded_target in expanded_targets:
            cube_files.append(expanded_target.unique_id)
    cube_files = list(set(cube_files))

    if dimensions_db is None:
        # If a previously loaded dimensions_db isn't passed in, load it.
        prof_log(tt.start('load-db', 'cube-axes-loading-dimensions-db-start'))
        dimensions_db = deepy.dimensions.DimensionsDB(redis_backed=True)
        prof_log(tt.end('load-db', 'cube-axes-loading-dimensions-db-end'))

    result = []
    for cube_file in cube_files:
        prof_log(tt.start(cube_file, 'cube-axes-load-cube-file-start {}'.format(cube_file)))
        try:
            cube_in = CubeLoader(cube_file, meta_only=True)
        except IOError:
            prof_log(tt.end(cube_file, 'cube-axes-load-cube-file-missing {}'.format(cube_file)))
            continue
        prof_log(tt.end(cube_file, 'cube-axes-load-cube-file-end {}'.format(cube_file)))

        if axis_type == 'dimensions':
            result = funcy.distinct(result + cube_in.dimensions)
        elif axis_type == 'measures':
            result = funcy.distinct(result + cube_in.measures)

    if axis_type == 'dimensions':
        # Convert dimension ids to names if it's in the DDB
        temp = []
        #Make sure we've loaded the dimensions by calling a function that
        #requires lazy loading of all the dimensions meta data
        dimensions_db.get_id_to_names()
        for x in result:
            x = str(x)
            dim, suffix = dimensions_db.dim_name_split(x)
            if dim in dimensions_db:
                temp.append(dimensions_db[dim]['cname'] + suffix)
            else:
                temp.append(x)
        result = temp
    elif axis_type == 'measures':
        # XXX Measure fixup actually creates these.. Not the most useful thing here, but eh..
        if 'recv_bytes' in result and 'sent_bytes' in result:
            result = ['sum.recv.bytes', 'sum.sent.bytes', 'sum.total.bytes', 'avg.recv.bps', 'avg.sent.bps', 'avg.total.bps']
        result = list(result)

    prof_log(tt.end('cube_axes', 'cube-axes-end {}'.format(axis_type)))
    return result

def cube_positions(src_cube_id, time_step=3600, time_slices=None, dim_name=None, dimensions_db=None):
    if time_slices == None:
        time_slices = []

    # Find a matching src cube. Must match name and time_step.
    # Could maybe make this more automatic.
    target_expander = _find_cube_rule_match(src_cube_id, time_step)
    if target_expander is None:
        raise QueryError('matching cube not found: cube_id=%s time_step=%d' %
                (src_cube_id, time_step))

    timestamps = _timeslices_to_timestamps(time_slices, time_step)

    timestamps = list(timestamps)
    timestamps.sort()

    cube_files = []
    for ts in timestamps:
        expanded_targets = target_expander.expand(
            {
                "start_time": ts,
                "end_time": ts
            }
        )
        for expanded_target in expanded_targets:
            cube_files.append(expanded_target.unique_id)
    cube_files = list(set(cube_files))

    if dimensions_db is None:
        # If a previously loaded dimensions_db isn't passed in, load it.
        dimensions_db = deepy.dimensions.DimensionsDB(redis_backed=True)

    conv_id = dimensions_db.get_id_by_name(dim_name)
    if conv_id == None:
        conv_id = dim_name

    result = []
    for cube_file in cube_files:
        try:
            cube_in = CubeLoader(cube_file, meta_only=True, dimensions_db=dimensions_db)
        except IOError:
            continue

        if conv_id in cube_in.dimensions:
            for i in (i for i, x in enumerate(cube_in.dimensions) if x == conv_id):
                result = funcy.distinct(result + cube_in.axes[i])

    # Convert position ids to names if it's in the DDB
    if (conv_id != dim_name):
        ddp = dimensions_db.get_by_id(conv_id)['positions']
        result = [ddp[str(x)]['name'] if str(x) in ddp else x for x in result]

    return list(result)

# Base class for cubes
class CubeBase(object):
    cube_version = 2

    def __init__(self):
        super(CubeBase, self).__init__()
        self.dimensions = None
        self.measures = None
        # Set for cubes with time. Goes into meta_data.
        self.time = TimeMeta()

    def __eq__(self, other):
        # == operator just compares data. To check types, dimension/measure
        # order use equals().
        return self.equals(other, check_order=False, check_type=False)
    def __ne__(self, other):
        return not (self == other)

    # TODO This won't work if positions are in a different order. Would need
    # to sort or use hash to support that.
    # Can compare different types of cubes as long as they implement the
    # necessary interfaces, mainly to_arrays().
    def equals(self, other, check_order=False, check_type=False):
        if check_type:
            if type(self) != type(other):
                return False

        # Compare len.
        if len(self) != len(other):
            return False

        # Check same number of arrays.
        if len(self.dimensions) != len(other.dimensions):
            return False
        if len(self.measures) != len(other.measures):
            return False

        # Check that dim_ids and meas_ids match.
        if check_order:
            dim_match = [k1 == k2 for k1, k2 in
                    zip(self.dimensions, other.dimensions)]
            meas_match = [k1 == k2 for k1, k2 in
                    zip(self.measures, other.measures)]
            if not all(dim_match + meas_match):
                return False
        else:
            if set(self.dimensions) != set(other.dimensions):
                return False
            if set(self.measures) != set(other.measures):
                return False

        # Compare arrays.
        pos_map1, meas_map1 = self.to_arrays()
        pos_map2, meas_map2 = other.to_arrays()
        pos_match = [np.all(pos_map1[k1] == pos_map2[k1])
                for k1 in pos_map1.keys()]
        meas_match = [np.all(meas_map1[k1] == meas_map2[k1])
                for k1 in meas_map1.keys()]
        if not all(pos_match + meas_match):
            return False
        return True


# XXX Getting confusing to always look up arrays based on indices. Add
# position/axis array lookup based on dict.
#
# meta_only - don't load data
# keep_npz - save npz handle. don't use. creates fd leak.
# required_dimension_ids - dimensions that will be used. if None, all will be
#   loaded
# required_measures - measures that will be used. if None, all will be loaded.
# include_measures - measures that are both in the cube and this list will be
#   loaded, unless there are no measures in common. In that case, all measures
#   will be used, instead. This is used during bundle queries to limit the
#   number of measures returned.
NONE_FLAG = 2**64 - 1
class CubeLoader(CubeBase):
    # Not currently used. Here to mimic CubeHash interface.
    dim_db = None
    dim_db_local = None

    def __init__(self, cube_file, dimensions_db=None, meta_only=False,
            keep_npz=False, required_dimension_ids=None,
            optional_dimension_ids=None, required_measures=None,
            lightweight_meta=False, include_measures=None):

        super(CubeLoader, self).__init__()
        self.cube_file = cube_file
        # Will load with position arrays.
        self.positions = None
        self.dimensions_db = dimensions_db
        self.lightweight_meta = lightweight_meta
        self.meta_only = meta_only
        self.required_dimension_ids = required_dimension_ids
        self.optional_dimension_ids = optional_dimension_ids

        self.required_measures = required_measures
        self.include_measures = include_measures
        self.keep_npz = keep_npz

        # dimensions will be the combination of loaded required and optional
        # dimensions (possibly a subset of file_dimensions), and the faked
        # optional dimensions.
        self.dimensions = None
        # file_dimensions are the true dimesions that exist in the file. Not
        # all may be loaded.
        self.file_dimensions = None
        # load_dimensions are the ones actually loaded from file.
        self.load_dimensions = None
        # fake_dimensions are the requested optional dimensions that don't
        # exist in the file. They will be faked with columns of None.
        self.fake_dimensions = None
        # missing_dimensions are required dimensions that aren't in the file.
        self.missing_dimensions = None
        self.measures = None
        self.meta_extra = {}

        log.debug('cube-load: %s' % (self.cube_file))

        deepy.store.cache_load_from_remote(self.cube_file)

        if self.cube_file.endswith('.h5'):
            self._load_h5()

        self._add_fake_dimensions()
        self._remap_converted_positions()


    def __len__(self):
        if self.positions is None or len(self.positions) == 0:
            return 0
        return self.positions[0].shape[0]
    def num_positions(self):
        return len(self)

    # Used for testing. Convert directly to CubeHash.
    def to_cube_hash(self):
        # Convert from parallel lists to dicts, as expected from
        # from_indexed_arrays().
        positions = OrderedDict(zip(self.dimensions, self.positions))
        axes = OrderedDict(zip(self.dimensions, self.axes))
        measures = OrderedDict(zip(self.measures, self.measure_arrays))
        return CubeHash.from_indexed_arrays(positions, axes, measures, self,
            self.time['valid_seconds'], self.time['step'])

    def to_data_frame(self):
        return self.to_cube_hash().to_data_frame()

    # Provide same method that CubeHash has.
    def get_meta(self):
        return self.meta

    #
    # Version specific file handling
    #
    def _load_h5(self):
        log.debug('cube-load-v2-h5')

        try:
            h5 = tables.open_file(self.cube_file)
        except tables.exceptions.HDF5ExtError:
            raise QueryWarning({'error': 'Cube file is corrupted and cannot be read', 'file': self.cube_file})

        if not hasattr(h5.root, 'meta') or not hasattr(h5.root, 'axes'):
            raise QueryWarning({'error': 'Cube does not have meta/axes node', 'file': self.cube_file})

        version = 1
        if hasattr(h5.root.meta.attrs, 'version'):
            version = h5.root.meta.attrs.version

        if version == 1:
            self.meta = ujson.loads(h5.root.meta.attrs.meta)
        elif version == 2:
            axes_node = tables.nodes.filenode.open_node(h5.root.axes)

            try:
                all_axes = ujson.loads(axes_node.read())
            except ValueError:
                raise QueryWarning({'error': 'Cube file cannot be decoded as JSON', 'file': self.cube_file})
            axes_node.close()

            meta_node = tables.nodes.filenode.open_node(h5.root.meta)
            self.meta = ujson.loads(meta_node.read())
            meta_node.close()

        self.time = TimeMeta.from_dict(self.meta['time'])
        self._set_dimensions_and_measures()

        if version == 1:
            axes_lookup = {}
            for i in range(len(self.file_dimensions)):
                name = 'axes_%05d' % (i,)
                arr = getattr(h5.root, name).read()
                axes_lookup[name] = arr
            all_axes = sorted([(name,arr) for name,arr in axes_lookup.items() if name.startswith('axes')])
            all_axes = [list(map(replace_none, x[1])) for x in all_axes]

        if self.file_dimensions is not None:
            file_dims = dict([(val, idx)
                for idx, val in enumerate(self.file_dimensions)])

            self.axes = []
            for val in self.load_dimensions:
                idx = file_dims[val]
                _axes = all_axes[idx]
                self.axes.append(_axes)

            if self.meta_only:
                h5.close()
                return

            # Load data.
            self.positions = []
            for val in self.load_dimensions:
                idx = file_dims[val]
                name = 'dimension_%d' % idx
                pos = getattr(h5.root, name, None)
                if pos:
                    arr = pos.read()
                    # asarray will only cast if necessary.
                    arr = np.asarray(arr, dtype=position_internal_index_type)
                else:
                    arr = np.array([], dtype=position_internal_index_type)
                self.positions.append(arr)

        self.measure_arrays = []
        file_meas = {val: idx for idx, val in enumerate(self.meta.get('measures', []))}
        for val in self.measures:
            idx = file_meas[val]
            name = 'measure_%d' % idx
            m = getattr(h5.root, name, None)
            if m:
                arr = m.read()
                arr = arr.astype(measure_type)
            else:
                arr = np.array([], dtype=measure_type)
            self.measure_arrays.append(arr)

        h5.close()

    def _load_npz(self):
        # NOTE: npz uses lazy-loading of archive members. So cube data won't
        # actually be loaded until you try to access it.
        # See pydoc numpy.lib.npyio.NpzFile
        # However, it looks like every time you access a member, it is
        # reloaded from the zip archive, so need to only grab once.

        # Bug in numpy http://projects.scipy.org/numpy/attachment/ticket/1517/numpy_bug.py
        # fds not closed after np.load(). Suggested workaround in the bug is
        # to open and close manually.
        try:
            cube_fd = open(self.cube_file, 'r')
        except IOError as e:
            #log.warn('cube-open-failed %s, %s' % (self.cube_file, e))
            raise IOError('Unable to open cube npz')

        try:
            cube_npz = np.load(cube_fd)
        except (IOError, zipfile.BadZipfile) as e:
            cube_fd.close()
            log.warn('cube-load-failed %s, %s' % (self.cube_file, e))
            raise IOError('Unable to load cube npz')

        # Unpack some stuff.
        np_meta = cube_npz['meta']
        # Non-numpy types stored as json.
        self.meta = ujson.loads(np_meta.item())

        if self.lightweight_meta:
            return

        version = self.meta.get('version')
        if version == 1:
            self._load_npz_v1(cube_npz, self.meta_only)
        elif version == 2:
            self._load_npz_v2(cube_npz, self.meta_only)
        else:
            log.warn('unknown-cube-version %s' % (str(version)))
            raise Exception('Unknown cube version: %s' % (str(version)))

        if self.keep_npz:
            # For debugging only! This results in an fd leak (see bug above).
            # Used by cube_op --inspect
            self.cube_npz = cube_npz
        else:
            cube_fd.close()

        log.debug('cube-load-done')

    def _load_npz_v1(self, cube_npz, meta_only):
        log.debug('cube-load-v1')
        np_axes = cube_npz['axes']
        self.axes = ujson.loads(np_axes.item())

        self.time = TimeMeta.from_dict(self.meta['time'])

        if self.meta['measures'] is None:
            # Normalize empty cubes to include measures.
            self.meta['measures'] = measures_sum_old
        self._set_dimensions_and_measures()

        file_dims = dict([(val, idx)
            for idx, val in enumerate(self.file_dimensions)])

        # Set axes based on required dimensions.
        np_axes = cube_npz['axes']
        all_axes = ujson.loads(np_axes.item())
        self.axes = []
        for val in self.load_dimensions:
            idx = file_dims[val]
            self.axes.append(all_axes[idx])

        if meta_only:
            return

        # Load data. Loads only what was required.
        # Convert to v2 format. 1D arrays, where each array is contiguous
        # in memory.
        positions_arr = cube_npz['positions']
        self.positions = []
        for dim_id in self.load_dimensions:
            # Loads the requested dimension from the structured array.
            arr = np.array(positions_arr[dim_id],
                    dtype=position_internal_index_type)
            self.positions.append(arr)

        self.measure_arrays = []
        measures_arr = cube_npz['measures']
        if len(measures_arr) == 0:
            # Normalize empty cubes to include measures.
            for x in self.measures:
                self.measure_arrays.append(np.array([], dtype=measure_type))
        else:
            # Break into 1D arrays.
            file_meas = dict([(val, idx)
                for idx, val in enumerate(self.meta['measures'])])
            for val in self.measures:
                idx = file_meas[val]
                arr = np.array(measures_arr[:,idx])
                self.measure_arrays.append(arr)

    def _load_npz_v2(self, cube_npz, meta_only):
        log.debug('cube-load-v2')

        self.time = TimeMeta.from_dict(self.meta['time'])
        self._set_dimensions_and_measures()

        file_dims = dict([(val, idx)
            for idx, val in enumerate(self.file_dimensions)])

        # Set axes based on required dimensions.
        np_axes = cube_npz['axes']
        all_axes = ujson.loads(np_axes.item())
        self.axes = []
        for val in self.load_dimensions:
            idx = file_dims[val]
            self.axes.append(all_axes[idx])

        if meta_only:
            return

        # Load data.
        self.positions = []
        for val in self.load_dimensions:
            idx = file_dims[val]
            arr = cube_npz['dimension_%d' % idx]
            # Convert type if necessary.
            arr = np.asarray(arr, dtype=position_internal_index_type)
            self.positions.append(arr)

        self.measure_arrays = []
        file_meas = dict([(val, idx)
            for idx, val in enumerate(self.meta['measures'])])
        for val in self.measures:
            idx = file_meas[val]
            arr = cube_npz['measure_%d' % idx]
            self.measure_arrays.append(arr)

    #
    # End Version specific file handling
    #

    # Sets measures and dimensions properties. Checks that required measures
    # and dimensions are available.
    # Also sets load_dimensions, fake_dimensions. These are used by the
    # loader to determine what to do.
    # NOTE: In the loader, required dimensions are the union of required and
    # slice dimensions from multiple queries. Similarly, optional is the
    # union of optional from multiple queries. Dimensions used for specific
    # queries are sorted out in setup_cube_result().
    # NOTE: Call after meta has been loaded.
    def _set_dimensions_and_measures(self):

        # dimensions
        self.file_dimensions = self.meta['dimensions']

        def _separate_optional():
            file_set = set(self.file_dimensions)
            load_opt = [x for x in self.optional_dimension_ids
                    if x in file_set]
            fake_opt = [x for x in self.optional_dimension_ids
                    if x not in file_set]
            return load_opt, fake_opt

        # Note: want to preserve order of dimensions, so doing some extra
        # list comprehensions below.
        if (self.required_dimension_ids is None and
                self.optional_dimension_ids is None):
            # Load all dimensions.
            self.dimensions = self.file_dimensions
            self.load_dimensions = self.file_dimensions
        elif (self.required_dimension_ids is None and self.optional_dimension_ids is not None):
            # Load all, and fake up missing optional.
            # XXX Unfortunately, using required_dimension_ids of None to
            # specify all. Now we have the case that only optional may be
            # specified. Would like to only load those in that case, but can't
            # tell if a slice may have also been specified.
            load_opt, fake_opt = _separate_optional()
            self.load_dimensions = self.file_dimensions
            self.dimensions = self.file_dimensions + fake_opt
            if len(fake_opt) != 0:
                self.fake_dimensions = fake_opt
        elif (self.required_dimension_ids is not None and
                self.optional_dimension_ids is None):
            # Required specified.
            missing_set = (set(self.required_dimension_ids) - set(self.file_dimensions))
            self.dimensions = [x for x in self.required_dimension_ids
                    if x not in missing_set]
            if len(missing_set) != 0:
                self.missing_dimensions = [x for x in
                        self.required_dimension_ids if x in missing_set]
            self.load_dimensions = self.dimensions
        elif (self.required_dimension_ids is not None and
                self.optional_dimension_ids is not None):
            # Both specified, can't overlap. Otherwise use all.
            isect_req_opt = (set(self.required_dimension_ids) &
                    set(self.optional_dimension_ids))
            if len(isect_req_opt) != 0:
                # Dimension can't be both required and optional.
                raise QueryError('Dimensions are required and optional: %s' %
                        (', '.join(isect_req_opt)))

            missing_set = (set(self.required_dimension_ids) -
                    set(self.file_dimensions))
            load_req = [x for x in self.required_dimension_ids
                    if x not in missing_set]
            load_opt, fake_opt = _separate_optional()
            self.dimensions = (load_req + self.optional_dimension_ids)
            self.load_dimensions = load_req + load_opt
            if len(fake_opt) != 0:
                self.fake_dimensions = fake_opt
            if len(missing_set) != 0:
                self.missing_dimensions = [x for x in
                        self.required_dimension_ids if x in missing_set]

        # measures
        if self.required_measures is None:
            self.measures = self.meta['measures']

            # For reducing measures in bundles. Defaults to all measures if nothing in intersection(all, include)
            if self.include_measures is not None:
                included = set(self.meta['measures']).intersection(set(self.include_measures))
                if included:
                    self.measures = list(included)
        else:
            missing = (set(self.required_measures) - set(self.meta['measures']))
            if len(missing) != 0:
                raise QueryWarning({
                    'error': 'Input cube missing measures',
                    'measures': ', '.join(missing),
                    'file': self.cube_file
                    })
            self.measures = self.required_measures

    # Map positions to new ids. Used by group_other() apply.
    def remap_positions(self, dim_id, new_id, pos_id_set, sense):
        if sense == 'include':
            include = True
        else:
            # exclude is used by group_other().
            include = False
        group_i = self.dimensions.index(dim_id)
        axis = self.axes[group_i]
        for idx, pos_id in enumerate(axis):
            if include and pos_id in pos_id_set:
                axis[idx] = new_id
            elif not include and pos_id not in pos_id_set:
                axis[idx] = new_id

    # Overwrite existing dimension, or add new one
    def add_or_overwrite_dimension(self, dim_id, positions_arr, axis):
        try:
            dim_idx = self.dimensions.index(dim_id)
        except ValueError:
            return self.add_dimension(dim_id, positions_arr, axis)
        self.positions[dim_idx] = positions_arr
        self.axes[dim_idx] = axis

    # Add a new dimension. Used by groupby_attribute() apply.
    def add_dimension(self, dim_id, positions_arr, axis):
        self.dimensions.append(dim_id)
        self.positions.append(positions_arr)
        self.axes.append(axis)

    # Add empty columns for optional dimensions that aren't in the loaded cube.
    def _add_fake_dimensions(self):
        if self.fake_dimensions is None:
            return
        # Fake dimensions are full of None. So, positions are all 0, and axis
        # has a single value, None. Debatable whether it should be None,
        # or some other new special value.
        for dim in self.fake_dimensions:
            self.axes.append([deepy.dimensions.special_positions['None']])
            p_arr = np.zeros(len(self), dtype=position_internal_index_type)
            self.positions.append(p_arr)

    # Follows 'convert_to' in ddb to convert/delete positions.
    def _remap_converted_positions(self):
        log.debug('cube-remap-converted-positions')

        SPECIAL_NON_DDB_DIMS = ['timestamp', 'user', 'page', 'subip', 'id']

        if self.dimensions_db is None:
            log.debug('no-dimensions_db-given')
            return

        if self.dimensions is None:
            return

        # Remapping all dimensions is expensive -- adds 2-3 seconds
        # Just remap what we need (craig)
        output_dimension_ids = []
        if self.required_dimension_ids:
            output_dimension_ids += self.required_dimension_ids
        if self.optional_dimension_ids:
            output_dimension_ids += self.optional_dimension_ids

        # Look for positions in each axis that need to be remapped
        #for idx, dim in enumerate(output_dimension_ids):
        for idx, dim in enumerate(self.dimensions):

            # timestamp is a special case.
            if dim in SPECIAL_NON_DDB_DIMS:
                log.debug('skipping-non-dimdb-dim')
                continue

            # lookup dimension
            ddb = self.dimensions_db.get_by_id(dim)
            if not ddb:
                if dim not in ['backbone', 'market.local', 'market.remote']:
                    continue
                else:
                    # HACK special case: backbone_small contains these dimensions no matter what
                    log.debug('dimension-missing-in-db %s', dim)
                    continue

            # HACK Special case; origin_asn can have missing IDs and be okay; just skip
            if 'origin_asn' in self.dimensions_db.get_names_by_id(dim):
                log.debug('skipping-origin_asn-dim')
                continue

            # HACK Special case; aspaths are often numbers and will be incorrectly
            # dereferenced as position ids below
            if 'aspaths' in self.dimensions_db.get_names_by_id(dim):
                log.debug('skipping-aspaths-dim')
                continue

            # HACK Special case; for DSCP 0, it is incorrectly
            # dereferenced as position null
            if 'dscp' in self.dimensions_db.get_names_by_id(dim):
                log.debug('skipping-dscp-dim')
                continue

            positions = ddb['positions']

            # Recursive position follower
            def _follow_position(posId, visited=None):
                if visited is None:
                    visited = []

                poss = str(posId)
                if not poss.isdigit():
                    return posId

                if posId in visited:
                    log.warn('cycle-detected %s %s', posId, visited)
                    return None

                # position exists in dimensions_db
                if poss in positions:
                    p = positions[poss]
                    # position def has convert_to
                    if 'convert_to' in p:
                        # convert_to: null
                        if not p['convert_to']:
                            log.debug('convert-to-null')
                            return None
                        # convert_to: <new_id>
                        else:
                            log.debug('following-position %s', posId)
                            try:
                                follow_pos = int(p['convert_to'])
                            except ValueError:
                                follow_pos = p['convert_to']
                            return _follow_position(follow_pos, visited=visited+[posId])
                    # position is grounded terminal
                    else:
                        return posId
                # position is missing from dimensions_db
                else:
                    log.debug('missing-position %s', poss)
                    return None

            # Remap positions
            for axisIdx, pos in enumerate(self.axes[idx]):
                if not pos:
                    continue
                self.axes[idx][axisIdx] = _follow_position(pos)


    def get_summary(self):
        #indices = [self.measures.index(x) for x in ['sent_bytes', 'recv_bytes']]
        indices = [self.measures.index(x) for x in self.measures]
        bytes_measures = [self.measure_arrays[i] for i in indices]
        total = 0
        vals = []
        vs = sum(self.time['valid_seconds'].values())

        to_Gbps = lambda _bytes, _vs: _bytes * 8 / _vs / 1e9 if _vs != 0 else 0

        for arr in bytes_measures:
            total += arr.sum()
            vals.append("%2.3f" % (to_Gbps(arr.sum(), vs)))

        ret = {
                'positions': self.num_positions(),
                'bytes': total,
                'Gbps': to_Gbps(total, vs),
                'total_secs': vs,
                'vals': vals
                }
        return ret

    # For cube_from_subflow transition. Remove unused old measures.
    def reset_measures_hack(self):
        assert self.measures == measures_sum_old
        self.measure_arrays = [self.measure_arrays[self.measures.index(meas)]
                for meas in measures_bytes]
        self.measures = measures_bytes


# Store cube in dict. keys are namedtuples of the position. values are
# the measures.
# XXX Sometimes measures are a flat dict (cube_from_subflow), and sometimes
# a numpy array (cube_map_queries).
class CubeDict(CubeBase, dict):
    # Reference to CubeQuery's dim_db.
    dim_db = None

    # Hold cube-specific dimensions. Currently for ephemeral dimensions.
    dim_db_local = None

    def __init__(self, dimensions=None, step=None):
        super(CubeDict, self).__init__()
        if dimensions is not None:
            self.set_dimensions(dimensions)
        self.time['step'] = step
        self.query_warnings = []

        self.cube = None
        self.query = None
        self.url = None
        self.urls = OrderedDict()
        self.values_per_position = None
        self.meta_extra = {}

    # Initialize cube with meta from another cube.
    @classmethod
    def from_meta(cls, cube_src):
        return from_meta_common(cls(), cube_src)

    def set_dimensions(self, dimensions):
        if len(self) != 0:
            raise Exception("set_dimensions on non-empty cube")
        self.dimensions = dimensions

    def dim_db_local_add_dimensions(self, dim_ids):
        if self.dim_db_local is None:
            self.dim_db_local = deepy.dimensions.DimensionsDB(empty=True)
        self.dim_db_local.copy_dimensions(self.dim_db, dim_ids)

    # Measures need to be 1-d numpy arrays of measures_sum_old
    def prepare_to_store(self, local_file):
        log.info('cube-dict-write file=%s n_positions=%d' %
                (local_file, len(self)))

        if len(self) == 0:
            log.warn('writing-empty-cube')

        # Put positions into numpy.
        dimension_idx = []
        position_arrays = []
        for dimension_name in self.dimensions:
            # Create indices to convert dimension values to ints.
            dimension_idx.append({})
            # Using 1-d arrays to hold the positions for each dimension.
            p_arr = np.zeros(len(self), dtype=position_internal_index_type)
            position_arrays.append(p_arr)

        log.debug('cube-dict-write-create-indices')
        for pos_i, pos in enumerate(self.iterkeys()):
            # Convert position to indices, and store in arrays.
            for dim_i in range(len(self.dimensions)):
                p = pos[dim_i]
                idx = dimension_idx[dim_i]
                # creating an index.
                p_idx = idx.get(p, None)
                if p_idx is None:
                    idx[p] = p_idx = len(idx)
                position_arrays[dim_i][pos_i] = p_idx

        # Setup for the npz save. Dimensions will be saved with the names
        # dimension_0, dimension_1... Measures will be measure_0, ...
        save_arrays = OrderedDict()
        for dim_i, pos_arr in enumerate(position_arrays):
            save_arrays['dimension_%d' % (dim_i)] = pos_arr

        # Create the axes by reversing the position indices, as that's what
        # we'll need when the file is read.
        axes = []
        for d in dimension_idx:
            # The reversed indices are lists of dimension values, literally
            # indexed by the position ids. Think of them as axes with labels.
            id_sorted = sorted(d.items(), key=lambda x: x[1])
            # Sanity check above code - make sure the ids are sequential from 0.
            if len(id_sorted) > 0 and id_sorted[-1][1] != len(id_sorted) - 1:
                raise Exception('bad ids')
            axes.append([x[0] for x in id_sorted])

        # Also turn measures into 1-d arrays.
        _vals = self.values()
        if _vals:
            measures_arr = np.array(_vals)
            for meas_i in range(measures_arr.shape[1]):
                save_arrays['measure_%d' % (meas_i)] = measures_arr[:,meas_i]

        # Convert non-numpy types to json. numpy will pickle non-numpy types.
        # pickle saves the module and class name for objects, which can
        # lead to problems if the module containing a class changes.
        meta_json = json.dumps(self.get_meta(), default=list)
        axes_json = json.dumps(axes, default=list)

        info = meta_json, axes_json, save_arrays

        def write_store():
            self._write_to_store(local_file, meta_json, axes_json, save_arrays)
        return write_store, info

    def _write_to_store(self, local_file, meta_json, axes_json, save_arrays):
        log.debug('cube-dict-write-saving')
        dirs = os.path.dirname(local_file)
        if dirs != '':
            try:
                os.makedirs(dirs)
            except OSError, e:
                if e.errno != errno.EEXIST:
                    raise e

        ext = '.npz'
        if local_file.endswith('.h5'):
            ext = '.h5'

        deepy.util.ensure_directory(deepy.cfg.data_tmp)
        tempFile = tempfile.NamedTemporaryFile(delete=False, suffix=ext, dir=deepy.cfg.data_tmp)
        tmp_name = tempFile.name
        tempFile.close()

        if local_file.endswith('.h5'):
            write_h5_cube(tmp_name, save_arrays, meta_json, axes_json)
        else:
            np.savez_compressed(tmp_name, meta=meta_json, axes=axes_json, **save_arrays)

        # test load, should raise an exception if it can't load
        CubeLoader(tmp_name)

        os.rename(tmp_name, local_file)
        os.chmod(local_file,
                 stat.S_IWUSR|stat.S_IRUSR|stat.S_IROTH|stat.S_IWOTH)

        deepy.store.cache_save_to_remote(local_file)
        log.info('cube-dict-write-done')

    # Measures need to be 1-d numpy arrays of measures_sum_old
    def write_to_store(self, local_file):
        write_store, info = self.prepare_to_store(local_file)
        write_store()

    def get_json(self, indent=None):
        return json.dumps(self.get_dict(), default=list, indent=indent)

    def get_dict(self):
        out = OrderedDict()     # keep meta_data at the top of the json.
        out['meta_data'] = self.get_meta()
        # Assuming this is going to be json returned to UI. Use the fully
        # parsed version of dim_db_local.
        if self.dim_db_local is not None:
            out['dim_db_local'] = self.dim_db_local

        # Reformat for json.
        out['cube'] = [list(position) + measures.tolist() for
                position, measures in self.iteritems()]

        return out

    # Returns a list of cube items where each item contains just the requested
    # fields.
    def get_fields(self, fields):
        positions_arr = np.array(self.keys())
        measures_arr = np.array(self.values())
        result = []
        for f in fields:
            if f in self.dimensions:
                idx = self.dimensions.index(f)
                result.append(positions_arr[:,idx].reshape(-1,1))
            elif f in self.measures:
                idx = self.measures.index(f)
                result.append(measures_arr[:,idx].reshape(-1,1))
            else:
                raise Exception('unknown-field %s' % (f))
        return np.hstack(result).tolist()

    def get_meta(self):
        return get_meta_common(self)

    # Return dicts of position and measure arrays.
    def to_arrays(self):
        pos_map = OrderedDict()
        pos_arr = np.array(self.keys())
        for i, dim_id in enumerate(self.dimensions):
            arr = pos_arr[:,i]
            # Replace None with 0.
            arr[arr == np.array(None)] = 0
            # Convert from object array.
            try:
                pos_map[dim_id] = np.array(arr,
                        dtype=deepy.cube_cy.position_dtype)
            except ValueError:
                # Positions contain other non-numerics. Probably did
                # convert_to_names apply. Continue, but return object array.
                pos_map[dim_id] = np.array(arr, dtype=object)

        meas_map = OrderedDict()
        meas_arr = np.array(self.values())
        for i, meas_id in enumerate(self.measures):
            meas_map[meas_id] = meas_arr[:,i]

        return pos_map, meas_map

    # For testing
    def to_cube_hash(self):
        pos_map, meas_map = self.to_arrays()
        axes = OrderedDict()
        for dim_id, pos_arr in pos_map.iteritems():
            pos_indexed, axis = deepy.cube_cy.positions_to_indexed(pos_arr)
            pos_map[dim_id] = pos_indexed
            axes[dim_id] = axis

        return CubeHash.from_indexed_arrays(pos_map, axes, meas_map, self,
            self.time['valid_seconds'], self.time['step'])

    def to_data_frame(self):
        return self.to_cube_hash().to_data_frame()


# Initialize cube with meta from another cube.
# Now copying more than just the "meta" section. Basically, trying to init new
# cube with everything from src except the actual data.
def from_meta_common(cube_obj, cube_src):
    meta = cube_src.get_meta()

    if meta is None:
        meta = {}

    cube_obj.set_dimensions(meta['dimensions'])
    # cube_obj = cls(dimensions=meta['dimensions'])
    cube_obj.measures = meta['measures'][:] if meta.get('measures') is not None else cube_obj.measures
    cube_obj.time = TimeMeta.from_dict(meta['time'])
    cube_obj.query_warnings = meta['query_warnings'] if 'query_warnings' in meta else cube_obj.query_warnings

    cube_obj.cube = meta.get('cube')
    cube_obj.query = meta.get('query')
    cube_obj.url = meta.get('url')

    cube_obj.urls = OrderedDict()
    for cube_name, url in meta.get('urls', {}):
        cube_obj.urls[cube_name] = url

    cube_obj.values_per_position = meta.get('values_per_position')

    cube_obj.dim_db = cube_src.dim_db
    cube_obj.dim_db_local = cube_src.dim_db_local
    cube_obj.meta_extra = cube_src.meta_extra


    return cube_obj


def get_meta_common(self):
    meta = OrderedDict()
    meta['version'] = self.cube_version
    meta['dimensions'] = self.dimensions
    meta['measures'] = self.measures
    meta['time'] = self.time
    meta['query_warnings'] = self.query_warnings

    meta['cube'] = self.cube
    meta['query'] = self.query
    meta['url'] = self.url

    meta['urls'] = []
    for cube_name, url in self.urls.items():
        meta['urls'].append((cube_name, url))

    meta['values_per_position'] = self.values_per_position
    if hasattr(self, 'meta_extra'):
        for k in self.meta_extra:
            meta[k] = self.meta_extra[k]
        #meta['meta_extra'] = self.meta_extra

    return meta


def replace_none(x):
    if x == NONE_FLAG:
        return None
    elif x is None:
        return NONE_FLAG
    return int(x)


def write_h5_cube(output_file, arrs, meta_json, axes_json, version=2, chunkshape=None, complevel=9):
    if chunkshape == None:
        chunkshape = (4048576,)

    h5 = tables.open_file(output_file, mode = 'w')
    filt_blosc = tables.Filters(complevel=complevel, complib='blosc')

    meta_node = tables.nodes.filenode.new_node(h5, where='/', name='meta')
    meta_node.attrs.version = version
    meta_node.write(meta_json)
    meta_node.close()

    axes_node = tables.nodes.filenode.new_node(h5, where='/', name='axes')
    axes_node.write(axes_json)
    axes_node.close()

    if arrs:
        largest_arr = max([len(arr) for arr in arrs.values()])
        chunkshape = min([chunkshape[0], largest_arr])
        chunkshape = max(1, chunkshape)

        for name, arr in arrs.items():
            if len(arr) == 0:
                continue
            atom = tables.Atom.from_dtype(arr.dtype)
            ds = h5.createCArray(h5.root, name, atom, arr.shape, filters=filt_blosc, chunkshape=(chunkshape,))
            ds[:] = arr

    h5.close()

def serialize_cube(dim_arrs, meas_arrs):
    # Setup for the npz save. Dimensions will be saved with the names
    # dimension_0, dimension_1... Measures will be measure_0, ...
    save_arrays = OrderedDict()

    if dim_arrs is not None: # sum_all
        for dim_i, dim_arr in enumerate(dim_arrs):
            name = 'dimension_%d' % (dim_i)
            save_arrays[name] = dim_arr

    if meas_arrs is not None: # sum_all
        for meas_i, meas_arr in enumerate(meas_arrs):
            name = 'measure_%d' % (meas_i)
            save_arrays[name] = meas_arr

    return save_arrays

class CubeHash(CubeBase):
    # Maps from local ids to global ids. Note: after rollup, the axes may
    # contain ids that aren't in the cube. This is cleaned up during
    # write_to_store().
    axes = None

    # Python lists of numpy arrays.
    # For rollup, not available until after finalize().
    dimension_arrays = None
    measure_arrays = None

    # Reference to CubeQuery's dim_db.
    dim_db = None

    # Hold cube-specific dimensions. Currently for ephemeral dimensions.
    dim_db_local = None

    # Maps from global ids to local ids.
    _position_indices = None

    # Distinguish b/n rollup and builder.
    _did_rollup = False

    # Used for rollup to track dimensions that were ever faked.
    _faked_dim_ids = set()

    # GroupbySum for rollup
    _groupby = None

    # Track ts on merge (craig)
    _ts_in_seen = set()

    def __init__(self, dimensions=None, step=None, dim_db=None):
        super(CubeHash, self).__init__()
        self.dim_db = dim_db
        self._groupby = deepy.cube_cy.GroupbySum()
        self._ts_in_seen = set()

        # sum all only works with the product of a time_dist apply
        # (ie it needs to go through the rollup_bundle/finalize_bundle
        # normal rollup doesn't support it
        self.sum_all = False

        if dimensions is not None:
            self.set_dimensions(dimensions)
        self.time['step'] = step
        self.query_warnings = []
        self.df = pd.DataFrame()
        self.valid_seconds = []
        self.values_per_position = None
        self.use_bundle_rollup = False

        self.cube = None
        self.meta_extra = {}
        self.query = None
        self.url = None
        self.urls = OrderedDict()

    def get_measure(self, measure_name, row_id):
        '''
        Returns the requested measure for the specified row_id
        '''
        return self.get_measures(measure_name)[row_id]

    def get_measures(self, measure_name):
        '''
        Returns an array of all of the measures with the specified measure name
        '''
        index = self.measures.index(measure_name)
        return self.measure_arrays[index]

    def _find_dimension_index(self, dimension):
        index = None
        try:
           index = self.dimensions.index(dimension)
        except ValueError:
           pass

        if index is None and self.dim_db is None:
            raise ValueError("Dimension {} not found".format(dimension))

        if index is None:
            index = self.dimensions.index(self.dim_db.get_id_by_name(dimension))
        if index is None:
            raise ValueError("Dimension {} not found".format(dimension))

        return index

    def get_position_id(self, dimension, row_id):
        '''
        Returns the position of the requested dimension for the specified row_id
        '''
        index = self._find_dimension_index(dimension)
        axis_id = self.dimension_arrays[index][row_id]
        axis = self.axes[index]
        return axis[axis_id]

    def get_position_ids(self, dimension):
        '''
        Return a list of position ids (as opposed to axis ids) for given dimension.
        dimension can be either a name or an id. Tries id first, falls back to name.
        '''
        index = self._find_dimension_index(dimension)
        axis_ids = self.dimension_arrays[index]
        axis = self.axes[index]
        return map(lambda x: axis[x], axis_ids)


    # Initialize cube with meta from another cube.
    @classmethod
    def from_meta(cls, cube_src):
        return from_meta_common(cls(), cube_src)

    def __len__(self):
        if self.sum_all:
            return 1
        elif self.dimension_arrays is None:
            return self._groupby.num_positions()
        elif len(self.dimension_arrays) > 0:
            return len(self.dimension_arrays[0])
        return 0

    def num_positions(self):
        return len(self)

    def set_dimensions(self, dimensions):
        if len(self) != 0:
            raise Exception("set_dimensions on non-empty cube")
        self.dimensions = dimensions
        self._position_indices = [{} for x in self.dimensions]
        self.axes = [[] for x in self.dimensions]

    def get_position_index(self, axis_idx, pos_id):
        pos_index = self._position_indices[axis_idx]
        axis = self.axes[axis_idx]
        idx = pos_index.get(pos_id)
        if idx is None:
            idx = len(axis)
            pos_index[pos_id] = idx
            axis.append(pos_id)
        return idx

    def dim_db_local_add_dimensions(self, dim_ids):
        if self.dim_db_local is None:
            self.dim_db_local = deepy.dimensions.DimensionsDB(empty=True)
        self.dim_db_local.copy_dimensions(self.dim_db, dim_ids)
        self.dimensions = list(set(self.dimensions) | set(dim_ids))

    # Similar to CubeDict iteritems. Yields position tuple and view of numpy
    # measures.
    def iterslow(self):
        dim_arrs = self.dimension_arrays
        meas_arrs = self.measure_arrays

        if self.dimensions is None and meas_arrs:
            # reading in file result of sum_all
            meas_all = np.vstack(meas_arrs)
            yield tuple(), meas_all[:,0]
        else:
            if len(self) == 0:
                # nditer doesn't like length 0 arrays.
                return

            meas_all = np.vstack(meas_arrs)
            # Not memory efficient, but faster to stack all measures together at
            # beginning.
            if len(dim_arrs) == 1:
                # nditer behaves differently if there is only array. It returns
                # just the value, rather than a tuple with values.
                for pos_i, iter_val in enumerate(np.nditer(dim_arrs)):
                    new_pos = (self.axes[0][iter_val],)
                    yield new_pos, meas_all[:,pos_i]
            else:
                for pos_i, iter_val in enumerate(zip(*dim_arrs)):
                    new_pos = tuple([self.axes[i][p]
                        for i, p in enumerate(iter_val)])
                    yield new_pos, meas_all[:,pos_i]

    # XXX For now, provide method to convert back to standard CubeDict, so
    # rest of the datapath (applies) still work.
    def to_cube_dict(self):
        log.debug('to-cube-dict-start')
        out = CubeDict.from_meta(self)
        for pos, meas in self.iterslow():
            out[pos] = meas
        log.debug('to-cube-dict-done')
        return out

    # Return dicts of position and measure arrays. Kinda the opposite of
    # from_arrays(). Does the conversion from indexed positions to actual
    # position ids.
    # NOTE: Converts None positions to 0. Otherwise output arrays would have
    # to be of type Object (big). Also, using 0 for Null is the way forward.
    # Preserves dimension and measure order with OrderedDicts.
    def to_arrays(self):
        pos_arrs = []
        for pos_indexed, axis in zip(self.dimension_arrays, self.axes):
            # Convert None to 0.
            try:
                nul_val = deepy.dimensions.special_positions['None']
                nul_idx = axis.index(nul_val)
            except ValueError:
                pass
            else:
                axis = axis[:]  # Don't modify original axis.
                axis[nul_idx] = 0
            pos_arrs.append(deepy.cube_cy.indexed_to_positions(pos_indexed, axis))

        pos_map = OrderedDict(zip(self.dimensions, pos_arrs))
        meas_map = OrderedDict(zip(self.measures, self.measure_arrays))
        return pos_map, meas_map

    def to_data_frame(self):
        '''
        Converts the CubeHash to a Pandas DataFrame
        '''
        pos_map, meas_map = self.to_arrays()

        # Make a pandas dataframe from it
        pd_dict = OrderedDict()
        pd_dict.update(meas_map)
        pd_dict.update(pos_map)
        data_frame = pd.DataFrame(pd_dict)

        return data_frame

    def get_meta(self):
        return get_meta_common(self)

    def get_summary(self):
        #indices = [self.measures.index(x) for x in ['sent_bytes', 'recv_bytes']]
        indices = [self.measures.index(x) for x in self.measures]
        bytes_measures = [self.measure_arrays[i] for i in indices]
        total = 0
        vals = []
        vs = sum(self.time['valid_seconds'].values())
        for arr in bytes_measures:
            total += arr.sum()
            vals.append("%2.2f" % (arr.sum() * 8/vs/1000000000.0))

        ret = {
                'positions': self.num_positions(),
                'bytes': total,
                'Gbps': total * 8/vs/1000000000.0,
                'total_secs': vs,
                'vals': vals
                }
        return ret

    def _sort(self, save_arrays):
        t1 = time.time()
        pos_arrs = OrderedDict()
        for di, (name, dim) in enumerate(save_arrays.items()):
            if name.startswith('dimen'):
                dim_axes = self.axes[di]
                arr = np.array(dim, dtype=np.uint32)
                for i, idx in enumerate(dim):
                    arr[i] = replace_none(dim_axes[idx])
            else:
                arr = dim
            pos_arrs[name] = arr
        t2 = time.time()
        print 'make pos', t2-t1

        t1 = time.time()
        records = np.core.records.fromarrays(pos_arrs.values(), names=pos_arrs.keys())
        indices = records.argsort()
        t2 = time.time()
        print 'argsort', t2-t1

        t1 = time.time()
        records = np.core.records.fromarrays(save_arrays.values(), names=save_arrays.keys())
        records = records[indices]
        t2 = time.time()
        print 'sort', t2-t1

        t1 = time.time()
        save_arrays2 = OrderedDict()
        for key, val in save_arrays.items():
            save_arrays2[key] = getattr(records, key)
        t2 = time.time()
        print 'final', t2-t1

        return save_arrays2

    def prepare_to_store(self, local_file, sort=False):
        log.info('cube-hash-write file=%s n_positions=%d' %
                (local_file, len(self)))

        if len(self) == 0:
            DeepStats().event('platform.make.empty_cube')
            log.warn('writing-empty-cube')

        if self._did_rollup:
            self._reindex_arrays()

        save_arrays = serialize_cube(self.dimension_arrays, self.measure_arrays)

        if sort:
            save_arrays = self._sort(save_arrays)

        # Convert non-numpy types to json. numpy will pickle non-numpy types.
        # pickle saves the module and class name for objects, which can
        # lead to problems if the module containing a class changes.
        meta_json = json.dumps(self.get_meta(), default=list)
        axes_json = json.dumps(self.axes, default=list)

        info = meta_json, axes_json, save_arrays

        def write_store():
            self._write_to_store(local_file, meta_json, axes_json, save_arrays)

        return write_store, info

    def _write_to_store(self, local_file, meta_json, axes_json, save_arrays):
        log.debug('cube-hash-write-saving')
        dirs = os.path.dirname(local_file)
        if dirs != '':
            try:
                os.makedirs(dirs)
            except OSError, e:
                if e.errno != errno.EEXIST:
                    raise e

        ext = '.npz'
        if local_file.endswith('.h5'):
            ext = '.h5'

        deepy.util.ensure_directory(deepy.cfg.data_tmp)
        tempFile = tempfile.NamedTemporaryFile(delete=False, suffix=ext, dir=deepy.cfg.data_tmp)
        tmp_name = tempFile.name
        tempFile.close()

        if local_file.endswith('.h5'):
            write_h5_cube(tmp_name, save_arrays, meta_json, axes_json)
        else:
            np.savez_compressed(tmp_name, meta=meta_json, axes=axes_json, **save_arrays)

        # test load, should raise an exception if it can't load
        CubeLoader(tmp_name)

        os.rename(tmp_name, local_file)
        os.chmod(local_file,
                 stat.S_IWUSR|stat.S_IRUSR|stat.S_IROTH|stat.S_IWOTH)

        deepy.store.cache_save_to_remote(local_file)
        log.debug('cube-hash-write-done')

    # Measures need to be 1-d numpy arrays of measures_sum_old
    def write_to_store(self, local_file, sort=False):
        write_store, info = self.prepare_to_store(local_file, sort)
        write_store()

    # XXX Make native
    def get_json(self, indent=None):
        cube_dict = self.to_cube_dict()
        return cube_dict.get_json(indent)

    # XXX Make native
    def get_dict(self):
        cube_dict = self.to_cube_dict()
        return cube_dict.get_dict()

    # XXX Make native
    def get_fields(self, fields):
        cube_dict = self.to_cube_dict()
        return cube_dict.get_fields(fields)

    # #### CubeBuilder-Specific Methods

    # positions - dict with dim_ids as keys and values of numpy 1D arrays
    # of ddb position ids, using 0 for None. Will be converted to dtype u4
    # if not already.
    #
    # measures - dict with measure_ids as keys and values of numpy 1D arrays
    # of measure values. Will be converted to dtype f4 if not already.
    #
    # aggregate - deduplicate positions. If you've already done this, you can
    # skip this step.
    #
    # timestep - seconds. Set only if you're passing in a timestamp dimension.
    # NOTE: You can leave timestamp dimension out, and add it later using
    # add_timestamp_dimension(). (Easier in most cases)
    #
    # If you want to preserve your dimension and measure order, pass in
    # OrderedDicts.
    @classmethod
    def from_arrays(cls, positions, measures, aggregate=True, timestep=None):
        cube = cls()

        # Convert types if necessary.
        pos_arrs = positions.values()
        dtypes = [arr.dtype for arr in pos_arrs]
        if not all([dt == deepy.cube_cy.position_dtype for dt in dtypes]):
            log.debug('casting-positions')
            pos_arrs = [np.array(arr, dtype=deepy.cube_cy.position_dtype)
                        for arr in pos_arrs]

        meas_arrs = measures.values()
        dtypes = [arr.dtype for arr in meas_arrs]
        if not all([dt == deepy.cube_cy.measure_dtype for dt in dtypes]):
            log.debug('casting-measures')
            meas_arrs = [np.array(arr, dtype=deepy.cube_cy.measure_dtype)
                    for arr in meas_arrs]

        # Aggregate
        if aggregate:
            log.debug('aggregating')
            gb = deepy.cube_cy.GroupbySum()
            gb.process(pos_arrs, meas_arrs)
            pos_arrs, meas_arrs = gb.finish()

        # Relying on dict returning keys/values in same order.
        cube.measures = measures.keys()
        cube.dimensions = positions.keys()

        # Set measures
        cube.measure_arrays = meas_arrs

        # Set dimension_arrays and axes.
        cube._set_positions_and_axes_from_arrs(pos_arrs)

        # Setup timestep dimension if passed in.
        if timestep is not None:
            cube._set_time(timestep)

        return cube

    @classmethod
    def from_data_frame(cls, data_frame, dimension_map,
        aggregate=False, timestep=None):
        '''
        Converts a data frame into a cube.

        Dimension map is a dictionary that maps fields in the data frame
        to dimension ids.

        timestep is passed to from_arrays, so it's used in the same way.

        '''
        # Convert indices to positions
        positions = collections.OrderedDict()
        measures = collections.OrderedDict()
        index_names = data_frame.index.names
        for i, dimension_name in enumerate(data_frame.index.names):
            if not hasattr(data_frame.index, 'levels'):
                break
            levels = data_frame.index.levels
            labels = data_frame.index.labels
            dimension_id = dimension_map.get(dimension_name)
            dimension_id = dimension_id or dimension_name
            positions[dimension_id] = np.array(levels[i][labels[i]])
            if dimension_name in dimension_map:
                del dimension_map[dimension_name]

        dimension_name = data_frame.index.name
        if dimension_name:
            dimension_id = dimension_map.get(dimension_name)
            dimension_id = dimension_id or dimension_name
            positions[dimension_id] = np.array(data_frame.index)
            if dimension_name in dimension_map:
                del dimension_map[dimension_name]

        # Convert the rest of the dimensions to position arrays
        exclude_keys = set()
        for dimension_name, dimension_id in dimension_map.iteritems():
            exclude_keys.add(dimension_name)
            dimension_id = dimension_id or dimension_name
            positions[dimension_id] = np.array(data_frame[dimension_name])

        # Convert measures
        for field in data_frame.keys():
            if field in exclude_keys: continue
            measures[field] = np.array(data_frame[field])

        # Pass to from arrays
        if not 'timestamp' in data_frame.reset_index():
            timestep = None
        return cls.from_arrays(positions, measures,
            timestep=timestep, aggregate=aggregate)


    # Expands a single timestamp out to cover entire cube. Sets up meta,
    # valid_seconds as well.
    # timestamp - unix timestamp (int)
    # timestep - seconds (int)
    def add_timestamp_dimension(self, timestamp, timestep):
        if 'timestamp' in self.dimensions:
            raise ValueError
        self.axes.append([timestamp])
        self.dimensions.append('timestamp')
        self.dimension_arrays.append(np.zeros(len(self),
            dtype=position_internal_index_type))
        self._set_time(timestep)

    # For cube building, setup the time attribute. Assumes the timestamp
    # dimension/axis already exists.
    def _set_time(self, timestep):
        if 'timestamp' not in self.dimensions:
            raise ValueError

        self.time['step'] = timestep

        ts_i = self.dimensions.index('timestamp')
        ts_axis = self.axes[ts_i]
        # All timestamps start out with timestep valid_seconds.
        self.time['valid_seconds'] = dict([(ts, timestep) for ts in ts_axis])

    # Given position_arrays that have ddb pos_ids (or other global id), create
    # axes and dimension arrays.
    def _set_positions_and_axes_from_arrs(self, position_arrays):
        new_arrs = []
        axes = []
        # pos_len = len(position_arrays[0])
        if position_arrays is not None:
            for pos_arr in position_arrays:
                new_arr, new_axis = deepy.cube_cy.positions_to_indexed(pos_arr)
                # Convert 0 to None in axis.
                try:
                    none_idx = new_axis.index(0)
                except:
                    pass
                else:
                    new_axis[none_idx] = deepy.dimensions.special_positions['None']

                new_arrs.append(new_arr)
                axes.append(new_axis)

        self.dimension_arrays = new_arrs
        self.axes = axes


    # #### Rollup-Specific Methods

    # positions_arr_list is list of 1D numpy arrays containing the selected
    #   dimensions.
    # measures_arr_list is list of 1D numpy arrays containing the selected
    #   measures.
    # convert_axes is a list of python lists that map from the input local
    #   ids to the result local ids.
    # selected_indices is array/iterable of the indices selected for rollup
    #   (by slicing)
    def rollup(self, positions_arr_list, measures_arr_list, convert_axes, selected_indices):
        self._did_rollup = True
        # Results of np.where seem to have dtype int64. Normalize to u4.
        selected_indices_arr = np.array(selected_indices, dtype='u4')

        # Make list of numpy arrays for convert_axes.
        convert_axes_arr_list = [np.array(axis,
            dtype=deepy.cube_cy.position_dtype) for axis in convert_axes]

        if len(positions_arr_list) == 0:
            assert(0)

        self._groupby.process(positions_arr_list, measures_arr_list,
                selected_indices=selected_indices_arr,
                convert_axes=convert_axes_arr_list)

    def rollup_bundle(self, cube_in, positions_arr_list, measures_arr_list, convert_axes, selected_indices):
        self.use_bundle_rollup = True

        values_per_position = cube_in.meta['values_per_position']
        cube_vs = cube_in.time['valid_seconds']

        self.required_dimension_ids = cube_in.required_dimension_ids

        self._did_rollup = True

        positions_arr_list = [x[selected_indices] for x in positions_arr_list]
        measures_arr_list = [x[selected_indices] for x in measures_arr_list]

        # convert input local ids to output/result local ids
        # result is set by the first cube coming in (see farther up the stack)
        new_positions_arr_list = []
        for convert_axis, dim in zip(convert_axes, positions_arr_list):
            pos_arr = []
            for pos_in in dim:
                pos_out = convert_axis[pos_in]
                pos_arr.append(pos_out)
            new_positions_arr_list.append(pos_arr)

        pos_arrs = dict(zip(self.dimensions, new_positions_arr_list))
        meas_arrs = collections.OrderedDict(zip(self.measures, measures_arr_list))

        valid_seconds = {}
        if 'timestamp' in self.dimensions and not self.sum_all:
            # setup valids seconds
            axes_arrs = collections.OrderedDict(zip(self.dimensions, self.axes))
            timestamps = deepy.cube_cy.indexed_to_positions(pos_arrs['timestamp'], axes_arrs['timestamp'])

            ovs = []
            for ts in timestamps:
                vs = cube_vs[ts]
                ovs.append(vs)
            valid_seconds = {'valid_seconds': np.array(ovs)}
        elif (
               # summary in make_bundle_drill_query_summary/make_bundle_drill_month_summary
               ('timestamp' not in self.dimensions) or

               # summary in make_bundle_drill_day_summary
               ('timestamp' in self.dimensions and self.sum_all)
             ):
            # since we don't have a timestamp dimension
            # match up the valid seconds with each position
            # should all be the same
            # assumes one timestamp in valid_seconds
            _vs = cube_in.meta['time']['valid_seconds'].values()[0]
            if new_positions_arr_list:
                pos_len = len(new_positions_arr_list[0])
            else:
                pos_len = 1 # summary
            ovs = [_vs]*pos_len
            valid_seconds = {'valid_seconds': np.array(ovs)}
        else:
            assert False

        # construct arrays for pandas dataframe
        df_arrs = {}
        df_arrs.update(pos_arrs)
        df_arrs.update(valid_seconds)
        df_arrs.update(meas_arrs)

        # put in number_positions column
        df = pd.DataFrame(df_arrs)
        num_pos_arr = []
        for group in df[self.dimensions].itertuples():
            num_pos_arr.append(values_per_position)

        df_arrs.update({'number_positions': num_pos_arr})
        df = pd.DataFrame(df_arrs)

        self.df = self.df.append(df)

    # Run when rollup is done.
    def finalize(self):
        empty_results = True
        pos_arrs, meas_arrs = self._groupby.finish()
        # Don't try to reuse.
        self._groupby = None
        if pos_arrs is not None:
            empty_results = False
            self.dimension_arrays = pos_arrs
            self.measure_arrays = meas_arrs

        if empty_results:
            if self.dimensions is None or self.measures is None:
                # For consistency, don't generate cube w/o dimensions or
                # measures. I think this will only happen when no input
                # cubes were found.
                raise QueryError('no valid input cubes found')
            # Make empty dimension and measure arrays.
            pos_type = position_internal_index_type
            self.dimension_arrays = [np.array([], dtype=pos_type)
                   for x in self.dimensions]
            self.measure_arrays = [np.array([], dtype=measure_type)
                    for x in self.measures]

    def group_df_keys(self, df):
        dfkeys = df.keys()
        p_to_index_measure_type = []
        p_to_index_pth = []
        measure_group_index_lists = {}
        meas_set = set()
        for i, key in enumerate(dfkeys):
            mtype = None
            pth = None
            if '.' in key:
                parts = key.split('.')
                # pctl.local_host_count.40
                if len(parts) == 3:
                    _, mtype, pth = parts
                    try:
                        pth = int(pth)
                    except ValueError:
                        mtype = ''
                        pth = 0
                elif len(parts) == 4:
                    _, mtype, _, pth = parts
                    pth = int(pth)
                else:
                    mtype = ''
                    pth = -1
                p_to_index_measure_type.append(mtype)
                p_to_index_pth.append(pth)
                if mtype:
                    meas_set.add(mtype)
            else:
                p_to_index_measure_type.append('')
                p_to_index_pth.append(-1)
            measure_group_index_lists[mtype] = measure_group_index_lists.get(mtype, []) + [(pth, i)]

        # sort each measure type array by the percentile 0 to 100
        _measure_index = []
        for mtype, mgi in measure_group_index_lists.items():
            mgi.sort()
            ars = [(fulli, smalli, mtype, pth) for smalli, (pth, fulli) in enumerate(mgi)]
            _measure_index += ars
        _measure_index.sort()
        measure_index = np.array([x[1] for x in _measure_index])

        #for x in measure_index: print x

        return p_to_index_measure_type, np.array(p_to_index_pth), measure_index, meas_set

    def calc95(self, df, dims, percentiles, pctl_gap, base_cnt_denom, p_to_index_measure_type, p_to_index_pth, measure_index, meas_set):
        number_positions_arr = df['number_positions'].values
        measure_groups = deepy.cube_cy.construct_measure_groups(df, dims, p_to_index_measure_type, p_to_index_pth, measure_index, meas_set)
        column_types, columns_arr = deepy.cube_cy.calc_percentiles(measure_groups, number_positions_arr, percentiles, pctl_gap, base_cnt_denom)

        # 5 times as fast as df[dims].values[0]
        dim_vals = np.array([df[dim].values[0] for dim in dims])

        dsum = df['number_positions'].sum()

        columns_arr = np.concatenate([dim_vals, [dsum], columns_arr])

        # turn rows -> columns
        columns_arr.shape = (1, columns_arr.shape[0])

        column_names = []
        column_names += dims + ['number_positions']
        for col_type in column_types:
            ext = '.bps'
            if col_type == 'local_host_count':
                ext = ''
            for percentile in percentiles:
                column_name = 'pctl.{}{}.{}'.format(col_type, ext, int(percentile))
                column_names.append(column_name)

        # add pctl values
        ret = pd.DataFrame(columns_arr)
        ret.columns = column_names

        return ret

    def compute_avg_max(self, is_timeseries, df_final):
        # compute avg/max
        if is_timeseries:
            # max timeseries
            valid_seconds = 300 # FIXME need to carry this forward from original 5 min cubes

            if 'max.recv.bytes' in df_final:
                df_final['max.recv.bps'] = 8.0*df_final['max.recv.bytes']/valid_seconds

            if 'max.sent.bytes' in df_final:
                df_final['max.sent.bps'] = 8.0*df_final['max.sent.bytes']/valid_seconds

            # average/sum timeseries
            if 'sum.recv.bytes' in df_final:
                df_final['avg.recv.bps'] = 8.0*df_final['sum.recv.bytes']/df_final['valid_seconds']

            if 'sum.sent.bytes' in df_final:
                df_final['avg.sent.bps'] = 8.0*df_final['sum.sent.bytes']/df_final['valid_seconds']

            if 'sum.total.bytes' in df_final:
                df_final['avg.total.bps'] = 8.0*df_final['sum.total.bytes']/df_final['valid_seconds']

            if 'sum.local_host_count' in df_final:
                df_final['avg.local_host_count'] = df_final['sum.local_host_count']/(df_final['valid_seconds']/3600.)

            ########################################
            # router drill in average/sum timeseries
            ########################################
            if 'sum.input.bytes' in df_final:
                df_final['avg.input.bps'] = 8.0*df_final['sum.input.bytes']/df_final['valid_seconds']

            if 'sum.output.bytes' in df_final:
                df_final['avg.output.bps'] = 8.0*df_final['sum.output.bytes']/df_final['valid_seconds']


            ########################################
            # backbone-derived drill
            ########################################
            if 'sum.ingress.bytes' in df_final:
                df_final['avg.ingress.bps'] = 8.0*df_final['sum.ingress.bytes']/df_final['valid_seconds']

            if 'sum.egress.bytes' in df_final:
                df_final['avg.egress.bps'] = 8.0*df_final['sum.egress.bytes']/df_final['valid_seconds']

            # max timeseries
            valid_seconds = 3600 # FIXME need to carry this forward from original cubes

            if 'max.input.bytes' in df_final:
                df_final['max.input.bps'] = 8.0*df_final['max.input.bytes']/valid_seconds

            if 'max.output.bytes' in df_final:
                df_final['max.output.bps'] = 8.0*df_final['max.output.bytes']/valid_seconds

            # Assuming max.ingress.bytes is the sum of individual max 5-min values
            # per day, and that valid seconds is the sum of all seconds across
            # input day cubes..
            if 'max.total.bytes' in df_final:
                # Not changing "is_timestamp" logic in general to avoid breaking existing bundles
                if 'pctl.total.bps.100' in df_final:
                    df_final['max.total.bps'] = df_final['pctl.total.bps.100']

            if 'max.ingress.bytes' in df_final:
                if 'pctl.ingress.bps.100' in df_final:
                    df_final['max.ingress.bps'] = df_final['pctl.ingress.bps.100']

            if 'max.egress.bytes' in df_final:
                if 'pctl.egress.bps.100' in df_final:
                    df_final['max.egress.bps'] = df_final['pctl.egress.bps.100']

        else:
            if 'sum.recv.bytes' in df_final:
                df_final['avg.recv.bps'] = 8.0*df_final['sum.recv.bytes']/df_final['valid_seconds']

            if 'sum.sent.bytes' in df_final:
                df_final['avg.sent.bps'] = 8.0*df_final['sum.sent.bytes']/df_final['valid_seconds']

            if 'sum.total.bytes' in df_final:
                df_final['avg.total.bps'] = 8.0*df_final['sum.total.bytes']/df_final['valid_seconds']

            if 'sum.local_host_count' in df_final:
                df_final['avg.local_host_count'] = df_final['sum.local_host_count']/(df_final['valid_seconds']/3600.)

            ########################################
            # router drill in
            ########################################

            if 'sum.input.bytes' in df_final:
                df_final['avg.input.bps'] = 8.0*df_final['sum.input.bytes']/df_final['valid_seconds']

            if 'sum.output.bytes' in df_final:
                df_final['avg.output.bps'] = 8.0*df_final['sum.output.bytes']/df_final['valid_seconds']


            ########################################
            # backbone-derived drill in
            ########################################

            if 'sum.ingress.bytes' in df_final:
                df_final['avg.ingress.bps'] = 8.0*df_final['sum.ingress.bytes']/df_final['valid_seconds']

            if 'sum.egress.bytes' in df_final:
                df_final['avg.egress.bps'] = 8.0*df_final['sum.egress.bytes']/df_final['valid_seconds']


            # Assuming max.ingress.bytes is the sum of individual max 5-min values
            # per day, and that valid seconds is the sum of all seconds across
            # input day cubes..
            if 'max.total.bytes' in df_final:
                # Not changing "is_timestamp" logic in general to avoid breaking existing bundles
                if 'pctl.total.bps.100' in df_final:
                    df_final['max.total.bps'] = df_final['pctl.total.bps.100']

            if 'max.ingress.bytes' in df_final:
                if 'pctl.ingress.bps.100' in df_final:
                    df_final['max.ingress.bps'] = df_final['pctl.ingress.bps.100']

            if 'max.egress.bytes' in df_final:
                if 'pctl.egress.bps.100' in df_final:
                    df_final['max.egress.bps'] = df_final['pctl.egress.bps.100']

    def _do_percentiles(self, percentiles, pctl_gap, agg_dims, agg_dims_95,
                        df95_keys):
        # divide by this for weight of total mass
        base_cnt_denom = pctl_gap * 100.0
        p_to_index_measure_type, p_to_index_pth, measure_index, meas_set = self.group_df_keys(self.df[df95_keys])

        gb = self.df[df95_keys].groupby(agg_dims, sort=False, as_index=False)
        df95 = gb.apply(self.calc95, agg_dims_95, percentiles, pctl_gap, base_cnt_denom, p_to_index_measure_type, p_to_index_pth, measure_index, meas_set)
        return df95

    def finalize_bundle(self):
        tt = deepy.util.TrackTime()

        ops = {}
        for name in self.measures:
            if name.startswith('max.') and name.endswith('.bytes'):
                ops[name] = 'sum'
            elif name.startswith('max.'):
                ops[name] = 'max'
            elif name.startswith('avg.') or 'pctl' in name:
                # do average below
                # 95 uses apply
                pass
            else:
                ops[name] = 'sum'

        # only do this for timeseries not for anything else
        # exclude summary with sum_all
        is_timeseries = 'timestamp' in self.dimensions and len(self.dimensions) == 1 and not self.sum_all

        if 'valid_seconds' in self.df:

            # for timeseries, you only need to divide by
            if is_timeseries:
                ops['valid_seconds'] = lambda x: x[0]
            else:
                ops['valid_seconds'] = np.sum
        ops['number_positions'] = np.sum

        if self.sum_all:
            # don't have anything required, group by nothing
            agg_dims = pd.Int64Index(np.zeros(len(self.df)))
            agg_cols = ops.keys()
            agg_dims_95 = []
        else:
            agg_dims = self.dimensions
            agg_cols = self.dimensions + ops.keys()
            agg_dims_95 = self.dimensions

        tt.end('df_agg')

        # use dims, pctls, and number_positions
        df95_keys = []
        for key in self.df.keys():
            if (key in agg_dims or
                key == 'number_positions' or
                key.startswith('pctl.')):
                df95_keys.append(key)

        ##############################
        # pre-compute for speed
        ##############################
        percentiles = np.array(deepy.cube_apply.ApplyTimeDist.update_percentiles(), dtype='f')
        pctl_gap = percentiles[1:] - percentiles[:-1]

        gb = self.df[agg_cols].groupby(agg_dims, sort=False, as_index=False)

        df_agg = gb.agg(ops)
        df95 = self._do_percentiles(percentiles, pctl_gap, agg_dims,
                                    agg_dims_95, df95_keys)
        tt.end('df95')

        # XXX rearrange tt.end()'s to be meaningful w/ new program flow

        if self.sum_all:
            # manual join is easiest
            dff = {}
            for key, val in df_agg.iteritems():
                if key:
                    dff[key] = val.values

            for key, val in df95.iteritems():
                if key:
                    dff[key] = val.values

            df_final = pd.DataFrame(dff)
        else:
            df_final = pd.merge(df_agg, df95, on=agg_dims, how='left')

        assert 'valid_seconds' in df_final

        tt.end('concat')

        self.compute_avg_max(is_timeseries, df_final)

        tt.end('avg')

        # convert axes, remove timestamps
        if self.sum_all:
            # keep timestamp since you need to return something
            # FIXME maybe do a nice custom timestamp?
            self.dimensions = None
            self.dimension_arrays = None
            self.axes = None
        else:
            self.dimension_arrays = [df_final[d].values.astype(np.uint32) for d in self.dimensions]

        ms = [m for m in self.measures if m in df_final.keys()] # keep in order and subset
        self.measures = ms
        self.measure_arrays = [df_final[m].values for m in self.measures]
        tt.end('dims-meas')

        log.info('finalize-bundle %s' % (tt))


    # Rebuild axes, and update positions to match.
    # Localids are allocated during rollup that may not end up in the final
    # cube (due to slicing). Rebuilding minimizes the local id space so the
    # axes only contain what's in the cube. Things like cube_positions() rely
    # on this. But, running through every position again isn't ideal.
    # Right now this is only done when writing to disk. Cleaning up the local
    # id space isn't necessary if we're just going to output a dict.
    def _reindex_arrays(self):
        log.debug('reindexing-start')
        if len(self) == 0 or (
            self.dimension_arrays is None and
            self.axes is None):
            return
        new_pos_arrs = []
        new_axes = []
        for pos_indexed, axis in zip(self.dimension_arrays, self.axes):
            # cvt_axis will index into axis to create new_axis.
            # Example, actual positions are [None, 13, 13]
            # pos_indexed = [1, 3, 3], axis = [9, None, 11, 13]
            # pos_reindexed = [0, 1, 1], cvt_axis = [1, 3]
            # new_axis = [None, 13]
            pos_reindexed, cvt_axis = deepy.cube_cy.positions_to_indexed(pos_indexed)
            new_axis = [axis[cvt_i] for cvt_i in cvt_axis]
            new_pos_arrs.append(pos_reindexed)
            new_axes.append(new_axis)
        self.dimension_arrays = new_pos_arrs
        self.axes = new_axes
        log.debug('reindexing-done')

    # Used by time_dist() to put the final cube together. Positions are
    # already aggregated and indexed (axes).
    # Now also used by CubeLoader and CubeDict to_cube_hash().
    @classmethod
    def from_indexed_arrays(cls, positions, axes, measures, cube_src,
            valid_seconds, step):
        cube = cls.from_meta(cube_src)
        cube.time['step'] = step
        cube.time['valid_seconds'] = copy.deepcopy(valid_seconds)

        # Convert types if necessary.
        pos_arrs = positions.values()
        dtypes = [arr.dtype for arr in pos_arrs]
        if not all([dt == deepy.cube_cy.position_dtype for dt in dtypes]):
            log.debug('casting-positions')
            pos_arrs = [np.array(arr, dtype=deepy.cube_cy.position_dtype)
                        for arr in pos_arrs]

        meas_arrs = measures.values()
        dtypes = [arr.dtype for arr in meas_arrs]
        if not all([dt == deepy.cube_cy.measure_dtype for dt in dtypes]):
            log.debug('casting-measures')
            meas_arrs = [np.array(arr, dtype=deepy.cube_cy.measure_dtype)
                    for arr in meas_arrs]

        # Relying on dict returning keys/values in same order.
        cube.measures = measures.keys()
        cube.dimensions = positions.keys()

        # Set measures
        cube.measure_arrays = meas_arrs

        # Set dimension_arrays and axes.
        cube.dimension_arrays = pos_arrs
        cube.axes = [axes[dim_id] for dim_id in cube.dimensions]

        return cube

    # Used by measure_fixup
    def replace_measures(self, measures):
        # Convert types if necessary.
        meas_arrs = measures.values()
        dtypes = [arr.dtype for arr in meas_arrs]
        if not all([dt == deepy.cube_cy.measure_dtype for dt in dtypes]):
            log.debug('casting-measures')
            meas_arrs = [np.array(arr, dtype=deepy.cube_cy.measure_dtype)
                    for arr in meas_arrs]

        # Set measures
        self.measures = measures.keys()
        self.measure_arrays = meas_arrs

    # Track dimensions that were faked for remove_empty_fake
    def track_fake(self, fake_dim_ids):
        if fake_dim_ids is None:
            return
        self._faked_dim_ids |= set(fake_dim_ids)

    # Used by apply remove_empty_fake. Remove dimensions that were faked
    # and remain empty at the end of the query.
    def remove_empty_fake(self):
        for dim_id in self._faked_dim_ids:
            dim_idx = self.dimensions.index(dim_id)
            axis = self.axes[dim_idx]
            if len(axis) == 1 and axis[0] is None:
                del self.dimensions[dim_idx]
                del self.dimension_arrays[dim_idx]
                del self._position_indices[dim_idx]
                del self.axes[dim_idx]


# Kinda evil, but it works.
# mro() = [<class 'deepy.cube.CubeOrderedDict'>, <class 'deepy.cube.CubeDict'>,
# <class 'deepy.cube.CubeBase'>, <class 'collections.OrderedDict'>,
# <type 'dict'>, <type 'object'>].
class CubeOrderedDict(CubeDict, OrderedDict):
    def __init__(self, *args, **kwargs):
        # Pass args to CubeDict.
        super(CubeOrderedDict, self).__init__(*args, **kwargs)

    def __reduce_ex__(self, proto=2):
        return self.__reduce__()

    def __reduce__(self):
        'Copied from collections.py with modified logic'
        items = [[k, self[k]] for k in self]
        inst_dict = vars(self).copy()
        for k in vars(OrderedDict()):
            inst_dict.pop(k, None)
        inst_dict['items'] = items
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def __setstate__(self, state):
        for k,v in state['items']:
            self[k] = v
        del state['items']
        self.__dict__.update(state)

# Keeping the calculations separate to keep from confusing myself.
class CubeDictCalc(CubeDict):
    pass


# A dict of CubeDicts (not really a cube). Defined to override get_json().
class PostSliceCubeDict(dict):
    def get_json(self, indent=None):
        return json.dumps(self.get_dict(), default=list, indent=indent)

    def get_dict(self):
        out = {}
        # Call get_dict() on each sub-cube.
        for k, v in self.iteritems():
            out[k] = v.get_dict()
        return out




# Make errors good enough to pass back through api.
class QueryError(Exception):
    pass


# Something that's not necessarily fatal. Data missing in one cube, etc.
# Generally goes into json for debug.
class QueryWarning(Exception):
    # Convenience for json. Pass back errors as dict. See examples in code.
    def get_dict(self):
        # args[0] should be passed a dict.
        return dict(self.args[0])


def _timeslices_to_timestamps(time_slices, step, allow_large=False):
    # Convert time slices to files.
    timestamps = set()
    for s in time_slices:
        if s['type'] == 'include':
            timestamps |= s['values']

        elif s['type'] == 'range_include':
            start = s['values']['start']
            end = s['values']['end']
            if start is None or end is None:
                # TODO might be nice to allow start/end of None, which would mean start of data/now.
                raise QueryError('unsupported time slice')

            if step == 'month':
                # month is a special case.
                # For limit check, approximate to 30 day months.
                if (end - start) / (86400 * 30) > 1000:
                    # Limit single range.
                    if not allow_large:
                        raise QueryError('time range too large')
                timestamps |= set(deepy.timerange.get_month_time_range(start, end))
            else:
                if (end - start) / step > 1000:
                    # Limit single range.
                    if not allow_large:
                        raise QueryError('time range too large')
                # Round up to nearest step.
                start = (start + step - 1) / step * step
                timestamps |= set(range(start, end + 1, step))

        else:
            raise QueryError('timestamp slice type not permitted: %s' %
                    (s['type']))

    # Limit total time slices.
    if len(timestamps) > 1000 and not allow_large:
        raise QueryError('time range too large')

    return timestamps






# Helper
def _find_cube_rule_match(cube_id, time_step):
    # Prevent a circular dependency by importing locally
    import deepy.build.jobs
    time_step = deepy.timerange.convert_seconds_to_range(time_step)
    rules_db = deepy.build.util.construct_rules()
    for rule_name, rule in rules_db.iteritems():
        meta = rule.get('meta', {})
        if (meta.get('cube_id') == cube_id and
            (rule.get('time_step') == time_step or
                rule.get('make_time_step') == time_step)):
            job = deepy.build.jobs.DeepyDictJob(rule_name, rules_db)
            targets = job.get_targets()
            target = targets["produces"][0]
            return target
        elif (rule_name == cube_id and
            (rule.get('time_step') == time_step or
                rule.get('make_time_step') == time_step)):
            job = deepy.build.jobs.DeepyDictJob(rule_name, rules_db)
            targets = job.get_targets()
            target = targets["produces"][0]
            return target
    return None


def find_cube_possible_rules(cube_id):
    '''Returns a list of possible rules matching a cube id'''
    time_steps = [300, 3600, 86400]
    results = map(lambda x: _find_cube_rule_match(cube_id, x), time_steps)
    return filter(lambda x: x, results)

def use_query(subquery, name):
    use = False
    for q in subquery:
        pat = re.compile(q)
        if pat.match(name):
            use = True
            break

    return use


def bundle_query(*args, **kwargs):
    return bundle_query_inner(*args, **kwargs)

@deepy.deepy_redis.cache_bundles
def bundle_query_inner(src_bundle_id, timeslices, slice_defs, dimensions_db, partition_query_updates=None, subquery=None, include_measures=None):
    # get queries from rule
    rules_db = deepy.build.util.construct_rules()
    bundle = rules_db[src_bundle_id]

    timestep = bundle.get('make_time_step') or bundle.get('timestep')

    # lookup files
    timestamps = _timeslices_to_timestamps(timeslices, timestep)

    timestamps = list(timestamps)
    timestamps.sort()

    query_strs = bundle.get('queries', {})
    queries = []

    if dimensions_db is None or dimensions_db == {}:
        dimension_db = deepy.dimensions.DimensionsDB(redis_backed=True)

    # XXX -- special case --- XX
    # Craig is really embarassed bv this and will let naim or luke
    # tell him the correct way to do this once we support contexts
    if slice_defs and len(slice_defs) >=1 and 'dimension' in slice_defs[0]:
        if slice_defs[0]['dimension'] == "bgp_peer.local":
            slice_defs[0]['dimension'] = "peer.local"
        if slice_defs[0]['dimension'] == "bgp_category":
            slice_defs[0]['dimension'] = "category"
        if slice_defs[0]['dimension'] == "bgp_origin_asn.local":
            slice_defs[0]['dimension'] = "origin_asn.local"
        if slice_defs[0]['dimension'] == "bgp_sites":
            slice_defs[0]['dimension'] = "sites"
        if slice_defs[0]['dimension'] == "bgp_aspath.local":
            slice_defs[0]['dimension'] = "aspath.local"
        if slice_defs[0]['dimension'] == "bgp_cdn":
            slice_defs[0]['dimension'] = "cdn"


    trimmed = 0
    for name, query_str in query_strs.items():

        # filter out other queries
        if subquery and not use_query(subquery, name):
            trimmed += 1
            log.debug('bundle-subquery-skip %s %s', name, str(subquery))
            continue

        query_str['slices'] = slice_defs

        # no applies or arg joins
        query_str['applies'] = None
        query_str['arg_joins'] = None

        if partition_query_updates:
            partition_query_updates(query_str)

        cube_files = []
        for ts in timestamps:
            target = query_str['target']
            cube_files.append(
                deepy.build.util.deepy_substitution(deepy.build.util.basic_substitution(target, ts), deepy.cfg))
        query_str['input_files'] = cube_files

        # do use need required_measures in querying bundles
        if 'required_measures' in query_str:
            del query_str['required_measures']

        if include_measures:
            query_str['include_measures'] = include_measures
        q = deepy.cube.CubeQuery(query_str, name=name, ddb=dimensions_db)
        queries.append(q)

    log.debug('trimmed-queries %d of %d', trimmed, len(query_strs))

    # run queries
    s = time.time()
    log.info("bundle-start-query")
    query_cubes = deepy.cube.cube_map_queries(queries, dimensions_db=dimensions_db)
    log.info("bundle-finish-query %2.1f seconds" % (time.time() - s))

    bundle = {}
    bundle["meta_data"] = {"version": 3}
    bundle["data"] = {}

    drill_cubes = ('drill_small', 'drill1', 'interface', 'backbone_small',
                   'datacenter', 'backbone_small_bgp', 'drill_small_network')

    for (query, cube) in query_cubes:
        log.info('bundle-query-writing-cube %s', query.name)
        bundle['data'][query.name] = cube.get_dict()

        for cube_name, url in cube.get_meta().get('urls', []):
            # HACK! FIXME make list of allowed drillable cubes
            if cube_name and (cube_name in drill_cubes or
                              cube_name.startswith('sub_count')):
                bundle['meta_data'][query.name] = {'cube': cube_name, 'url':url}
                break

        #Avoid returning sets in cube queries
        for s in cube.get_meta().get('query', {}).get('slices', []):
            if isinstance(s.get('values', 0), set):
                s['values'] = list(s['values'])

    return bundle



def check_view_satisfied(view, cube_id, time_step, dimensions):

    #if time_step != "1h" and cube_id == 'protectiongroup' and (dimensions == None or dimensions == ['protectiongroup.local', 'timestamp'] or dimensions == ['timestamp']):

    if time_step != "5min":
        return

    dim_idx = deepy.dimensions.DimensionsIdx()
    #print d.name_to_id ("origin_asn.local")

    # Check dimensions are satsified
    # XXX this should include slice as well as results XXX
    for dimension in dimensions:
        if dimension == 'timestamp':
            continue

        if str(dim_idx.name_to_id(dimension)) not in map(str, view['dimensions']):
            print "******* MISSING", dim_idx.name_to_id(dimension), view['dimensions']
            return

    target = deepy.cfg.cubes_dir + "/" + cube_id + "/view/%s/days/" % view['name']
    target += "cube.%Y-%m-%d.h5"
    rule = {"time_step": time_step, "target": target}

    log.info("query-matched-view %s" % rule)

    return rule


def find_view_match (cube_id, slice_defs, time_step, dimensions):

    time_step = deepy.timerange.convert_seconds_to_range(time_step)
    contexts = deepy.context.load_contexts(from_cache=True)

    if dimensions:
        dimensions_tmp = set(dimensions)
    else:
        dimensions_tmp = set([])

    #{'values': set([4]), 'type': 'include', 'dimension': u'ip_version', 'key_path': None}
    for slice_def in slice_defs:
        if slice_def.get('type', None) == "include":
            dimensions_tmp.add(slice_def['dimension'])

    #[{'values': {'start': 1426464000, 'end': 1426518000}, 'type': 'range_include', 'dimension': u'timestamp', 'key_path': None}]

    for key, vals in contexts.iteritems():
        if key != cube_id:
            continue

        if 'views' not in vals:
            continue

        for view in vals['views']:

            # this allows us to let views populate before using
            if view.get('write-only'):
                continue
            
            rule = check_view_satisfied(view, cube_id, time_step, dimensions_tmp)
            if rule:
                return rule


    # XXX hard coded for now XXX
    #if time_step != "1h" and cube_id == 'protectiongroup' and (dimensions == None or dimensions == ['protectiongroup.local', 'timestamp'] or dimensions == ['timestamp']):
    #    log.info("use view")
     #   target = deepy.cfg.cubes_dir + "/" + cube_id + "/view/summary/days/cube.%Y-%m-%d.h5"
    #    rule = {"time_step": time_step, "target": target}
    #    return rule




# src_cube_id - "FROM" - big_cube, etc.
# time_step - the *input* time_step. Basically selects from hour or day
#   input cubes. The result step is set automatically by cube_map_queries().
# result_dimensions - "SELECT" - rollup
# exclude_dimensions - all dimensions except these
# required_measures - on input, only load these measures
# slice_defs - "WHERE" - slices, list of SliceDef objects
# apply - "WITH" - general purpose functions to manipulate measures and
# dimensions
def cube_query(src_cube_id, result_dimensions=None, exclude_dimensions=None,
        required_measures=None, time_step=None, slice_defs=None, apply_flags=None,
        dimensions_db=None, exclude_apply=None, allow_large=False, groupby=None):
    import deepy.build.targets
    import deepy.build.expanders

    rule_match = None
    found_view = False

    # Don't set optional arguments to mutable structures
    if slice_defs == None:
        slice_defs = []
    if apply_flags == None:
        apply_flags = {}
    if exclude_apply == None:
        exclude_apply = set()
    if groupby is None:
        groupby = []

    # Default to 3600 for now.
    if time_step is None:
        time_step = 3600

    # New View support (craig)
    #print "******************", slice_defs
    #[{'values': {'start': 1426464000, 'end': 1426518000}, 'type': 'range_include', 'dimension': u'timestamp', 'key_path': None}]
    #{'values': set([4]), 'type': 'include', 'dimension': u'ip_version', 'key_path': None}
    rule_match = find_view_match (src_cube_id, slice_defs, time_step, result_dimensions)
    if rule_match:
        found_view = True

    # Find a matching src cube. Must match name and time_step.
    # Could maybe make this more automatic.
    if not rule_match:
        rule_match = _find_cube_rule_match(src_cube_id, time_step)

    if rule_match is None:
        raise QueryError('matching cube not found: cube_id=%s time_step=%s' %
                (src_cube_id, str(time_step)))

    # Separate out time slices.
    time_slices = []
    other_slices = []
    for s in slice_defs:
        if s['dimension'] == 'timestamp':
            time_slices.append(s)
            other_slices.append(s)
        else:
            #Bitwise operations are not supported outside of impala
            if s.is_bitwise():
                raise NotImplementedError
            other_slices.append(s)
    if len(time_slices) == 0:
        # Requiring time specification.
        raise QueryError('specify timestamp slice')

    timestamps = _timeslices_to_timestamps(time_slices, time_step, allow_large=allow_large)

    timestamps = list(timestamps)
    timestamps.sort()

    if found_view:
        target_expander = deepy.build.deepy_expanders.DeepyTimestampExpander(
                deepy.build.deepy_targets.DeepyStoreBackedLocalFileSystemTarget,
                rule_match["target"], rule_match["time_step"],
                rule_match["time_step"])
        files = []
        for ts in timestamps:
            expanded_targets = target_expander.expand(
                {
                    "start_time": ts,
                    "end_time": ts,
                }
            )
            for expanded_target in expanded_targets:
                files.append(expanded_target.unique_id)

        files = list(set(files))

    else:
        target_expander = rule_match
        files = []
        for ts in timestamps:
            expanded_targets = target_expander.expand(
                {
                    "start_time": ts,
                    "end_time": ts
                }
            )
            for expanded_target in expanded_targets:
                files.append(expanded_target.unique_id)
        files = list(set(files))

    log.info("FILES %s" % files)

    if apply_flags == []:
        apply_flags = {}

    # Set query specific flags
    if isinstance(apply_flags, dict) and 'measure_fixup' not in exclude_apply:
        apply_flags.setdefault('measure_fixup', True)

    # Pass arg true for use_extended_names.
    if isinstance(apply_flags, dict)  and 'convert_to_names' not in exclude_apply:
        apply_flags.setdefault('convert_to_names', ['true'])

    if isinstance(apply_flags, dict)  and 'return_dimension_names' not in exclude_apply:
        apply_flags.setdefault('return_dimension_names', True)

    applies = []
    for gb in groupby:
        dimension = gb['dimension']
        aggregators = gb['aggregators']
        aggregator_list = []
        for aggregator in aggregators:
            if aggregator == 'avg':
                aggregator = 'mean'
            aggregator_list.append({'fn': aggregator})

        applies.append({
            'fn': 'groupby_pandas',
            'kwargs': {
                'eliminate_dimension': dimension,
                'aggregators': aggregator_list
            }
        })

    if dimensions_db:
        dimensions_db.del_ephemeral_dimensions()

    return cube_map(files, result_dimensions=result_dimensions,
            exclude_dimensions=exclude_dimensions,
            required_measures=required_measures, slice_defs=other_slices,
            apply_flags=apply_flags, applies=applies,
            dimensions_db=dimensions_db)

def cube_map(files, result_dimensions=None,
            optional_dimensions=None, exclude_dimensions=None,
            required_measures=None, slice_defs=None,
            # Note: apply_flags is depricated. Start using applies.
            applies=None, apply_flags=None,
            dimensions_db=None, result_step=None,
            include_measures=None):
    tt = TrackTimes()

    if dimensions_db is None:
        # If a previously loaded dimensions_db isn't passed in, load it.
        prof_log(tt.start('load-db', 'cube-map-loading-dimensions-db-start'))
        dimensions_db = deepy.dimensions.DimensionsDB(redis_backed=True)
        prof_log(tt.end('load-db', 'cube-map-loading-dimensions-db-end'))

    if applies is None:
        applies = []
    if apply_flags is not None and isinstance(apply_flags, dict):
        # Convert apply_flags if used.
        for fn, app_args in apply_flags.items():
            # Handle multiple of the same apply function
            if isinstance(app_args, list) and any(isinstance(app_arg, list) for app_arg in app_args):
                for app_arg in app_args:
                    applies.append({'fn':fn, 'args': app_arg})
            else:
                applies.append({'fn':fn, 'args': app_args})

    qd = {'dimensions':result_dimensions,
           'slices':slice_defs,
           'applies':applies,
           'result_step': result_step,
           'required_measures': required_measures,
           'include_measures': include_measures,
           'optional_dimensions': optional_dimensions,
           'exclude_dimensions': exclude_dimensions}
    cq = CubeQuery(qd, ddb=dimensions_db)

    query_cube = cube_map_queries([cq], cube_files=files, dimensions_db=dimensions_db)
    assert len(query_cube) <= 1

    if query_cube:
        (query, cube) = query_cube[0]
    else:
        cube = CubeHash()
    return cube

class CubeQuery(object):
    '''
        E.g.
        {
          "applies": [
            {"args": [ "months", "95" ],
              "fn": "time_dist",
              "kwargs": {}
            },
            {
              "args": [ "cdn" ],
              "fn": "post_slice"
            }
          ],
          "dimensions": [ "timestamp", "cdn" ],
          "input_files": ['file1', 'file2'],
          "input_file_glob": "$(cubes_dir)/drill1/hours/cube.%Y-%m-*.npz",
          "slices": [
            { "dimension": "cdn", "type": "include", "values": [ 'Akamai', 'Limelight'] }
          ]
        }
    '''

    def __init__(self, query_dict=None, ddb=None, ts=None, name=None, now=None, prev_month_days=None):
        '''
        query_dict, see class docs
        ddb = dim db
        ts = timestamp for input_file_glob
        name = override name in query_dict

        Perhaps ts/timestep should not be part of query and files should only be passed in
        They are used for bundle2.py right now
        '''

        assert ddb is not None
        self.query_dict = query_dict
        self.ddb = ddb
        self.ts = ts
        self.name = name

        self.result_dimensions = None
        self.optional_dimensions = None
        self.exclude_dimensions = None
        self.required_measures = None
        self.include_measures = None
        self.slice_defs = None
        self.applies = None
        self.arg_joins = None
        self.input_files = None
        self.result_step = None
        self.cube = None # for ui to use with drill
        self.target = None
        self.sum_all = False # rollup all even timestamp
        self.use_bundle_rollup = False
        self.now = now
        self.prev_month_days = prev_month_days
        self.arg_join_expand = arg_join_expand
 
        # Separate to handle various ways of initing.
        if query_dict is not None:
            self._init_query_dict(query_dict)
        else:
            # Invalid parameters
            raise ValueError('No query specified')
        # XXX make query_url parameter to create query from url format.
        # nice compact way to define simple queries.



    def set_required_measures(self, required_measures):
        self.required_measures = required_measures

    # XXX Handle optional dimensions.
    def to_url(self):
        '''
        returns parts of a query to be used by deepcube.js
        '''
        url = []
        if self.result_dimension_ids:
            url.append('dimensions=%s' % (','.join(self.result_dimension_ids)))

        for ad in self.apply_dicts:
            fn = ad.get('fn')
            args = ad.get('args', [])
            if type(args) != type([]):
                args = [args]
            if fn and ad.get('url_apply', True):
                a = 'apply={fn}({args})'.format(fn=fn, args=','.join(map(str,args)))
                url.append(a)

        for sd in self.slice_def_dicts:
            d = sd['dimension']
            t = sd.get('type')
            vals = sd.get('values')
            if t == 'range_include':
                if type(vals) == type([]):
                    start = deepy.slice_def.SliceDef.parse_val(d, vals[0])
                    end = deepy.slice_def.SliceDef.parse_val(d, vals[-1])
                else:
                    start = vals['start']
                    end = vals['end']
                v = '{}:{}'.format(start, end)
            else:
                svs = set()
                for val in vals:
                    svs.add(deepy.slice_def.SliceDef.parse_val(d, val))
                v = ','.join(map(str,list(svs)))

            op = ''
            if sd['type'] == 'exclude':
                op = '!'
            s = 'slice={dim}{op}({vals})'.format(dim=d, op=op, vals=v)
            url.append(s)

        return url

    def setup_ids(self):
        '''
        translate dimension name strings to dimension ids
        '''
        self.result_dimension_ids = get_dim_list_ids(self.result_dimensions, self.ddb)
        self.optional_dimension_ids = get_dim_list_ids(self.optional_dimensions, self.ddb)
        self.exclude_dimension_ids = get_dim_list_ids(self.exclude_dimensions, self.ddb)
        self.slice_dim_ids = _cube_map_process_get_slice_dim_ids(self.slice_defs, self.ddb)
        self._set_apply_dim_ids()
        self._set_input_dim_ids()

    def _replace_all(self, subst_dict, apply_args):
        for arg in apply_args:
            if arg in subst_dict:
                for p in subst_dict[arg].split(','):
                    yield p.strip()
            else:
                yield arg

    def make_arg_join_subst_dict(self):
        self.arg_join_subst_dict = {}
        if self.arg_joins is None:
            return
        self.arg_join_subst_dict = {}
        ts = deepy.timerange.parse_datetime(self.ts, '-')
        for aj_key, aj_file in self.arg_joins.iteritems():
            aj_file = deepy.build.util.deepy_substitution(
                deepy.build.util.basic_substitution(aj_file, ts),
                deepy.cfg)
            val = self.arg_join_expand(aj_file)
            # Clean this up; avoid jumping into and out of str format...
            if val is not None:
                self.arg_join_subst_dict['<{}>'.format(aj_key)] = val
            else:
                raise Exception('Arg join failed {}:{}'.format(aj_key, aj_file))

    def subst_arg_joins_slice(self):
        if not self.arg_join_subst_dict:
            return
        if self.slice_def_dicts:
            for sl in self.slice_def_dicts:
                if type(sl.get('values')) in (list, set):
                    sl['values'] = \
                      [a for a in self._replace_all(self.arg_join_subst_dict,
                                                    sl['values'])]

    def subst_arg_joins_apply(self):
        if not self.arg_join_subst_dict:
            return
        if self.apply_dicts:
            for appl in self.apply_dicts:
                if type(appl.get('args')) in (list, set):
                    appl['args'] = \
                      [a for a in self._replace_all(self.arg_join_subst_dict,
                                                    appl['args'])]

    def _init_query_dict(self, query_dict):
        # Pull out various query parameters.
        self.result_dimensions = query_dict.get('dimensions')
        self.optional_dimensions = query_dict.get('optional_dimensions')
        self.exclude_dimensions = query_dict.get('exclude_dimensions')
        self.required_measures = query_dict.get('required_measures')
        self.include_measures = query_dict.get('include_measures')
        self.result_step = query_dict.get('result_step')
        self.target = query_dict.get('target')
        self.sum_all = query_dict.get('sum_all')
        self.timestep = query_dict.get('timestep')
        self.use_bundle_rollup = query_dict.get('use_bundle_rollup')
        self.arg_joins = query_dict.get('arg_joins')
        self.make_arg_join_subst_dict()
        if self.target is not None and self.ts is not None:
            ts = deepy.timerange.parse_datetime(self.ts, '-')
            self.target = time.strftime(self.target, time.gmtime(ts))
            self.target = self.target.replace('$(cubes_dir)', deepy.cfg.cubes_dir)
        if self.name is None:
            self.name = query_dict.get('name', str(uuid.uuid4()))
        self.slice_def_dicts = query_dict.get('slices')
        if self.slice_def_dicts is None:
            # Handle missing or explicitly set to None.
            self.slice_def_dicts = []
        self.subst_arg_joins_slice()
        self.slice_defs = []
        for sdd in self.slice_def_dicts:
            slice_def = deepy.slice_def.SliceDef.from_dict(sdd)
            if slice_def is None:
                raise ValueError
            self.slice_defs.append(slice_def)
        self.apply_dicts = query_dict.get('applies')
        if self.apply_dicts is None:
            self.apply_dicts = []
        self.apply_dicts += self._applies_from_dims(self.result_dimensions,
                self.ddb)
        slice_dims = [s['dimension'] for s in self.slice_def_dicts]
        self.apply_dicts += self._applies_from_dims(slice_dims, self.ddb)
        self.subst_arg_joins_apply()
        self.applies = self._setup_applies(self.apply_dicts, self.ddb)
        if 'input_files' in query_dict:
            self.input_files = query_dict['input_files']
        elif 'input_file_glob' in query_dict:
            ifg = self.query_dict['input_file_glob']
            ifg = ifg.replace('$(cubes_dir)', deepy.cfg.cubes_dir)
            self.input_files = setup_input_file_glob(ifg, self.ts, self.timestep, self.now, self.prev_month_days)
        elif 'input_file_glob_simple' in query_dict:
            # Just do a regular glob.
            ifg = self.query_dict['input_file_glob_simple']
            self.input_files = deepy.store.ls_glob_simple(ifg)


        # find cube name "drill1" in /pipedream/cache/cubes/drill1/hours/cube....h5
        if self.input_files:
            self.input_files.sort()
            get_base = lambda x: os.path.basename(os.path.dirname(os.path.dirname(x)))
            self.cube = list(set(map(get_base, self.input_files)))[0] # assume they are all the same

        self.setup_ids()

        if self.result_step is None:
            self.result_step = get_result_step(self)



    # Create groupby_attribute applies from dimensions:key_path.
    # E.g., peer.remote:name
    # Also, detects groupby_attribute_connector dimensions.
    def _applies_from_dims(self, dim_list, ddb):
        if dim_list is None:
            return []
        agg_applies = []
        for dim in dim_list:
            # Helpers return dict if success, else None.
            agg = self._applies_from_groupby_attribute(dim)
            if agg is not None:
                agg_applies.append(agg)
                continue
            agg = self._applies_from_groupby_attribute_connector(dim, ddb)
            if agg is not None:
                agg_applies.append(agg)
                continue
            agg = self._applies_from_aggregate_connector(dim, ddb)
            if agg is not None:
                agg_applies.append(agg)
                continue

        return agg_applies

    def _applies_from_groupby_attribute(self, dim):
        # Parse out key_path if it exists.
        dim_parts = dim.split(':', 1)
        url_apply = deepy.cube_apply.ApplyGroupbyAttribute.url_apply
        if len(dim_parts) == 2:
            # groupby_attribute
            agg = {
                    "fn": "groupby_attribute",
                    "url_apply": url_apply,
                    "kwargs": {
                        "input_dimension": dim_parts[0],
                        "output_dimension": dim,
                        "key_path": dim_parts[1]
                        }
                    }
            return agg
        return None

    def _applies_from_groupby_attribute_connector(self, dim, ddb):
        # Check for groupby_attribute_connector dimension. Identify via
        # builders for now.
        bldr = deepy.cube_apply.ApplyGroupbyAttributeConnector.builder_id
        url_apply = deepy.cube_apply.ApplyGroupbyAttributeConnector.url_apply
        dim_info = ddb.get_by_name_or_id(dim)
        if dim_info is not None:
            builders = dim_info.get('builders')
            if builders is not None and bldr in builders:
                agg = {
                        "fn": "groupby_attribute_connector",
                        "url_apply": url_apply,
                        "kwargs": {
                            "output_dimension": dim
                            }
                        }
                return agg
        return None

    def _applies_from_aggregate_connector(self, dimension, dimensions_db):
        builder_id = deepy.cube_apply.ApplyAggregateConnector.builder_id
        dimension_info = dimensions_db.get_by_name_or_id(dimension)
        if dimension_info is not None:
            builders = dimension_info.get('builders')
            if builders is not None and builder_id in builders:
                agg = {
                        'fn': "aggregate_connector",
                        'kwargs': {
                            'aggregate_dimension_name': dimension
                        }
                      }
                return agg
        else:
            return None

    def __str__(self):
        return 'dims:{dims}\nslices:{slices}\napplies:{applies}\nfiles:{files}'.format(
                dims=self.result_dimensions,
                slices=self.slice_defs,
                applies=self.applies,
                files=self.input_files)

    # Returns dict of applies. keys are apply function names. Values are
    # either the apply object, or a list of apply objects. (Some apply
    # functions can be used more than once per query.)
    def _setup_applies(self, apply_dicts, ddb):
        applies = {}
        applyset = {x.get('fn') for x in apply_dicts}

        if 'time_dist' in applyset and 'measure_fixup' in applyset:
            applyset.remove('measure_fixup')

        for applyfn in apply_dicts:
            fn = applyfn.get('fn')

            # don't setup measure_fixup if time_dist
            if fn not in applyset:
                continue

            if fn:
                apply_args = applyfn.get('args', [])
                if type(apply_args) not in [types.TupleType, types.ListType]:
                    apply_args = [apply_args]
                apply_kwargs = applyfn.get('kwargs', {})

                ao = deepy.cube_apply.make_apply(fn, apply_args, apply_kwargs,
                        ddb)
                if ao is None:
                    raise QueryError('Invalid apply: %s ' % fn)
                if ao.is_conflict(applyset):
                    func_str = ' '.join(map(str, list(applyset)))
                    raise QueryError('Invalid apply combination: %s ' % func_str)

                # Don't like that we save a list or a single object. Should
                # just be consistent and always use list. Code that runs
                # applies would need to be cleaned up.
                if ao.allow_multiple:
                    applies[fn] = applies.get(fn, []) + [ao]
                else:
                    applies[fn] = ao

        return applies

    def iter_applies(self):
        # Ugly because apply values can be apply object or list of apply
        # objects.
        for apply_fn, apply_list in self.applies.iteritems():
            if not isinstance(apply_list, list):
                apply_list = [apply_list]
            for apply_obj in apply_list:
                yield apply_fn, apply_obj

    # Get the dimensions required by the applies.
    def _set_input_dim_ids(self):
        self.apply_dim_ids_in = []
        self.apply_dim_ids_out = []
        for apply_fn, apply_obj in self.iter_applies():
            self.apply_dim_ids_in = funcy.distinct(self.apply_dim_ids_in + apply_obj.get_input_dim_ids())
            self.apply_dim_ids_out = funcy.distinct(self.apply_dim_ids_out + apply_obj.get_output_dim_ids())

    def _set_apply_dim_ids(self):
        self.post_rollup_dim_ids = []
        for apply_fn, apply_obj in self.iter_applies():
            self.post_rollup_dim_ids = funcy.distinct( self.post_rollup_dim_ids + apply_obj.get_apply_dim_ids())

def get_rule_queries(rule_name, ts, dimensions_db, now=None):
    if now is None:
        now = datetime.datetime.now()

    # round to 5 minutes
    now = now - datetime.timedelta(minutes=now.minute % 5)

    rules_db = deepy.build.util.construct_rules()
    rule = rules_db[rule_name]

    query_strs = rule.get('queries', {})
    prev_month_days = rule.get('prev_month_days')

    queries = [CubeQuery(query, name=name, ddb=dimensions_db, ts=ts, now=now, prev_month_days=prev_month_days)
                for name,query in query_strs.items()]

    return queries

def find_ts_start_end(str_timestamp):
    ts, period = deepy.timerange.parse_datetime_timeperiod(str_timestamp, time_sep='-')
    dt = datetime.datetime.utcfromtimestamp(ts)

    now = datetime.datetime.utcnow()

    last_hour = 23

    if period == 'year':
        _, last_day_month = calendar.monthrange(dt.year, 1)
        start = datetime.datetime(dt.year, 1, 1, 0, 0)
        end = datetime.datetime(dt.year, 12, 31, last_hour, 59)

    elif period == 'month':
        _, last_day_month = calendar.monthrange(dt.year, dt.month)

        start = datetime.datetime(dt.year, dt.month, 1, 0, 0)
        end = datetime.datetime(dt.year, dt.month, last_day_month, last_hour, 59)
    elif period == 'day':
        start = datetime.datetime(dt.year, dt.month, dt.day, 0, 0)
        end = datetime.datetime(dt.year, dt.month, dt.day, last_hour, 59)
    elif period == 'hour':
        start = datetime.datetime(dt.year, dt.month, dt.day, dt.hour, 0)
        end = datetime.datetime(dt.year, dt.month, dt.day, dt.hour, 59)
    else:
        assert False

    #Sanity check to prevent looking into the future. If start is in the future skip this check
    #ci-1542
#    if now > start and now > end:
#        end = now

    return start, end

def guess_timestep(input_file_glob):
    dname = os.path.dirname(input_file_glob)
    dbase = os.path.basename(dname)

    if dbase in ['seconds', 'minutes', 'hours', 'days']:
        return dbase
    else:
        return None

def setup_input_file_glob(input_file_glob, timestamp, timestep, now=None, prev_month_days=None):
    '''
    what is the step of the file?
        file freq/timestep -> 5 minute, hour, files
        specify timestep explicitly so we don't need to guess
        glob needs to match up

    over what time period
        2013-11 -> start/end of month
        2013-11-10 -> start/end of day
        range -> use the range
    '''
    outfns = []
    if not timestep:
        timestep = guess_timestep(input_file_glob)

    ts_lookup = {
        'seconds': ('10sec', '%Y-%m-%d-%H-%M-%S'),
        'minutes': ('5Min', '%Y-%m-%d-%H-%M'),
        'hours': ('h', '%Y-%m-%d-%H'),
        'days': ('D', '%Y-%m-%d')}

    assert timestep in ts_lookup

    freq, time_format = ts_lookup.get(timestep)
    start, end = find_ts_start_end(timestamp)

    # for months, go back more days than just the first to show
    # more than the first day on the first
    if now is not None and prev_month_days is not None:
        days_from_month_start = (now - start).days
        if days_from_month_start < prev_month_days:
             start = now - datetime.timedelta(days=prev_month_days-1)

    dname = os.path.dirname(input_file_glob)
    dr = pd.date_range(start, end, freq=freq)
    for d in dr:
        t = d.strftime('cube.' + time_format)
        fn = os.path.join(dname, t)
        outfns.append(fn + '.h5')

    return outfns

def get_result_step(query):
    result_step = None

    timestep_change = query.applies.get('timestep_change')
    if timestep_change:
        result_step = timestep_change.get_step()

    time_dist = query.applies.get('time_dist')
    if time_dist:
        result_step = time_dist.get_step()

    return result_step

def get_dim_list_ids(result_dimensions, dimensions_db):

    result_dimension_ids = None
    if result_dimensions is not None:
        # Translate dimension names.
        result_dimension_ids = []
        for dim_name in result_dimensions:
            conv_id = dimensions_db.get_id_by_name(dim_name)
            if conv_id is None and dim_name not in deepy.dimensions.DONT_CACHE_DIMENSIONS:
                # See if this is really a number
                if not dimensions_db.get_by_id(dim_name):
                    log.warn("bad-dimension-name-get_dim_list_ids (skipping) %s" % dim_name)
                    continue

            # If name lookup failed, assume it was already an id.
            dim_id = conv_id if conv_id is not None else dim_name
            if dim_id not in result_dimension_ids: # no duplicate dimensions please ...
                result_dimension_ids.append(dim_id)
    return result_dimension_ids


# NOTE: This is determining what dimensions should be *loaded*. Individual
# queries will later select subsets based on what was specified in the query.
def union_query_dims_meas(queries):
    # get union of all dims/slice ids needed to do all cube queries
    req_dims = []
    req_dims_none_override = False
    bad_queries = []
    opt_dims = []
    req_measures = []
    incl_measures = []
    slice_dims = []
    apply_dims = []

    for query in queries:
        if query.result_dimension_ids is not None:
            req_dims = funcy.distinct(req_dims + query.result_dimension_ids)
        else:
            req_dims_none_override = True
            bad_queries.append(query.name)

        if query.optional_dimension_ids:
            opt_dims = funcy.distinct(opt_dims + query.optional_dimension_ids)

        if query.slice_dim_ids:
            slice_dims = funcy.distinct(slice_dims + query.slice_dim_ids)

        if query.apply_dim_ids_in:
            apply_dims = funcy.distinct(apply_dims + query.apply_dim_ids_in)

        if query.required_measures:
            req_measures = funcy.distinct(req_measures + query.required_measures)

        if query.include_measures:
            incl_measures = funcy.distinct(incl_measures + query.include_measures)


    if len(set(req_dims) & set(opt_dims)) != 0:
        # Not handling when multiple queries mix the same dimensions as
        # required and optional.
        raise QueryError('Dimensions are required and optional: %s' %
                (', '.join(funcy.distinct(req_dims + opt_dims))))

    if req_dims_none_override and len(req_dims) != 0:
        # Not handling when multiple queries mix specifying and not
        # specifying dimensions.
        raise QueryError('Dimension request mismatch on queries: %s' %
                (', '.join(bad_queries)))

    if len(req_dims) != 0:
        # if we have required any dimensions, union them with the slices
        req_dims = funcy.distinct(req_dims + slice_dims + apply_dims)
    else:
        # otherwise None means request all dims from first input cube
        req_dims = None

    if len(opt_dims) != 0:
        opt_dims = list(opt_dims)
    else:
        opt_dims = None

    if req_measures:
        req_measures = list(req_measures)
    else:
        req_measures = None # need this?

    if incl_measures:
        incl_measures = list(incl_measures)
    else:
        incl_measures = None # need this?

    return req_dims, opt_dims, req_measures, incl_measures


def union_files(queries, cube_files):
    '''
    union by file names and sum_all,
    sum_all doesn't mesh good with other queries since it doesn't require any dimensions
    '''
    if cube_files:
        filesets = [(tuple(cube_files), queries)]
    else:
        # XXX match exact files for now, could do subsets too ..
        _filesets = {}
        for i, q in enumerate(queries):
            if q.input_files is not None:
                k = (q.sum_all, tuple(q.input_files))
                _filesets[k] = _filesets.get(k, []) + [q]
        filesets = [(ifs,qs) for (sa, ifs), qs in _filesets.items()]
    return filesets


def other_ext(fn):
    if fn.endswith('.h5'):
        return fn.replace('.h5', '.npz')
    elif fn.endswith('.npz'):
        return fn.replace('.npz', '.h5')


def _cube_map_query_fileset(queries, cube_files, dimensions_db):
    tt = TrackTimes()
    prof_log(tt.start('_cube_map_query_fileset', '_cube_map_query_fileset-start'))


    results = {}
    req_dims, opt_dims, req_measures, incl_measures = union_query_dims_meas(queries)

    pps = [] # created every time, this is for fall through
    h5_or_npz = set()
    qnames = ' '.join([str(q.name) for q in queries])

    prof_log(tt.start('queries', '_cube_map_query_fileset-queries-start'))
    for cube_file in cube_files:

        # check for dups, only do one of h5 or npz
        base, ext = os.path.splitext(cube_file)
        #if base in h5_or_npz:
        #    log.info('skipping-already-processed-npz/h5-base {} {}'.format(base, h5_or_npz))
        #    continue

        h5_or_npz.add(base)

        prof_log(tt.start(cube_file, 'load-cube-start {} {}'.format(cube_file, qnames)))
        cube_in = load_cube_file(cube_file, req_dims, opt_dims, req_measures, dimensions_db, incl_measures)
        prof_log(tt.end(cube_file, 'load-cube-end {} {}'.format(cube_file, qnames)))

        if cube_in is None:
            prof_log('cube-load-failed:%s', cube_file)
            continue
        if not cube_in.measure_arrays or len(cube_in.measure_arrays[0]) == 0:
            prof_log('cube-is-empty:%s', cube_file)
            continue

        if (req_measures is None and cube_in.measures == measures_sum_old):
            # XXX Hack to handle transition to new cube_from_subflow. New
            # cubes only have sent/recv, and other measures were always
            # ignored. For future, may be better to have explicit measures
            # set in query (-M arg to cube_op).
            cube_in.reset_measures_hack()

        pps = [] # created every time, only use last set
        for i, query in enumerate(queries):
            prof_log(tt.start('qb' + query.name, 'query-begin {}'.format(query.name)))
            start_ru = deepy.util.getrusage()

            cube_result = results.get(i)
            if cube_result is None:
                cube_result = setup_cube_result(query, cube_in)
                results[i] = cube_result

            # setup url history
            cube_urls = cube_in.meta.get('urls')
            if cube_urls:
                # copy in previous history
                for cube_name, url in cube_urls:
                    cube_result.urls[cube_name] = url
            cube_result.urls[query.cube] = query.to_url()

            _process_query(query, cube_in, cube_result, start_ru)
            finalize_func = partial(_finalize_query, query, cube_result)
            pps.append((query, finalize_func))
            prof_log(tt.end('qb' + query.name, 'query-end {}'.format(query.name)))
    prof_log(tt.end('queries', '_cube_map_query_fileset-queries-end'))

    prof_log(tt.start('queries', '_cube_map_query_fileset-finalize-start'))
    out = []
    for query, pp in pps:

        fc = finalized_cube = pp()

        fc.cube = query.cube
        fc.query = query.query_dict
        fc.url = query.to_url()

        out.append((query, finalized_cube))
    prof_log(tt.end('queries', '_cube_map_query_fileset-finalize-end'))
    prof_log(tt.end('_cube_map_query_fileset', '_cube_map_query_fileset-end'))
    return out

# Returns list of (query, result_cube) pairs.
def cube_map_queries(all_queries, dimensions_db=None, cube_files=None):

    cube_filesets = union_files(all_queries, cube_files)
    tt = TrackTimes()
    prof_log(tt.start('total', 'cube-map-queries-start'))

    if cube_files == None:
        cube_files = []

    if dimensions_db is None:
        # If a previously loaded dimensions_db isn't passed in, load it.
        prof_log(tt.start('load-db', 'cube-map-queries-loading-dimensions-db-start'))
        dimensions_db = deepy.dimensions.DimensionsDB(redis_backed=True)
        prof_log(tt.end('load-db', 'cube-map-queries-loading-dimensions-db-end'))

    results = []
    for cube_files, queries in cube_filesets:
        qnames = ' '.join([str(q.name) for q in queries])
        #log.info('querying-files {}'.format(qnames))
        res = _cube_map_query_fileset(queries, cube_files, dimensions_db)
        #log.info('querying-files-finished {}'.format(qnames))
        results += res

    prof_log(tt.end('total', 'cube-map-queries-end'))
    return results


def setup_cube_result(query, cube_in):
    # Note: The result cube dimensions are ids. They stay as ids throughout
    # unless return_dimension_names() is specified.

    # Set result dimensions to required plus optional dimensions. Special
    # optional handling will be done in the Loader and finalize steps.
    if (query.result_dimension_ids is None and
            query.optional_dimension_ids is None):
        # Inherit required from first input cube. Use file_dimensions since
        # other queries may have added fake optional dimensions to
        # cube_in.dimensions.
        result_dims = cube_in.file_dimensions
    elif (query.result_dimension_ids is None and
            query.optional_dimension_ids is not None):
        # Dims specified by optional.
        result_dims = query.optional_dimension_ids
    elif (query.result_dimension_ids is not None and
            query.optional_dimension_ids is None):
        # Required specified in query. Preserve that ordering.
        result_dims = query.result_dimension_ids
    elif (query.result_dimension_ids is not None and
            query.optional_dimension_ids is not None):
        # Both specified, can't overlap. Otherwise use all.
        isect_req_opt = funcy.distinct(query.result_dimension_ids +
                query.optional_dimension_ids)
        if len(isect_req_opt) != 0:
            # Dimension can't be both required and optional.
            raise QueryError('Dimensions are required and optional: %s' %
                    (', '.join(isect_req_opt)))
        result_dims = query.result_dimension_ids + query.optional_dimension_ids

    # Apply exclude, preserve order from above.
    if query.exclude_dimension_ids is not None:
        ex_set = set(query.exclude_dimension_ids)
        result_dims = [x for x in result_dims if x not in ex_set]

    if result_dims:
        output_dimensions = funcy.distinct(result_dims + query.post_rollup_dim_ids)
    else:
        output_dimensions = result_dims
    cube_result = CubeHash(dimensions=output_dimensions, step=query.result_step,
            dim_db=query.ddb)

    # Set measures based on first input cube.
    if cube_result.measures is None:
        cube_result.measures = cube_in.measures

    # If no step was specified, inherit it from the input cube.
    if cube_result.time['step'] is None:
        cube_result.time['step'] = cube_in.time['step']

    return cube_result

query_warning_count = 0
def load_cube_file(cube_file, required_dimensions, optional_dimensions,
                   required_measures, dimensions_db, include_measures):
    cube_in = None
    try:
        cube_in = CubeLoader(cube_file,
                required_dimension_ids=required_dimensions,
                optional_dimension_ids=optional_dimensions,
                required_measures=required_measures,
                dimensions_db=dimensions_db,
                include_measures=include_measures)
    except IOError:
        pass
    except QueryWarning as e:
        # There's no need to spam the logs with 1000's of these warnings
        # (unless debug mode is specified)
        global query_warning_count
        query_warning_count += 1

        if query_warning_count == 10:
            log.warn('query-warning ...')
            log_function = log.debug
        elif query_warning_count > 10:
            log_function = log.debug
        else:
            log_function = log.warn

        # Catch missing dimensions, but don't fail. Dimension may be
        # in later cube of same query. Should possibly error out if
        # no good cube is ever found.
        log_function('query-warning %s' % (e))

        # FIXME add back in
        # cube_result.query_warnings.append(e.get_dict())
    return cube_in


def _process_query(query, cube_in, cube_result, start_ru):
    # Apply group_other to axes.
    # XXX It seems like this would play badly with multiple queries??

    # FIXME this only works with one cube being read in ie month
    if cube_result.dimensions is None: # no dimensions from a sum_all
        cube_result.measure_arrays = cube_in.measure_arrays
        return

    group_other_list = query.applies.get('group_other', [])
    if len(group_other_list) > 0:
        for group_other in group_other_list:
            if group_other.dim_id not in cube_in.dimensions:
                # Just skip if dimension isn't in the cube.
                continue
            other_id = deepy.dimensions.special_positions['Other']
            cube_in.remap_positions(group_other.dim_id, other_id,
                    group_other.exclude_pos_ids, 'exclude')

    timestep_change = query.applies.get('timestep_change')
    if timestep_change:
        timestep_change_arg = timestep_change
    else:
        timestep_change_arg = None

    do_slice_negate = True if 'slice_negate' in query.applies else False

    try:
        tt = TrackTimes()
        prof_log(tt.start('apply', 'process_cube_in-start {}'.format(query.name)))
        for apply_fn, apply_obj in query.iter_applies():
            # Not sure I like mixing this into the main rollup path. Nice for
            # performance, but gets messy.
            prof_log(tt.end('apply', 'process_cube_in-apply-start {} {}'.format(apply_obj.apply_name, query.name)))
            apply_obj.process_cube_in(cube_in)
            prof_log(tt.end('apply', 'process_cube_in-apply-end {} {}'.format(apply_obj.apply_name, query.name)))
        prof_log(tt.end('apply', 'process_cube_in-start {}'.format(query.name)))

        # The actual processing
        _cube_map_process(cube_result, cube_in, query,
                start_ru, timestep_change_arg, do_slice_negate=do_slice_negate)
    except QueryWarning as e:
        # There's no need to spam the logs with 1000's of these warnings
        # (unless debug mode is specified)
        global query_warning_count
        query_warning_count += 1

        if query_warning_count == 10:
            log.warn('query-warning ...')
            log_function = log.debug
        elif query_warning_count > 10:
            log_function = log.debug
        else:
            log_function = log.warn

        # Catch missing dimensions, but don't fail. Dimension may be
        # in later cube of same query. Should possibly error out if
        # no good cube is ever found.
        log_function('query-warning %s' % (e))
        cube_result.query_warnings.append(e.get_dict())
        return

def _finalize_query(query, cube_result):
    tt = TrackTimes()
    prof_log(tt.start('_finalize_query', '_finalize_query-start'))
    #####
    # Post-processing applies
    #

    # bundle rollup, could move into an apply
    if cube_result.use_bundle_rollup:
        log.info('finalize-bundle {}'.format(query.name))
        cube_result.finalize_bundle()
        log.info('finalize-bundle-finished {}'.format(query.name))
    else:
        if cube_result.dimensions is None and cube_result.measure_arrays:
            # reading cube that was result of sum_all
            pass
        else:
            # Tells CubeHash rollup is done.
            cube_result.finalize()

    apply_start = time.time()

    # Applies that require CubeHash must come first.
    asn_eval_aspath_expand = query.applies.get('asn_eval_aspath_expand')
    if asn_eval_aspath_expand:
        cube_result = asn_eval_aspath_expand.apply(cube_result)

    aggregate_connector = query.applies.get('aggregate_connector')
    if aggregate_connector:
        cube_result = aggregate_connector.apply(cube_result)

    remove_empty_fake = query.applies.get('remove_empty_fake')
    if remove_empty_fake:
        cube_result = remove_empty_fake.apply(cube_result)

    time_dist = query.applies.get('time_dist')
    do_measure_fixup = True
    if time_dist:
        do_measure_fixup = False
        cube_result = time_dist.apply(cube_result)

    # Need to do this here, before measure_fixup fiddles with the names
    groupby_pandas_list = query.applies.get('groupby_pandas', [])
    for groupby_pandas in groupby_pandas_list:
        cube_result = groupby_pandas.apply(cube_result)

    costing = query.applies.get('costing', None)
    if costing is not None:
        cube_result = costing.apply(cube_result)

    crowmile_distance_measure = query.applies.get('crowmile_distance_measure', None)
    if crowmile_distance_measure is not None:
        cube_result = crowmile_distance_measure.apply(cube_result)

    crowmile_distance = query.applies.get('crowmile_distance', None)
    if crowmile_distance is not None:
        cube_result = crowmile_distance.apply(cube_result)

    # Data injectors
    for data_injector_class in deepy.cube_apply.ApplyBaseDataInjector.__subclasses__():
        name = data_injector_class.apply_name
        data_injector_apply = query.applies.get(name)
        if data_injector_apply:
            data_injector_apply.apply(cube_result)

    measure_fixup = query.applies.get('measure_fixup')
    if measure_fixup and do_measure_fixup:
        # Clean up measures, do bps, etc. for output to UI/API
        cube_result = measure_fixup.apply(cube_result)


    # Perform secondary rollup
    # If the list of dimensions present is different than those requested in query, do a final rollup
    if query.result_dimension_ids and ((set(cube_result.dimensions) | set(query.result_dimension_ids)) != set(query.result_dimension_ids)) and cube_result._groupby:

        new_dimension_arrays = []
        new_dimensions = []
        drop_axes = set([])
        for i in xrange(len(cube_result.dimensions)):
            if not cube_result.dimensions[i] in query.result_dimension_ids:
                drop_axes.add(i)
                continue
            new_dimension_arrays.append(cube_result.dimension_arrays[i])
            new_dimensions.append(cube_result.dimensions[i])
        cube_result.dimensions = new_dimensions
        cube_result.dimension_arrays = new_dimension_arrays
        cube_result.positions = cube_result.dimension_arrays # So the _cube_map functions below work..
        cvt_positions, cvt_axes = _cube_map_process_setup_dimensions(cube_result,
                cube_result, timestep_change=None)
        meas_arrs = [m.astype(deepy.cube_cy.measure_dtype) for m in
                     _cube_map_process_setup_measures(cube_result, cube_result)]
        selected_indices = np.ones(cube_result.positions[0].shape, dtype=bool)
        cube_result.rollup(cvt_positions, meas_arrs, cvt_axes, selected_indices)
        old_axes = cube_result.axes
        cube_result.axes = []
        for idx, axis in enumerate(old_axes):
            if idx not in drop_axes:
                cube_result.axes.append(axis)
        # Done with secondary rollup


    # Do before sort so we can sort on names.
    convert_to_names = query.applies.get('convert_to_names')
    if convert_to_names:
        cube_result = convert_to_names.apply(cube_result)

    return_dimension_names = query.applies.get('return_dimension_names')
    if return_dimension_names:
        cube_result = return_dimension_names.apply(cube_result, query.result_dimensions)

    sorts = query.applies.get('sort', [])
    if sorts:
        # Support multiple sort statements
        if isinstance(sorts, list):
            for sort in reversed(sorts):
                cube_result = sort.apply(cube_result)
        else:
            cube_result = sorts.apply(cube_result)

    limit = query.applies.get('limit')
    if limit:
        cube_result = limit.apply(cube_result)

    # This needs to come after other regular applies, or at least after
    # any applies that will use dim_db. It removes its ephemeral dimension
    # from dim_db, so dim_db doesn't grow unboundedly (yes, that's a word).
    groupby_attribute_list = query.applies.get('groupby_attribute', [])
    for groupby_attribute in groupby_attribute_list:
        cube_result = groupby_attribute.apply(cube_result)

    # This should be last as the output is a non-standard result.
    post_slice = query.applies.get('post_slice')
    if post_slice:
        # Note, this changes cube_result to a dict of cubes.
        cube_result = post_slice.apply(cube_result)

    apply_end = time.time()
    msg = ('cube-map-apply-done time=%.2fs' % (apply_end - apply_start))
    if apply_end - apply_start > 2:
        log.warn(msg)
    else:
        log.debug(msg)
    log.debug(msg)

    #log.info('cube-map-done (%2.1f seconds)' % (time.time() - apply_start))

    prof_log(tt.end('_finalize_query', '_finalize_query-end'))
    return cube_result


# cube_in is a CubeLoader
# cube_result is a CubeHash
# raises exceptions on error.
def _cube_map_process(cube_result, cube_in, query,
        start_ru, timestep_change, do_slice_negate=False):
    tt = TrackTimes()
    prof_log(tt.start('total', 'cube-map-process-start {}'.format(query.name)))
    process_start = time.time()

    # Setup and verify input dimensions/positions and measures.
    cvt_positions, cvt_axes = _cube_map_process_setup_dimensions(cube_result,
            cube_in, timestep_change)
    meas_arrs = _cube_map_process_setup_measures(cube_result, cube_in)

    # Slice
    selected_indices = _cube_map_process_slice(cube_in, query.slice_defs,
            query.ddb, do_slice_negate)

    # At this point, we've verified that the input cube has the necessary
    # dimensions and measures. Wait until now to update valid_seconds since
    # we don't want to increase it unless the input is valid for this query.
    # It's possible that we'll end up with an empty cube or none selected,
    # but I think it's still valid to increase valid_seconds in those cases.
    # None selected implies 0 bytes, so still valid to increase denominator
    # for bps calculations.


    # Update valid_seconds for timestamps the input cube covers.
    vs_in = cube_in.time['valid_seconds']
    vs_result = cube_result.time['valid_seconds']

    for ts, vs in vs_in.iteritems():
        ts_in = ts

        # Fixup timestamp if necessary.
        if 'timestamp' not in cube_result.dimensions:
            # When timestamp is rolled out, use 0 as the key.
            ts = 0
        elif timestep_change:
            # timestep_change aggregates timestamps during rollup. Do the
            # same for valid_seconds here.
            # Note: time_dist handles fixing up valid_seconds itself.
            ts = timestep_change.get_ts(ts)
        if ts not in vs_result:
            vs_result[ts] = 0
        if timestep_change and ts_in in cube_result._ts_in_seen:
            continue

        vs_result[ts] += vs

        # craig test
        cube_result._ts_in_seen.add(ts_in)

    # Short circuit if input is empty b/c later stuff doesn't like 0-length
    # arrays.
    if cube_in.num_positions() == 0:
        log.warn('cube-map-process-empty-input-cube %s' % (cube_in.cube_file))
        return
    if len(selected_indices) == 0:
        log.debug('cube-map-process-none-selected %s' % (cube_in.cube_file))
        return

    cube_result.track_fake(cube_in.fake_dimensions)

    # bundle rollup
    if cube_in.meta.get('values_per_position') and query.use_bundle_rollup:
        cube_result.rollup_bundle(cube_in, cvt_positions, meas_arrs, cvt_axes, selected_indices)
        cube_result.sum_all = query.sum_all
    else:
        cube_result.rollup(cvt_positions, meas_arrs, cvt_axes, selected_indices)

    process_end = time.time()

    ru = deepy.util.getrusage()
    process_mb = ru['rss_mb'] - start_ru['rss_mb']

    if len(cube_result) > 0:
        bytes_per = process_mb * 1024 * 1024 / len(cube_result)
    else:
        bytes_per = 0

    msg = ('cube-map-process-done n_positions=%d/%d process_time=%.2fs total_time=%.1f file=%s' %
            (selected_indices.size, cube_in.num_positions(), process_end - process_start, ru['total_time'], cube_in.cube_file))
    msg2 = ('cube-map-process-mem result_positions=%d process_mb=%d bytes_per_pos=%d rss_mb=%d maxrss_mb=%d' %
            (len(cube_result), process_mb, bytes_per, ru['rss_mb'], ru['maxrss_mb']))

    if process_end - process_start > 2:
        # these took a long time. used to log.warn but that was pretty noisy.
        prof_log(msg)
        prof_log(msg2)
    prof_log(tt.end('total', 'cube-map-process-end {}'.format(query.name)))

def _cube_map_process_setup_dimensions(cube_result, cube_in, timestep_change):
    tt = TrackTimes()
    prof_log(tt.start('total', 'cube_map_process_setup_dimension-start '))
    if timestep_change is not None:
        try:
            result_ts_i = cube_result.dimensions.index('timestamp')
        except ValueError:
            raise deepy.cube.QueryError('timestep_change requires timestamp dimension')

    # Create axes that map from the cube_in dimension order to the result
    # dimension order.
    # E.g., res = [service, timestamp], in = [timestamp, cdn, service]
    # convert_positons =
    #        [cube_in_service_positions, cube_in_timestamp_positions]
    # convert_axes = [cube_in_service_axis, cube_in_timestamp_axis]
    convert_positions = []
    convert_axes = []

    for result_idx, dim_id in enumerate(cube_result.dimensions):
        try:
            # The index into the input cube's position/axis array lists.
            in_idx = cube_in.dimensions.index(dim_id)
        except ValueError:
            # The result dimension is not in the input cube. Either a hierarchy
            # function will provide it, or it's an error.
            # Currently treating as error.
            # For hierarchy functions that add new dimensions, may need to
            # keep known list of dimensions to validate.
            #
            # Maybe move this earlier, in cube_map_queries()?
            raise QueryWarning({
                'error': 'Input cube missing dimension (_cube_map_process)',
                'dim_id': dim_id,
                'file': cube_in.cube_file
                })

        convert_positions.append(cube_in.positions[in_idx])

        # Make a new axis that maps from the input position ids to the
        # result position ids. So, the axes will contain the result local
        # ids rather than the dim_db ids.
        # E.g., in_axis_cdn = [akamai_id, llnw_id, lvl3_id],
        # out_axis_cdn = [llnw_id, lvl3_id, akamai_id].
        # convert_axis_cdn = [2, 0, 1]
        new_axis = []
        for idx, pos_id in enumerate(cube_in.axes[in_idx]):
            if timestep_change is not None and result_idx == result_ts_i:
                # Multiple timestamps in the input will map to a single
                # timestamp in the result, based on the timestep_change period.
                # The convert axis will handle this mapping in addition to
                # mapping local ids.
                pos_id = timestep_change.get_ts(pos_id)

            # XXX XXX This creates an index in the result for every
            # position in the input, but many positions won't actually be
            # in the result due to slicing. So, the axis is gratuitously
            # large.
            new_idx = cube_result.get_position_index(result_idx, pos_id)
            new_axis.append(new_idx)
        convert_axes.append(new_axis)

    prof_log(tt.end('total', 'cube_map_process_setup_dimension-end'))
    return convert_positions, convert_axes

def _cube_map_process_setup_measures(cube_result, cube_in):
    tt = TrackTimes()
    prof_log(tt.start('total', 'cube-map-process-setup-measures-start'))
    # Make sure measures match, and reorder if necessary.
    meas_arrs = []
    meas_in_map = dict([(meas_id, idx)
        for idx, meas_id in enumerate(cube_in.measures)])
    # Hack to handle transition from underscore to dot.
    meas_equiv = {
            'sent_bytes': 'sent.bytes',
            'sent.bytes': 'sent_bytes',
            'recv_bytes': 'recv.bytes',
            'recv.bytes': 'recv_bytes',
            }
    for meas_id in cube_result.measures:
        if meas_id in meas_in_map:
            # Found
            in_idx = meas_in_map[meas_id]
        elif meas_id in meas_equiv and meas_equiv[meas_id] in meas_in_map:
            # Map input measure to what result is looking for.
            in_idx = meas_in_map[meas_equiv[meas_id]]
        else:
            # Not found
            raise QueryWarning({
                'error': 'Input cube missing measure (_cube_map_process)',
                'meas_id': meas_id,
                'file': cube_in.cube_file
                })
        meas_arrs.append(cube_in.measure_arrays[in_idx])

    prof_log(tt.end('total', 'cube-map-process-setup-measures-end'))
    return meas_arrs


# Get slice dimensions so they can be loaded. Same translation logic as in
# _cube_map_process_slice().
def _cube_map_process_get_slice_dim_ids(slice_defs, dimensions_db):
    dim_ids = []
    for i, slice_def in enumerate(slice_defs):
        # Translate dimension names.
        dim_name = slice_def['dimension']
        conv_id = dimensions_db.get_id_by_name(dim_name)
        # If name lookup failed, assume it was already an id.
        dim_id = conv_id if conv_id is not None else dim_name
        dim_ids.append(dim_id)
    return funcy.distinct(dim_ids)


def _build_slice_def_tuples(cube_in, slice_defs, ddb):
    # Map slice values to axes positions.
    # XXX This supports slicing by position id or name, but names don't include
    # extended names.
    slice_def_tuples = []

    for slice_def in slice_defs:
        # Translate dimension names.
        dim_name = slice_def['dimension']
        conv_id = ddb.get_id_by_name(dim_name)
        # If name lookup failed, assume it was already an id.
        dim_id = conv_id if conv_id is not None else dim_name

        # Various setup
        key_path = slice_def['key_path']
        if key_path is None:
            # Default to original behavior of comparing name.
            key_path = 'name'
            name_id_fallback = True
        else:
            name_id_fallback = False

        if slice_def['type'] == 'range_include':
            start = slice_def['values']['start']
            end = slice_def['values']['end']

        try:
            in_axis_idx = cube_in.dimensions.index(dim_id)
        except ValueError:
            # XXX This shouldn't happen anymore since we're checking in
            # CubeLoader
            # The slice dimension is not in the input cube.
            raise QueryWarning({

                'error': 'Input cube missing slice dimension (_build_slice_def_tuples)',
                'dim_id': dim_id,
                'file': cube_in.cube_file
                })
        axis = cube_in.axes[in_axis_idx]
        axis_indices = []

        # Setup match sets.
        # XXX Move this to SliceDef.
        match_set = set(slice_def['values'])
        match_set_glob = []
        for pat in match_set:
            # Only glob match if it's a string. But, will now glob on any
            # string, even if it was a normal slice statement (non-path).
            if isinstance(pat, basestring):
                match_set_glob.append(pat)

        # hardcoded dimensions (timestamp, old geo) aren't in ddb,
        # support special case of ddb not loaded (for testing),
        # or we are trying to compare with strings that don't look like numbers (i.e. not '153')
        hardcoded_dim = (ddb.get_by_id(dim_id) == None) or \
            all(isinstance(i, basestring) and not i.isdigit() for i in axis)

        # Walk axis looking for matching positions.
        for axis_idx, pos_id in enumerate(axis):
            # Determine pos_val that we'll be checking for match.
            if hardcoded_dim:
                # Can only compare based on id.
                pos_val = pos_id
            elif pos_id in deepy.dimensions.special_positions_by_id:
                # None/Other position
                pos_val = pos_id
            else:
                # Path lookup
                try:
                    pos_val = ddb.get_pos_path(dim_id, str(pos_id), key_path)
                except LookupError:
                    # No value, can't match.
                    continue

            if slice_def['type'] == 'range_include':
                if pos_val is None:
                    # Can't include the None position with a range.
                    continue
                if pos_val >= start and pos_val <= end:
                    axis_indices.append(axis_idx)
            else:
                # Check match sets.
                if isinstance(pos_val, collections.Hashable) and pos_val in match_set:
                    # Found exact match.
                    axis_indices.append(axis_idx)
                elif isinstance(pos_val, list):
                    # Consider each list value for match
                    for pv in pos_val:
                        if pv in match_set:
                            # Found exact match.
                            axis_indices.append(axis_idx)
                            break
                elif name_id_fallback and pos_id in match_set:
                    # Support original behavior of match against pos ids.
                    axis_indices.append(axis_idx)
                else:
                    # Glob
                    if pos_val is None:
                        # Can't glob match None.
                        continue
                    for pat in match_set_glob:
                        if fnmatch.fnmatchcase(str(pos_val), pat):
                            # Found glob match.
                            axis_indices.append(axis_idx)
                            break

        # Keep tuple of the def, in_axis_idx, and axis_indices
        slice_def_tuples.append((slice_def, in_axis_idx, axis_indices))
    return slice_def_tuples


# Given cube and slice_defs, return numpy array containing list of indices
# into cube_in that match the slices.
def _cube_map_process_slice(cube_in, slice_defs, ddb, do_slice_negate=False):
    tt = TrackTimes()
    prof_log(tt.start('total', '_cube_map_process_slice-start'))
    slice_def_tuples = _build_slice_def_tuples(cube_in, slice_defs, ddb)

    # Numpy slice
    # Start with everything selected, then And
    # selected starts as full-size index to handle case of no slices.
    selected = np.ones(cube_in.positions[0].shape, dtype=bool)
    for slice_def_tuple in slice_def_tuples:
        slice_def, in_axis_idx, axis_indices = slice_def_tuple
        slice_type = slice_def['type']
        dimension_positions = cube_in.positions[in_axis_idx]
        # uses dimension_positions so that there is no unused warning ...
        dimension_positions

        # Build boolean index array for this slice.
        # Start with nothing selected, then Or
        # The first iteration will use broadcasting to extend the single value.
        slice_selected = False
        exprs = []
        locs = locals()
        for axis_idx in axis_indices:
            # this line is replaced by numexpr
            # numexpr decreased this select statement by ~40 %
            # slice_selected |= dimension_positions == axis_idx
            name = 'axis_idx_%d' % (axis_idx,)
            locs[name] = axis_idx
            exprs.append('(dimension_positions == %s)' % (name,))

        step = 30 # limited by numpy max args/max python recursion limit, numexpr may fix this in the future
        for si in range(0, len(exprs), step):
            slice_selected |= numexpr.evaluate('|'.join(exprs[si:si+step]))

        if slice_type == 'exclude':
            slice_selected = np.logical_not(slice_selected)

        # Combine slice index with overall index.
        selected &= slice_selected

    if do_slice_negate:
        selected = np.logical_not(selected)

    # Process the nodes selected by the slice operations.
    # XXX There's gotta be a better/more-efficient way to do this iteration
    # than using where.
    where_selected = np.where(selected)
    # where returns tuple of dimensions. We're only using 1 dimension.
    prof_log(tt.end('total', '_cube_map_process_slice-end'))
    return where_selected[0]


# Throw from CubeBuilder subclass to break out of conv processing for a sub
class CubeBuilderSeenEnoughConvs(Exception):
    pass


# Throw from CubeBuilder subclass _add_sub_scratch() to skip sub
class CubeBuilderSkipSub(Exception):
    pass


####
# Cube Building (from subflow)

# Common stuff for building a cube from subflow.
class CubeBuilder(object):
    # Keep in sync with position layout.
    dimensions = None
    measures = None

    def __init__(self, time_str, results_file, step=None):
        # Copy in config.
        self.time_str = time_str
        self.results_file = results_file

        self._set_dimensions()
        self._set_measures()

        self.ts = deepy.timerange.parse_datetime(time_str, '-')

        self.cube = CubeDict(self.dimensions, step=step)
        self.cube.time['valid_seconds'] = {self.ts: step}


        # Debugging. Used when logging each error as it happens would be too
        # verbose.
        self.errors = {}

    def process_sub(self, sub):
        try:
            self._add_sub_scratch(sub)
        except CubeBuilderSkipSub:
            return

        if deepy.cfg.deployment_id == 'demo':
            sub.sent = sub.sent * 212
            sub.recv = sub.recv * 212
            sub.bytes = sub.recv * 212

        conv_sent_total = 0
        conv_recv_total = 0
        for conv in sub.conv:
            sb = conv.sent_bytes
            rb = conv.recv_bytes

            if deepy.cfg.deployment_id == 'demo':
                sb = sb * 212
                rb = rb * 212

            if sb + rb == 0:
                # dnsflow with no matching netflow.
                continue

            # Track bytes delegated to conversations.
            conv_sent_total += sb
            conv_recv_total += rb

            try:
                position = self._get_subflow_position_conv(sub, conv)
                self._update_position(position, sub, sb, rb)
            except CubeBuilderSeenEnoughConvs:
                break


        # Bytes not attributed to a conversation are added to a position
        # with only sub.type and time defined. Fills in Nones for remaining
        # dimensions.
        try:
            position = self._get_subflow_position_sub(sub)
            self._update_position(position, sub, sub.sent - conv_sent_total,
                    sub.recv - conv_recv_total)
        except CubeBuilderSeenEnoughConvs:
            pass

    def _get_measures(self, position):
        measures, scratch = self.cube.get(position, (None, None))
        if measures is None:
            # XXX convert to numpy?
            # measures = np.zeros(len(measures_sum_old), dtype=measure_type)

            # New position. Initialize all measures to 0.
            measures = dict([(meas, 0) for meas in self.measures])
            # Store a scratch space with the measures. Currently used to
            # help count subs. scratch is removed before writing the cube.
            scratch = {}
            self.cube[position] = (measures, scratch)
        return measures, scratch

    def write_results(self, measures_arg=None):
        if len(self.errors) > 0:
            log.warn('processing-errors %s' % (self.errors))

        # Remove scratch. Convert to numpy format expect by write_to_store.
        if measures_arg:
            meas_tup = namedtuple('meas_tup' + str(id(self)), measures_arg)
        else:
            meas_tup = namedtuple('meas_tup' + str(id(self)), measures_sum_old)

        for pos, (meas, scratch) in self.cube.iteritems():
            measures = np.array(meas_tup(**meas), dtype=measure_type)
            self.cube[pos] = measures

        if measures_arg:
            self.cube.measures = measures_arg
        else:
            self.cube.measures = measures_sum_old

        self._print_summary()
        self.cube.write_to_store(self.results_file)

    def results_exist(self):
        # Grab result file, if it exists.
        deepy.store.cache_load_from_remote(self.results_file)
        if os.path.exists(self.results_file):
            return True
        return False

    # For testing
    def _print_summary(self):
        total = 0
        for pos, meas in self.cube.iteritems():
            # assuming positions 0 and 1 are bytes.
            # (though router cube only has one measure)
            total += meas[0]
            try:
                total += meas[1]
            except:
                pass

        #step = self['step']
        #if set is None:
        step = 3600

        log.info('cube-summary %s: %d positions, %d bytes, %.2f Gbps' %
                (os.path.basename(self.results_file), len(self.cube),
                total, total * 8/step/1000000000.0))

    # Override
    def _add_sub_scratch(self, sub):
        pass
    def _set_dimensions(self):
        pass
    def _set_measures(self):
        pass
    def _get_subflow_position_sub(self, sub):
        pass
    def _get_subflow_position_conv(self, sub, conv):
        pass
    def _update_position(self, position, sub, sent_bytes, recv_bytes):
        pass


class CubeBuilder2(object):
    def __init__(self, time_step, time_str, dimension_types, measures,
            subflow_files, results_file):
        # Copy in config.
        self.time_str = time_str
        self.dimension_types = dimension_types
        self.measures = measures
        self.subflow_files = subflow_files
        self.results_file = results_file

        self.ts = deepy.timerange.parse_datetime(time_str, '-')

        self.cube = CubeHash(step=time_step)
        self.cube.time['valid_seconds'] = {self.ts: time_step}

        self.cube.load_subflow(dimension_types, measures, subflow_files)

    def write_results(self):
        self._print_summary()
        self.cube.write_to_store(self.results_file)

    # For testing
    def _print_summary(self):
        summ = self.cube.get_summary()
        log.info('cube-summary %d positions, %d bytes, %.2f Gbps, %d secs' %
                (summ['positions'], summ['bytes'], summ['Gbps'], summ['total_secs']))

class CubeFromArrays(object):
    '''
    Build cube from numpy arrays. Wraps Groupby and from_arrays().
    '''
    def __init__(self, timestamp=None, timestep=None):
        '''
        timestamp - unix timestamp (int)
        timestep - seconds (int)
        '''
        self.timestamp = timestamp
        self.timestep = timestep
        self.meas_ids = None
        self.dim_ids = None
        self._gb = deepy.cube_cy.GroupbySum()

    def add_arrays(self, positions, measures):
        '''
        Add positions. Can be called repeatedly. positions and measures must
        be consistent across calls.

        positions - dict with dim_ids as keys and values of numpy 1D arrays
          of ddb position ids, using 0 for None. Will be converted to dtype u4
          if not already.
        measures - dict with measure_ids as keys and values of numpy 1D arrays
          of measure values. Will be converted to dtype f4 if not already.

        If you want to preserve your dimension and measure order, pass in
          OrderedDicts.
        '''
        if self.dim_ids is None:
            # Set on first call.
            self.dim_ids = positions.keys()
            self.meas_ids = measures.keys()
        else:
            if self.dim_ids != positions.keys():
                raise ValueError
            if self.meas_ids != measures.keys():
                raise ValueError

        # Convert to position type expected for cubes.
        pos_arrs = positions.values()
        dtypes = [arr.dtype for arr in pos_arrs]
        if not all([dt == deepy.cube_cy.position_dtype for dt in dtypes]):
            log.debug('casting-positions')
            pos_arrs = [np.array(arr, deepy.cube_cy.position_dtype)
                        for arr in pos_arrs]
        # Convert to measure type expected for groupby.
        meas_arrs = measures.values()
        dtypes = [arr.dtype for arr in meas_arrs]
        if not all([dt == self._gb.measure_dtype for dt in dtypes]):
            log.debug('casting-measures')
            meas_arrs = [np.array(arr, dtype=self._gb.measure_dtype)
                    for arr in meas_arrs]

        # Aggregate
        self._gb.process(pos_arrs, meas_arrs)

    def finish(self):
        pos_arrs, meas_arrs = self._gb.finish()
        # Don't try to reuse.
        self._gb = None

        pos_dict = OrderedDict(zip(self.dim_ids, pos_arrs))
        meas_dict = OrderedDict(zip(self.meas_ids, meas_arrs))
        cube = deepy.cube.CubeHash.from_arrays(pos_dict, meas_dict,
                aggregate=False)
        if self.timestamp is not None:
            cube.add_timestamp_dimension(int(self.timestamp),
                    int(self.timestep))
        return cube

def _create_apply_dicts(apply_args):
    '''
    Convert apply function format to dict format.
    '''
    applies = []
    # apply
    for a in apply_args:
        m = re.search('([^(]+)\((.*)\)', a)
        if not m:
            raise ValueError('Invalid apply: %s' % (a))
        fn, params = m.groups()
        default_param = [True]
        if fn[-1] == '!':
            continue

        if len(params) == 0:
            app_args = default_param
        else:
            app_args = [p.strip() for p in params.split(',')]

        applies.append({'fn':fn, 'args': app_args})

    return applies


def _create_slice_defs(slice_args):
    '''
    src_cube_id = id found in jobs_makefile.json, eg big_cube, router, etc
    dimensions = timestamp,cdn comma-sep
    apply_args = time_dist(days), measure_fixup()
    slice_args = 102=1282, local_geo=g:CA
    '''
    slice_defs = []
    for a in slice_args:
        slice_def = deepy.slice_def.SliceDef.from_cmdline(a)
        if slice_def is None:
            raise 'Invalid slice: %s' % (a)
        else:
            slice_defs.append(slice_def)
    return slice_defs

def arg_join_expand(arg_file):
    val = None
    arg_json = deepy.store.simple_load_json(arg_file)
    if arg_json is not None:
        val = ','.join([':'.join([str(i) for i in x]) for x in arg_json])
    else:
        print 'Arg load failed: %s' % (arg_file)
    return val

def parse_arg_join(a):
    subst_dict = {}
    if not a:
        return subst_dict
    # opt of form subst_key=filename
    subst_key, arg_file = a.split('=', 1)
    subst_key = '<%s>' % (subst_key)
    # Expecting json file with list of 1-item lists.
    # E.g. [[36040], [3356], [22822]]
    # Format as command line arg.
    val = arg_join_expand(arg_file)
    if val is not None:
        subst_dict[subst_key] = val
        log.debug('cmd-substitution %s=%s' % (subst_key, val))
    return subst_dict


def create_slice_with_subst(slice_args, subst_dict):
    subst_slice_args = []
    for a in slice_args:
        # Do substitutions.
        for subst_key, val in subst_dict.iteritems():
            a = a.replace(subst_key, val)
        subst_slice_args.append(a)
    slice_defs = _create_slice_defs(subst_slice_args)
    return slice_defs


def create_apply_with_subst(apply_args, subst_dict):
    subst_apply_args = []
    for a in apply_args:
        # Do substitutions.
        for subst_key, val in subst_dict.iteritems():
            a = a.replace(subst_key, val)
        subst_apply_args.append(a)
    applies = _create_apply_dicts(subst_apply_args)
    return applies

def copy_cube(in_file, out_file):

    icube = os.path.basename(in_file).replace('cube.', '').replace('.npz', '').replace('.h5', '')
    itime = deepy.timerange.parse_datetime(icube, '-')

    ocube = os.path.basename(out_file).replace('cube.', '').replace('.npz', '').replace('.h5', '')
    otime = deepy.timerange.parse_datetime(ocube, '-')

    if os.path.exists(out_file):
        print 'backing up', out_file, 'to .bak'
        shutil.copy(out_file, out_file + '.bak')

    save_arrays = OrderedDict()
    if in_file.endswith('.npz'):
        in_cube = np.load(in_file)
        for k in in_cube.keys():
            if k not in ['meta', 'axes']:
                save_arrays[k] = in_cube[k]
            else:
                print 'not copied', k,
        print
        meta = ujson.loads(in_cube['meta'].item())
        axes = ujson.loads(in_cube['axes'].item())
    else:
        in_cube = CubeLoader(in_file)
        save_arrays = serialize_cube(in_cube.positions, in_cube.measure_arrays)
        meta = in_cube.meta
        axes = in_cube.axes

    ts_index = meta['dimensions'].index('timestamp')

    #print 'before'
    #print meta
    #print axes[ts_index]

    vs = meta['time']['valid_seconds']
    valid_seconds = vs.get(str(itime))
    if valid_seconds is None:
        valid_seconds = vs.get(int(itime))
    assert valid_seconds is not None

    new_vs = {}
    ts_keys = sorted(map(int, vs.keys()))
    first_ts = ts_keys[0]
    old_to_new_ts = {}
    for _ts, _vs in vs.items():
        _ts = int(_ts)
        diff = _ts - first_ts
        new_ts = otime+diff
        new_vs[str(new_ts)] = _vs

        old_to_new_ts[_ts] = new_ts

    for i, ts in enumerate(axes[ts_index]):
        # rewrite timestamp axes as well
        axes[ts_index][i] = old_to_new_ts[ts]

    meta['time']['valid_seconds'] = new_vs

    #print 'after'
    #print meta
    #print axes[ts_index]

    meta_json = ujson.dumps(meta)
    axes_json = ujson.dumps(axes)
    #if npzFlag:
    #    np.savez_compressed(out_file, meta=meta_json, axes=axes_json, **save_arrays)
    #else:
    write_h5_cube(out_file, save_arrays, meta_json, axes_json)

def get_rule(cube, step):
    '''Given a cube and step, find the rule. Step is ignored unless the cube has multiple
    matches and a step is required for disambiguation'''
    possible_expanders = find_cube_possible_rules(cube)
    if not possible_expanders:
        print "Couldn't find rules for cube", cube
        sys.exit(1)

    if len(possible_expanders) > 1 and not step:
        print "Found results for time steps:",
        for r in possible_expanders:
            print r.unexpanded_id, r.time_step
        sys.exit(1)

    matched_rules = filter(lambda x: x.time_step == step, possible_expanders)
    if not matched_rules:
        print "Couldn't find time step {} for cube {}".format(step, cube)
        print "Found: ",
        for r in possible_expanders:
            print r.unexpanded_id, r.time_step,
        sys.exit(1)

    assert len(matched_rules) == 1
    return matched_rules[0]

