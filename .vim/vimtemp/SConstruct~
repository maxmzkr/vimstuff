import site
import os
import subprocess
import urllib2
import sys
import glob
import json
import re
import datetime
import calendar
import SCons

# insert 0, use local deepy before remote while installing
sys.path.insert(0, os.path.abspath('lib'))
from deepy.platform_info import (get_python_install_path,
        is_mac, is_linux, is_virtenv, os_name, os_version)

from distutils import sysconfig
from distutils import version

# Custom builders
import install

# Define the custom function
from SCons.Script.SConscript import SConsEnvironment
SConsEnvironment.Chmod = SCons.Action.ActionFactory(os.chmod,
        lambda dest, mode: 'Chmod("%s", 0%o)' % (dest, mode))

try:
    from slimit import minify
except ImportError:
    minify = None

try:
    import numpy
except ImportError:
    numpy = None

HOME = Dir('.').path

# Specify if crawler on command line
BUILD_TYPE = "deployment"
if ARGUMENTS.get("build_type", "") == "crawler":
    BUILD_TYPE = "crawler"

def PhonyTargets(env = None, **kw):
    if not env: env = DefaultEnvironment()
    for target,action in kw.items():
        env.AlwaysBuild(env.Alias(target, [], action))

# C compilation flags
CFLAGS = Split('-g -ggdb -fno-strict-aliasing -Wall')
if is_linux():
    # -Wno-unused-function needed for cython compatability reference:
    # http://stackoverflow.com/questions/14201192/what-is-this-import-umath-function
    CFLAGS += Split('-Werror -Wno-unused-function')

# Global installation directories
INSTALL_DIR = os.path.join('/', 'var', 'local', 'pipedream')
JAR_DIR = os.path.join('/', 'var', 'local', 'pipedream', 'jar')
UDFS_DIR = os.path.join('/', 'var', 'local', 'pipedream', 'udfs')
SCRIPT_DIR = os.path.join('/', 'usr', 'local', 'sbin')
DEFINES_DIR = os.path.join(INSTALL_DIR, 'defines')
UI_DIR = os.path.join(INSTALL_DIR, 'ui')
WHEELHOUSE_DIR = os.path.join(INSTALL_DIR, 'wheelhouse')
S3_WHEELHOUSE_DIR = "http://s3.amazonaws.com/download.deepfield.net/provision/wheels/wheelhouse-%s-%s/" % (os_name(), os_version())
S3CMD_WHEELHOUSE_DIR = "s3://download.deepfield.net/provision/wheels/wheelhouse-%s-%s/" % (os_name(), os_version())
S3CMD_TARAPT_DIR = "s3://download.deepfield.net/provision/apt/"


################################################################################
# setup system dependent install path
################################################################################

PYX_INSTALL_DIR = get_python_install_path()
assert PYX_INSTALL_DIR is not None, "Warning unknown os platform"


if 'build-package' in COMMAND_LINE_TARGETS:
    INSTALL_DIR = os.path.join(os.path.curdir, 'debian', INSTALL_DIR.lstrip('/'))
    SCRIPT_DIR = os.path.join(os.path.curdir, 'debian', SCRIPT_DIR.lstrip('/'))
    DEFINES_DIR = os.path.join(os.path.curdir, 'debian', DEFINES_DIR.lstrip('/'))
    UI_DIR = os.path.join(os.path.curdir, 'debian', UI_DIR.lstrip('/'))
    PYX_INSTALL_DIR = os.path.join(os.path.curdir, 'debian', PYX_INSTALL_DIR.lstrip('/'))
    WHEELHOUSE_DIR = os.path.join(os.path.curdir, 'debian', WHEELHOUSE_DIR.lstrip('/'))

# Regular expressions to determine third-party directories in a version-independent fashion
# The actual dependency objects to pass along
third_party_deps = {}
third_party_deps_install = {}

# Directories to add to setup.sh for building in place
third_party_python_dirs = []

INCLUDES = [
    "include",
    "lib",
    "lib/ipfrag",
    "lib/flow",
    "lib/dimensions",
    "lib/classify",
    "lib/pipedream",
    "lib/tags",
    "lib/bgp",
    "lib/dnsflow",
    "lib/h5flow",
    "lib/hll",
    "lib/deepylog",
    "third-party/cii-2.0/include",
    "third-party/cii-2.0/include",
    "third-party/libdnet-1.12/trunk/include",
    "./third-party/klib",
    os.path.join(sysconfig.PREFIX, 'include'),
    "/opt/local/include",
    "/usr/local/include/",
    "third-party/cityhash-c",
    "third-party/jansson-2.4/src/",
    "third-party/blosc/blosc",
    "third-party/blosc/hdf5",
    sysconfig.get_python_inc(),
    sysconfig.get_python_inc(plat_specific=True)
]

if numpy is not None:
    INCLUDES.append(numpy.get_include())
    if version.LooseVersion(numpy.version.version) < version.LooseVersion("1.9.0") :
        INCLUDES.append(numpy.get_numarray_include())

LIBPATHS = [
    'lib/flow',
    'lib/bgp',
    'lib/dnsflow',
    'lib/h5flow',
    'lib/ipfrag',
    'lib/pipedream',
    'lib/tags',
    'lib/classify',
    'lib/dimensions',
    'lib/hll',
    'lib/deepylog',
    os.path.join(sysconfig.PREFIX, 'lib'),
    '/usr/local/lib',
    '/opt/local/lib',
    'fakeinstall/lib',
    'third-party/cityhash-c',
    'third-party/blosc/blosc'
]

BASE_ENVIRONMENT = Environment()
BASE_ENVIRONMENT.Append(RPATH=BASE_ENVIRONMENT.Literal(sysconfig.PREFIX+"/lib"))



# Need this to work for installing into virtualenv
python_directory = "(.*)/include/python%d.%d" % (sys.version_info.major, sys.version_info.minor)
m = re.match(python_directory, sysconfig.get_python_inc())
if m:
    lib_path = os.path.join(m.groups()[0], "lib")
    LIBPATHS.append(lib_path)

CPPDEFINES = [
    '__FAVOR_BSD',
    '_BSD_SOURCE'
]

general_depends = []

def set_general_depends(target, env, use_third_party=True, default_target=True):
    """
    OS + Python Packages
    """

    if default_target:
        env.Default(target)

    if not isinstance(target, list):
        target = [target]

    for t in target:
        for d in general_depends:
            env.Depends(t, d)

        if use_third_party:
            for d in third_party_deps:
                env.Depends(t, third_party_deps[d])

def build_environment(env):
    if BUILD_TYPE == 'crawler':
        return crawler_build_env(env)
    elif is_linux():
        return ubuntu_build_env(env)
    elif is_mac():
        return mac_build_env(env)
    else:
        assert None, "Warning unknown build environment"

def crawler_build_env(env):
    # Target shows us when the packages were last updated
    target_file = os.path.join("build_deps", ".lastRun_system_packages")
    deps_file = os.path.join("build_deps", "crawler_dependencies.json")

    cmds = []
    deps = json.load(open(deps_file))["crawler_dependencies"]
    deps_str = ' '.join(deps)

    cmds.append("sudo add-apt-repository -y ppa:ubuntu-mozilla-security/ppa")
    cmds.append("sudo apt-get update -y")
    cmds.append("sudo apt-get install -y %s" % (deps_str))
    cmds.append("echo 1 > %s" % (target_file))

    o = env.Command(target_file, deps_file, cmds)
    return o

def ubuntu_build_env(env):
    o = env.Alias('UBUNTU_BUILD_ENV', [], '@echo')
    return o

def mac_build_env(env):
    home = os.getenv("HOME")
    env['ENV']['HOME'] = home
    o = env.Alias("MAC_BUILD_ENV", [], '@echo')
    return o

def third_party(env):
    dirs = [
        'fakeinstall',
        'fakeinstall/lib',
        'fakeinstall/include',
        'fakeinstall/man',
        'fakeinstall/bin',
        'fakeinstall/sbin'
    ]
    for d in dirs:
        if not os.path.exists(d):
            os.makedirs(d)

    fake_install_dir = os.path.abspath("fakeinstall")

    # ripencc-bgpdump
    ripencc_bgpdump_dir = os.path.join("third-party", "ripencc-bgpdump")
    ripencc_bgpdump_c = Glob(os.path.join(ripencc_bgpdump_dir, "*.c"))
    ripencc_bgpdump_h = Glob(os.path.join(ripencc_bgpdump_dir, "*.h"))

    # exclude bgpdump-config.h that is generated during bgpdump building
    ripencc_bgpdump_h = [str(x) for x in ripencc_bgpdump_h if 'bgpdump-config.h' not in str(x)]
    ripencc_bgpdump_c += ripencc_bgpdump_h

    ripencc_bgpdump_targets = [os.path.join(fake_install_dir, "bin", "bgpdump")]
    ripencc_bgpdump_cmds = [
        "./bootstrap.sh",
        "make",
        "cp *.h %s" % (os.path.join(fake_install_dir, "include")),
        "cp bgpdump %s" % (os.path.join(fake_install_dir, "bin"))
    ]
    third_party_deps["bgpdump"] = build_third_party(env, ripencc_bgpdump_targets,
        ripencc_bgpdump_c, ripencc_bgpdump_dir, ripencc_bgpdump_cmds)
    bgpdump_bin = [x for x in third_party_deps["bgpdump"] if str(x).endswith("bgpdump")][0]
    env.Alias("bgpdump", third_party_deps["bgpdump"])

    # cii
    cii_dir = os.path.join("third-party", "cii-2.0")
    cii_c = glob.glob(os.path.join(cii_dir, "src", "*.c"))
    cii_h = glob.glob(os.path.join(cii_dir, "include", "*.h"))
    cii_c += cii_h
    cii_h = [os.path.join(fake_install_dir, "include", os.path.basename(h)) for h in cii_h]

    cii_targets = [os.path.join(fake_install_dir, "lib", "libcii.a")] + cii_h
    cii_cmds = [
        "make -k THREADS=",
        "cp include/*.h %s" % (os.path.join(fake_install_dir, "include")),
        "cp libcii.a %s" % (os.path.join(fake_install_dir, "lib"))
    ]
    third_party_deps["cii"] = build_third_party(env, cii_targets, cii_c, cii_dir, cii_cmds)
    env.Alias("cii", third_party_deps["cii"])

    # jansson
    jansson_dir = os.path.join("third-party", "jansson-2.4")
    jansson_c = glob.glob(os.path.join(jansson_dir, "src", "*.c"))

    jansson_targets = [
        os.path.join(fake_install_dir, "lib", "libjansson.a"),
        os.path.join(fake_install_dir, "lib", "libjansson" + ".so" if is_linux() else ".dylib"),
        os.path.join(fake_install_dir, "include", "jansson.h")
    ]
    jansson_cmds = [
        "./configure --prefix=%s" % (fake_install_dir),
        "make install"
    ]
    third_party_deps["jansson"] = build_third_party(env, jansson_targets, jansson_c,
        jansson_dir, jansson_cmds)
    env.Alias("jansson", third_party_deps["jansson"])

    # klib
    klib_dir = os.path.join("third-party", "klib")
    klib_h = [
        os.path.join(klib_dir, "khash.h"),
        os.path.join(klib_dir, "kvec.h")
    ]

    klib_targets = [
        os.path.join(fake_install_dir, "include", "khash.h"),
        os.path.join(fake_install_dir, "include", "kvec.h")
    ]
    klib_cmds = [
        "cp khash.h %s" % (os.path.join(fake_install_dir, "include")),
        "cp kvec.h %s" % (os.path.join(fake_install_dir, "include"))
    ]
    third_party_deps["klib"] = build_third_party(env, klib_targets, klib_h,
        klib_dir, klib_cmds)
    env.Alias("klib", third_party_deps["klib"])

    # libdnet general
    libdnet_dir = os.path.join("third-party", "libdnet-1.12")

    # libdnet C
    libdnet_c = glob.glob(os.path.join(libdnet_dir, "src", "*.c"))
    libdnet_targets = [
        os.path.join(fake_install_dir, "lib", "libdnet.a"),
        os.path.join(fake_install_dir, "include", "dnet.h")
    ]
    libdnet_cmds = [
        "./configure --prefix=%s CFLAGS=-fPIC" % (fake_install_dir),
        "make install"
    ]
    third_party_deps["dnet_c"] = build_third_party(env, libdnet_targets, libdnet_c,
        libdnet_dir, libdnet_cmds)
    env.Alias("dnet_c", third_party_deps["dnet_c"])

    # libdnet Python
    libdnet_python_dir = os.path.join(libdnet_dir, "python")
    third_party_python_dirs.append(libdnet_python_dir)

    libdnet_py = [
        os.path.join(libdnet_dir, "python", "dnet.pyx"),
        os.path.join(libdnet_dir, "python", "dnet.c")
    ]
    third_party_deps["dnet_py"] = build_third_party_python(env, libdnet_py, libdnet_python_dir)
    third_party_deps_install["dnet_py"] = install_third_party_python(env, [], libdnet_python_dir)
    env.Alias("dnet_py", third_party_deps["dnet_py"])

    env.Alias("dnet", ["dnet_py", "dnet_c"])

    # Add general depends to all the build objects we just made
    for dep in third_party_deps.values():
        set_general_depends(dep, env, use_third_party=False)

    bgpdump = env.Install(SCRIPT_DIR, bgpdump_bin)
    return bgpdump

def build_third_party_python(env, srcs, dir):
    #Use a target file in the python packages to determine when they were last run
    target = dir + '/.lastRun'

    cmds = ['python setup.py build']
    cmds += ["echo 1 > %s" % ( '.lastRun')]
    return build_third_party(env, target, srcs, dir, cmds)

#Generate install object for python libs (src should be the build object)
def install_third_party_python(env, src, dir):
    cmds = ['python setup.py install']

    #Use a fake target so that the install command always runs (To make sure its unique prefix it with the dir)
    target=[dir+"/NOT_A_REAL_TARGET"]

    o = build_third_party(env, target, src, dir, cmds)
    #Since this is an install that looks like a normal target to scons we need to explicitly exclude it from the default build
    env.Ignore('.', [o])
    return o

def build_third_party(env, targets, srcs, dir, cmds=None):
    if cmds is None:
        return

    #Set depends on the source files to ensure the general depends are run before anything else
    set_general_depends(srcs, env, default_target=False)

    #Using chdir=? doesn't work when running scons with multiple threads (-jN)
    #    reference: http://scons.tigris.org/ds/viewMessage.do?dsForumId=1272&dsMessageId=2673628&orderBy=createDate&orderType=desc
    # To get around this we prepend all commands with cd dir
    for i in range(len(cmds)):
        cmds[i] = "cd %s && " % (dir) + cmds[i]

    o = env.Command(targets, srcs, cmds)
    return o

def setup_cython_env():
    # This builder takes the cython source code and generates c code.
    cythonBuilder = Builder(action ='cython -o $TARGET $SOURCE',
            suffix = '.c',
            src_suffix = '.pyx')

    cfg = sysconfig.get_config_vars()
    pyincs = Split(cfg['INCLDIRSTOMAKE'])
    incs = Split(cfg['OPT'])

    # Setup the compilation environment.
    env = BASE_ENVIRONMENT.Clone(
            IMPLICIT_COMMAND_DEPENDENCIES=0,
            CCFLAGS=incs+['-fPIC', '-fno-strict-aliasing'],
            CFLAGS=CFLAGS + ['-Wno-error=cpp','-Wno-error=pointer-sign'],
            # CPPDEFINES={'NPY_NO_DEPRECATED_API': 'NPY_1_7_API_VERSION'},
            CPPPATH=INCLUDES+pyincs,
            LIBPATH=LIBPATHS,
            ENV = {"PATH":os.environ["PATH"]})
    env['BUILDERS']['Py2C'] = cythonBuilder

    if not is_linux():
        env['SHLINKFLAGS'] = ['$LINKFLAGS', '-shared', '-install_name', '${TARGET.abspath}']
        env['SHLIBSUFFIX'] = '.so'
        print 'Linking with flags', env['SHLINKFLAGS']

    return env

def build_cython_so(env, source, c_files, name=None, *args, **kws):
    # Primarily for mac numpy, but ok for linux
    kws['LIBS'] = kws.get('LIBS', []) + ['python2.7']

    set_general_depends(c_files, env, default_target=False)
    set_general_depends(source + ".pyx", env, default_target=False)

    if not name:
        name = source
        cCode = env.Py2C(name, source)
        objs = [cCode] + [env.SharedObject(c) for c in c_files]
        return env.SharedLibrary(name, objs, *args, **kws)
    else:

        path = os.path.dirname(name)
        f_name = os.path.basename(name)
        directory = path + "/." + f_name
        copy_target = directory + "/"+ f_name + ".pyx"

        env.Command(copy_target, source + ".pyx",
            [
                Mkdir(directory),
                Copy("$TARGET", "$SOURCE"),
            ])
        # Create a dummy name for the output
        # (This is needed because of naming conflicts specifically in h5flow
        # i.e. there is already a h5flow.c)

        cythonized_output = name + "_cythonized"
        cCode = env.Py2C(cythonized_output, copy_target)
        objs = [cCode] + [env.SharedObject(c) for c in c_files]
        return env.SharedLibrary(name, objs, *args, **kws)

def build_bgp(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('pcre hdf5  dimensions pipedream deepylog cii jansson z')

    pyx = 'lib/bgp/bgp_cy'
    name = 'lib/bgp/h5bgp'

    c_files = Split('lib/bgp/bgp.c  lib/bgp/bgp_extra.c')

    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)
    envcy.Alias('bgp', o)

    i = envcy.Install(PYX_INSTALL_DIR, o)

    return i

def build_flowd(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('pcap cii dnet event z jansson pcre hiredis')
    if is_linux():
        deps += Split('rt crypt')

    pyx = 'lib/flowd/flowd_cy'
    name = 'lib/flowd/flowd'
    c_files = Split('lib/flowd/flowd.c lib/flowd/pcap.c')
    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('flowd', i)

    return i

def build_dnsflow(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('pcre hdf5 pipedream cii jansson z deepylog')

    pyx = 'lib/dnsflow/dnsflow_cy'
    name = 'lib/dnsflow/h5dnsflow'
    c_files = Split('lib/dnsflow/dnsflow.c lib/dnsflow/dns_extra.c')
    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('dnsflow', i)

    return i

def build_dimensions(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('z pipedream jansson cii hdf5 blosc deepylog')

    pyx = 'lib/dimensions/dimensions_cy'

    c_files = Split('lib/dimensions/dimensions.c lib/dimensions/dimensions_extra.c lib/dimensions/genome.c  lib/dimensions/geoip.c')
    o = build_cython_so(envcy, pyx, c_files, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('dimensions', i)

    return i

def build_classify(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('z pipedream jansson deepylog cii pcre hdf5')

    pyx = 'lib/classify/h5classify_cy'
    name = 'lib/classify/h5classify'

    c_files = Split('lib/classify/classify_extra.c lib/classify/classify.c')
    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('classify', i)

    return i

def build_h5flow(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('dnsflow h5flow flow ipfrag dnet event z hll jansson deepylog cii pcre hdf5 blosc pipedream')

    pyx = 'lib/h5flow/h5flow_cy'
    name = 'lib/h5flow/h5flow'

    c_files = Split('lib/h5flow/h5flow_cy_helper.c')
    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('h5flow', i)

    return i

def build_h5cube(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('z hdf5 jansson deepylog cii pcre blosc hll dnet')

    pyx = 'lib/h5cube/h5cube_cy'
    name = 'lib/h5cube/h5cube'

    c_files = Split('lib/h5cube/h5cube_cy_helper.c')
    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('h5cube', i)

    return i

def build_pipedream(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('z jansson cii pcre')

    pyx = 'lib/pipedream/pipedream'
    c_files = Split('')
    o = build_cython_so(envcy, pyx, c_files, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('pipedream', i)

    return i

def build_percentile(env):

    pctl = env.SharedObject('lib/percentile/pctl.cpp',
            CPPPATH=['lib/percentile'],
            LIBS=['m', 'stdc++'],
            CCFLAGS=['-O3', '-Wall', '-Werror'])
    so = 'lib/percentile/libdfpctl.so'
    pctllib = env.SharedLibrary(so, [pctl])
    install_so = env.Install(PYX_INSTALL_DIR, pctllib)
    env.Alias('pctl', pctllib)
    set_general_depends(pctllib, env)
    return [install_so]

def build_deepy(envcy, deps=None):
    if not deps:
         deps = []

    deps += Split('pipedream z jansson cii pcre')
    pyx = 'lib/deepy/cube_cy'
    c_files = Split('lib/deepy/cube_cy_helper.c')
    o = build_cython_so(envcy, pyx, c_files, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    deepy_dst = os.path.join(PYX_INSTALL_DIR, "deepy")
    builder_dst = os.path.join(PYX_INSTALL_DIR, "builder")
    build_dst = os.path.join(PYX_INSTALL_DIR, "deepy", "build")
    event_dst = os.path.join(PYX_INSTALL_DIR, "deepy", "event")
    impala_dst = os.path.join(PYX_INSTALL_DIR, "deepy", "impala")
    impala_apply_dst = os.path.join(PYX_INSTALL_DIR, "deepy", "impala", "apply")
    celery_dst = os.path.join(PYX_INSTALL_DIR, "deepy", "ui_celery")
    install_so = envcy.Install(deepy_dst, o)

    deepy_src = Glob('lib/deepy/*.py')
    install_deepy = envcy.Install(deepy_dst, deepy_src)

    builder_src = Glob('lib/builder/*.py')
    install_builder = envcy.Install(builder_dst, builder_src)

    build_src = Glob('lib/builder/*.py')
    install_build = envcy.Install(build_dst, build_src)

    event_src = Glob('lib/deepy/event/*.py')
    install_event = envcy.Install(event_dst, event_src)

    impala_src = Glob('lib/deepy/impala/*.py')
    install_impala = envcy.Install(impala_dst, impala_src)

    impala_apply_src = Glob('lib/deepy/impala/apply/*.py')
    install_impala_apply = envcy.Install(impala_apply_dst, impala_apply_src)

    celery_src = Glob('lib/deepy/ui_celery/*.py')
    install_celery = envcy.Install(celery_dst, celery_src)

    return [install_deepy, install_build, install_event, install_impala, install_celery, install_so, install_impala_apply]

def build_routemap(envcy, deps=None):
    if not deps:
        deps = []

    deps += Split('pipedream hdf5 cii z jansson deepylog')

    pyx = 'lib/routemap/routemap_cy'
    name = 'lib/routemap/h5routemap'

    c_files = Split('lib/routemap/routemap.c lib/routemap/routemap_extra.c')
    o = build_cython_so(envcy, pyx, c_files, name=name, LIBPREFIX='', LIBS=deps)

    set_general_depends(o, envcy)

    i = envcy.Install(PYX_INSTALL_DIR, o)
    envcy.Alias('routemap', i)

    return i

def add_options():
    AddOption('--aliases',
        dest='aliases',
        action='store_true',
        help='print possible aliases')

    AddOption('--verbose',
        dest='verbose',
        action='store_true')

def build_wheels_actions():
    wheel_commands = ['@python build_deps/build-wheels.py']
    return wheel_commands

def install_udf(env, udflib, name, so, func_prefix, alias):
    _install = env.Install(UDFS_DIR, udflib)
    descfn, write_desc_func = write_udf_description(name, so, func_prefix)
    write_desc = env.Command(descfn, _install, write_desc_func)
    env.Depends(write_desc, _install)
    env.Alias('udf:' + alias, write_desc)
    return write_desc

def write_udf_description(name, so, func_prefix):
    #XXX could pass in sql, for now, all udfs are the same ...
    sql = ['create database if not exists udfs',
    'drop aggregate function if exists udfs.{name}(double)'.format(name=name),
    '''create aggregate function udfs.{name}(double) returns string
      location '/udfs/{so}'
      init_fn='{pfx}Init'
      update_fn='{pfx}Update'
      merge_fn='{pfx}Merge'
      serialize_fn='{pfx}Serialize'
      finalize_fn='{pfx}Finalize'
    '''.format(name=name, so=so, pfx=func_prefix)]
    fn = os.path.join(UDFS_DIR, name + '.json')
    desc = {'so':so, 'sql':sql}
    def construct(target, source, env):
        with open(fn, 'w') as fp:
            json.dump(desc, fp, indent=2)
    return fn, construct

def main():

    ################################################################################
    # Setup Build environments
    ################################################################################

    # Figure out the pipedream home var
    home = setup_pipedream_vars()

    # Setup the main build environment
    env = BASE_ENVIRONMENT.Clone(CFLAGS=CFLAGS,
            IMPLICIT_COMMAND_DEPENDENCIES=0,
            ENV = {"PATH":os.environ["PATH"],"SSH_AUTH_SOCK":os.environ.get("SSH_AUTH_SOCK"),"SSH_AGENT_PID":os.environ.get("SSH_AGENT_PID"),"SSH_AGENT_LAUNCHER":os.environ.get("SSH_AGENT_LAUNCHER")}
            ) #, **color_env)
    install.TOOL_INSTALL(env)

    # Copy environment variables over to build environment
    for var in ('PATH', 'PYTHONPATH', 'PIPEDREAM_HOOD'):
        if var in os.environ:
            env['ENV'][var] = os.environ[var]

    # Always run OS-specific build config
    os_specific_environment_setup = build_environment(env)
    env.AlwaysBuild(os_specific_environment_setup)

    # Setup cython environment
    envcy = setup_cython_env()

    # Setup virtual env paths
    if is_virtenv():
        env['ENV']['VIRTUAL_ENV'] = os.environ.get('VIRTUAL_ENV')
        env['ENV']['PATH'] = "%s:%s" % \
            (os.path.join(os.environ.get('VIRTUAL_ENV') , 'bin'), env['ENV']['PATH'])

    global general_depends
    general_depends = []

    # Build third party
    third_party_env = BASE_ENVIRONMENT.Clone(CFLAGS=CFLAGS,
            IMPLICIT_COMMAND_DEPENDENCIES=0,

            ENV = {"PATH":os.environ["PATH"]})
    third_party_deps = third_party(third_party_env)

    # https://github.com/romanbsd/fast-stemmer/issues/9
    if is_mac():
        unused_flag = '-Wno-error=unused-command-line-argument-hard-error-in-future'
        env['ENV']['ARCHFLAGS'] = unused_flag
        third_party_env['ENV']['ARCHFLAGS'] = unused_flag
        envcy['ENV']['ARCHFLAGS'] = unused_flag

    ################################################################################
    # Phony Targets (aliases for commands)
    ################################################################################

    upload_wheels_commands = []
    if os.path.exists(WHEELHOUSE_DIR):
        upload_wheels_commands.append('@s3cmd sync --acl-public "{}/" "{}"'.format(WHEELHOUSE_DIR, S3CMD_WHEELHOUSE_DIR))

    exec_env = BASE_ENVIRONMENT.Clone(ENV=os.environ)
    PhonyTargets(exec_env,
        TEST=['@echo test1', '@env'],
        wheels=build_wheels_actions(),
        upload_wheels=upload_wheels_commands,
        tar_wheels=['@tar cvfz {} {}'.format('wheels.tar.gz', WHEELHOUSE_DIR)],
        tarapt=['@tar cvfz apt.tar.gz /var/cache/apt/archives/ /var/lib/apt/lists'],
        upload_tarapt=['@s3cmd put --acl-public apt.tar.gz "%s"' % (S3CMD_TARAPT_DIR)],
        salt_development=['@cd {}/salt-states; git pull'.format(HOME), '@sudo salt-call --local -l debug state.highstate'],
        development=['@cd {}/salt-states; pwd; git pull'.format(HOME), '@sudo salt-call --local -l debug state.highstate', link_git_hooks],
        link_git_hooks=[link_git_hooks],
        salt_highstate=['@sudo salt-call state.highstate'],
        test=['@pdtest.py run -u'],
        fulltest=['@pdtest.py run'],
    )

    ################################################################################
    # lib/flow
    ################################################################################

    cs = Split('lib/flow/netflow.c lib/flow/netflow_strings.c lib/flow/sflow.c')
    set_general_depends(cs, env, default_target=False)
    libflow = env.StaticLibrary('lib/flow/libflow.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC'])
    env.Alias('libflow', libflow)
    set_general_depends(libflow, env)

    ################################################################################
    # third-party/cityhash-c
    ################################################################################

    cs = 'third-party/cityhash-c/city.c'
    set_general_depends(cs, env, default_target=False)
    libcityhash = env.StaticLibrary('third-party/cityhash-c/libcityhash.a', cs, CFLAGS=CFLAGS+['-fPIC', '-msse4.2', '-O3'])
    env.Alias('cityhash', libcityhash)
    set_general_depends(libcityhash, env)

    ################################################################################
    # lib/ipfrag
    ################################################################################

    cs = 'lib/ipfrag/ipfrag.c'
    set_general_depends(cs, env, default_target=False)
    libipfrag = env.StaticLibrary('lib/ipfrag/libipfrag.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC'])
    set_general_depends(libipfrag, env)

    ################################################################################
    # lib/deepylog
    ################################################################################

    cs = 'lib/deepylog/deepylog.c'
    set_general_depends(cs, env, default_target=False)
    libdeepylog = env.StaticLibrary('lib/deepylog/libdeepylog.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC'])
    env.Alias('libdeepylog', libdeepylog)
    set_general_depends(libdeepylog, env)

    ################################################################################
    # lib/hll
    ################################################################################

    cs = Split('lib/hll/hll.c lib/hll/hll_constants.c lib/hll/murmur.c')
    set_general_depends(cs, env, default_target=False)
    libhll = env.StaticLibrary('lib/hll/libhll.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC', '-std=c99'])
    env.Alias('libhll', libhll)
    set_general_depends(libhll, env)

    ################################################################################
    # third-party/blosc
    ################################################################################

    cs = Split('third-party/blosc/blosc/blosc.c third-party/blosc/blosc/blosclz.c third-party/blosc/blosc/shuffle.c third-party/blosc/hdf5/blosc_filter.c')
    set_general_depends(cs, env, default_target=False)
    libblosc = env.StaticLibrary('third-party/blosc/blosc/libblosc.a', cs, CFLAGS=CFLAGS+['-I/usr/local/include', '-fPIC', '-msse4.2', '-O3'])
    set_general_depends(libblosc, env)
    env.Alias('blosc', libblosc)

    ################################################################################
    # lib/pipedream
    ################################################################################

    cs = [os.path.join('lib/pipedream',x)
       for x in Split('prefix.c ptrie.c predicates.c dcap.c fileutil.c')]
    set_general_depends(cs, env, default_target=False)
    libpipedream = env.StaticLibrary('lib/pipedream/libpipedream.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC'], LIBS=['python2.7'])
    set_general_depends(libpipedream, env)

    pipedream_install = build_pipedream(envcy)

    ################################################################################
    # lib/dimensions
    ################################################################################

    cs = Split('lib/dimensions/dimensions.c  lib/dimensions/genome.c lib/dimensions/geoip.c')
    set_general_depends(cs, env, default_target=False)
    libdims = env.StaticLibrary('lib/dimensions/libdimensions.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC', '-g'])
    set_general_depends(libdims, env)

    dimensions_install = build_dimensions(envcy, [libpipedream])

    ################################################################################
    # lib/dnsflow
    ################################################################################

    cs = Split('lib/dnsflow/dnsflow.c')
    set_general_depends(cs, env, default_target=False)
    libdnsflow = env.StaticLibrary('lib/dnsflow/libdnsflow.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC', '-g'])
    set_general_depends(libdnsflow, env)

    dnsflow_install = build_dnsflow(envcy, [libdims, libdeepylog, libpipedream, libblosc, libhll])

    ################################################################################
    # lib/bgp
    ################################################################################

    cs = Split('lib/bgp/bgp.c')
    set_general_depends(cs, env, default_target=False)
    libbgp = env.StaticLibrary('lib/bgp/libbgp.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC', '-g'])
    set_general_depends(libbgp, env)

    bgp_install = build_bgp(envcy, [libblosc, libpipedream])

    ################################################################################
    # lib/classify -- just the library (Ordering issue)
    ################################################################################

    cs = Split('lib/classify/classify.c')
    set_general_depends(cs, env, default_target=False)
    libclassify = env.StaticLibrary('lib/classify/libclassify.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC', '-g'])
    set_general_depends(libclassify, env)

    ################################################################################
    # lib/h5flow
    ################################################################################

    cs = Split('lib/h5flow/h5flow.c')
    set_general_depends(cs, env, default_target=False)
    libh5flow = env.StaticLibrary('lib/h5flow/libh5flow.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC', '-g'])
    set_general_depends(libh5flow, env)

    h5flow_install = build_h5flow(envcy, [libblosc, libdims, libh5flow, libdnsflow, libbgp, libpipedream, libclassify, libflow, libipfrag, libhll])

    ################################################################################
    # lib/classify -- Just the cython
    ################################################################################

    classify_install = build_classify(envcy, [libblosc, libdims, libh5flow, libdnsflow, libbgp, libpipedream, libhll])

    ################################################################################
    # lib/h5cube
    ################################################################################

    h5cube_install = build_h5cube(envcy, [libblosc, libdims, libclassify, libh5flow, libdnsflow, libpipedream])

    ################################################################################
    # lib/routemap
    ################################################################################

    # remove this should we find we don't use this
    # cs = [os.path.join('lib/routemap',x)
    #      for x in Split('routemap.c')]
    # set_general_depends(cs, env, default_target=False)
    # libroutemap = env.StaticLibrary('lib/routemap/routemap.a', cs, CPPPATH=INCLUDES, CFLAGS=CFLAGS+['-fPIC'])
    # set_general_depends(libroutemap, env)

    deps = [libpipedream, libdims, libbgp, libblosc]
    routemap_install = build_routemap(envcy, deps)

    ################################################################################
    # lib/deepy
    ################################################################################

    deps = [libcityhash, libpipedream]
    deepy_install_list = build_deepy(envcy, deps)

    ################################################################################
    # flowd
    ################################################################################
    percentile_install = build_percentile(env)

    ################################################################################
    # flowd
    ################################################################################

    #flowd_fns = Split('flowd.c pcap.c')
    #set_general_depends(flowd_fns, env, default_target=False)
    #flowd_fns = [os.path.join('flowd', x) for x in flowd_fns]

    #sublibs = Split('pcap flow pipedream deepylog ipfrag cii dnet event z jansson pcre')
    #if is_linux():
    #    sublibs += Split('rt crypt')
    #flowd = env.Program(flowd_fns, CPPPATH=INCLUDES,
    #        CPPDEFINES=CPPDEFINES, LIBS=sublibs, LIBPATH=LIBPATHS)

    deps = [libpipedream, libdeepylog, libflow, libipfrag]
    flowd_install = build_flowd(envcy, deps)


    ################################################################################
    # benchmarking
    ################################################################################

    rs_fns = Split('benchmarking/benchmark.c')
    set_general_depends(rs_fns, env, default_target=False)
    benchmarklibs = Split('pthread h5flow libblosc hdf5 dimensions pipedream cii z jansson hll m deepylog')

    rs = env.Program(rs_fns,
            CPPPATH=INCLUDES,
            CPPDEFINES=CPPDEFINES, LIBS=benchmarklibs, LIBPATH=LIBPATHS)
    set_general_depends(rs, env)
    env.Install(SCRIPT_DIR, [rs])
    env.Alias('benchmark', rs)

    ################################################################################
    # cloudmapping
    ################################################################################

    rs_fns = Split('cloudmapping/dns_regexp.c')
    set_general_depends(rs_fns, env, default_target=False)
    sublibs = Split('pipedream cii z jansson pcre')
    rs = env.Program(rs_fns,
            CPPPATH=INCLUDES,
            CPPDEFINES=CPPDEFINES, LIBS=sublibs, LIBPATH=LIBPATHS)
    set_general_depends(rs, env)
    env.Install(SCRIPT_DIR, [rs])
    env.Alias('dns_regexp', rs)

    ################################################################################
    # install python/scripts
    ################################################################################

    pyfiles = Glob('*/*.sh')
    pyfiles += Glob('*/*.py')

    # Replicate exactly what the Makefile was doing
    pyfiles += Glob('connectors/shared/routers.py')
    pyfiles += Glob('connectors/shared/bgp_routers.py')
    pyfiles += Glob('connectors/shared/interfaces.py')
    pyfiles += Glob('connectors/shared/peers.py')
    pyfiles += Glob('connectors/shared/dnsflow_connector.py')
    pyfiles += Glob('connectors/shared/aspaths.py')
    pyfiles += Glob('connectors/shared/community.py')
    pyfiles += Glob('connectors/shared/pops.py')
    pyfiles += Glob('connectors/shared/dscp.py')
    pyfiles += Glob('connectors/shared/bgproute.py')
    pyfiles += Glob('connectors/shared/dns_resolvers.py')
    pyfiles += Glob('connectors/shared/ixp.py')
    pyfiles += Glob('connectors/shared/aggregation_connector.py')
    pyfiles += Glob('connectors/shared/asn.py')
    pyfiles += Glob('connectors/shared/interconnection.py')
    pyfiles += Glob('connectors/shared/capacity_information.py')
    pyfiles += Glob('connectors/shared/capacity_status.py')
    pyfiles += Glob('connectors/shared/peer_relationship.py')
    pyfiles += Glob('connectors/telarg/access_type.py')
    pyfiles += Glob('connectors/aliant/access.py')

    pyfiles += Glob('lib/deepy/linkedin.py')
    pyfiles += Glob('flowd/flowd_tests/flowd_util.py')
    pyfiles += Glob('lib/deepy/pybird.py')

    pyfiles += Glob('deployment/impala/insertcube.py')
    pyfiles += Glob('deployment/impala/compact_cubes.py')
    pyfiles += Glob('deployment/impala/loadcubequeue.py')
    pyfiles += Glob('deployment/impala/test_impalad.py')
    pyfiles += Glob('deployment/impala/impala_index.py')

    pyfiles += Glob('deployment/vss/vss-make-vss-cubes.py')
    pyfiles += Glob('deployment/vss/vss-master-fetch.py')

    # don't install these python files
    EXCEPTIONS = Split('lib/setup.py lib/flow/setup.py')
    def is_exc(sf):
        f = sf.path
        val = f in EXCEPTIONS or f.startswith('ui') or f.endswith('tests.py') or f.endswith('__init__.py')
        return not val
    pyfiles = filter(is_exc, pyfiles)

    install_py = env.Install(SCRIPT_DIR, pyfiles)
    env.Alias('python', install_py)

    ################################################################################
    # source script to run in order to run without installing and sudo
    ################################################################################

    code_root = os.path.abspath(os.getcwd())

    with open('setup.sh', 'w') as fp:
        pydirs = Split('lib lib/flowd lib/classify lib/pipedream lib/dimensions lib/dnsflow lib/bgp lib/h5flow lib/routemap lib/h5cube lib/testing/scripts async_celery')
        pydirs += third_party_python_dirs
        for pd in pydirs:
            pd = os.path.join(code_root, pd)
            print >>fp, 'export PYTHONPATH={}:$PYTHONPATH'.format(pd)
        print >>fp, 'export PYTHONPATH={}:$PYTHONPATH'.format(code_root)
        pd = os.path.join(code_root, 'config/components_db.json')
        print >>fp, 'export PIPEDREAM_COMPONENTS_DB={}'.format(pd)

        pydirs = Split('flow mine ddos probe flowd classify bundles dimensions cron_jobs crawling bgp routemap connectors/shared flowd flowd/flowd_tests dnsflow')
        pydirs += Split('search_ips deployment cube status routeviews snmp jobs cloudmapping genome ui qa lib/testing/scripts deployment/impala deployment/vss async_celery')
        for pd in pydirs:
            pd = os.path.join(code_root, pd)
            print >>fp, 'export PATH={}:$PATH'.format(pd)

        fpath = os.path.join(code_root, 'util', 'cflow.lua')
        print >>fp, 'export CFLOW_LUA={}'.format(fpath)

        if 'CONDA_DEFAULT_ENV' in os.environ:
            if is_mac():
                print >>fp, 'export DYLD_FALLBACK_LIBRARY_PATH={}:/usr/lib'.format(os.path.join(os.environ['CONDA_DEFAULT_ENV'], 'lib'))
            elif is_linux():
                print >>fp, 'export LD_LIBRARY_PATH={}'.format(os.path.join(os.environ['CONDA_DEFAULT_ENV'], 'lib'))

    ################################################################################
    # deployment-files
    ################################################################################

    config_files = Split('''components_db.json attributes.json
                            geoip_latlon_db.json maxmind_city_locations.csv.gz
                            zips.json countries.json rc.json roles.json
			    system_context.json
                            cablelabs-isp.json.gz
                            cablelabs-paths.json.gz
                            cablelabs-sources.json.gz''')
    config_files = [os.path.join('config', x) for x in config_files]
    config_install = env.Install(DEFINES_DIR, config_files)
    env.Alias('defines', config_install)

    if is_linux():
        snmpd_files= Split('snmpd/etc/default/snmpd snmpd/etc/snmp/snmpd.conf')
        snmpd_install = env.Install(DEFINES_DIR, snmpd_files)
        env.Alias('snmpd', snmpd_install)

    staging = env.Install(INSTALL_DIR, 'staging')
    env.Alias('staging', staging)
    pdrops = os.path.join(INSTALL_DIR, 'staging', 'shared', 'pdrops.key')
    env.AddPostAction(staging, env.Chmod(pdrops, 0600))
    env.AlwaysBuild(staging)

    ################################################################################
    # udfs
    ################################################################################

    # impala udfs only compile on 12.04 right now
    udflibs = []
    if os_version() == '12.04' and os.path.exists('/usr/include/impala_udf/udf.h'):
        udflibs = []
        exports = 'UDFS_DIR write_udf_description install_udf'
        udflibs.append(env.SConscript('udfs/percentile/SConstruct', exports=exports))
        udflibs.append(env.SConscript('udfs/dsq/clinear/SConstruct', exports=exports))
        env.Alias('udfs', udflibs)

    ################################################################################
    # lein pqwriter
    ################################################################################

    javafn = [
        'deployment/impala/pqwriter/src/main/java/com/deepfield/parquet/PQWriter.java',
        'deployment/impala/pqwriter/src/main/java/com/deepfield/parquet/PQMetaReader.java',
        'deployment/impala/pqwriter/src/main/java/com/deepfield/parquet/PQMain.java',
    ]
    jarfn = 'deployment/impala/pqwriter/target/pqwriter-0.1.0-SNAPSHOT-standalone.jar'
    def build_pqwriter(target, source, env):
        d = os.getcwd()
        os.chdir('deployment/impala/pqwriter')
        cmd = '../lein uberjar'
        if os.getuid() == 0: # root
            cmd = 'LEIN_ROOT=1 ../lein uberjar'
        subprocess.call(cmd, shell=True)
        os.chdir(d)
    jar = env.Command(jarfn, javafn, build_pqwriter)
    env.Alias('jar', jar)
    jar_install = env.Install(JAR_DIR, jar)
    env.Alias('install-jar', jar_install)

    ################################################################################
    # ui
    ################################################################################

    # run the grunt build script
    def build_grunt(source, target, env):
        print 'Running Grunt build'
        d = os.getcwd()
        os.chdir('ui')
        cmd = ['grunt build --target=development']
        return_code = subprocess.check_call(cmd, shell=True)

        if os.getuid() == 0:
            cmd = ['chmod 777 -R static/build']
            return_code = subprocess.check_call(cmd, shell=True)

        os.chdir(d)

    grunt_src = [
        'ui/static/lib/jquery-ui/css/jquery-ui-1.9.1.custom.css',
        Glob('ui/*.py'),
        Glob('ui/templates/*'),
        Glob('ui/templates/tpl/*'),
        Glob('ui/static/lib/jquery/plugins/css/*.css'),
        Glob('ui/static/lib/pickadate/themes/*.css'),
        Glob('ui/static/lib/d3/plugins/css/cubism.css'),
        Glob('ui/static/lib/*/*.css'),
        Glob('ui/static/lib/*/css/*.css'),
        Glob('ui/static/css/*'),
        Glob('ui/static/js/*'),
        Glob('ui/static/js/*/*'),
        Glob('ui/static/js/*/*/*'),
        Glob('ui/static/js/lib/*/*'),
        Glob('ui/static/js/lib/*/*/*'),
        Glob('ui/static/js/lib/*/*/*/*')
    ]

    grunt_build = None
    if not ARGUMENTS.get('no-grunt'):
        grunt_build = env.Command(['ui/static/build/vendor.css' , 'ui/static/build/deepfield.css', 'ui/static/build/templates/chrome.html'], grunt_src, build_grunt)
        env.Alias('grunt_build', grunt_build)
        env.Default(grunt_build)

    # run the grunt build script
    def install_grunt(source, target, env):
        print 'Installing Grunt files'
        d = os.getcwd()
        os.chdir('ui')
        cmd = ['grunt build --distpath=' + UI_DIR]
        return_code = subprocess.check_call(cmd, shell=True)
        os.chdir(d)

    grunt_install = None
    if not ARGUMENTS.get('no-grunt'):
        grunt_install = env.Command("DOES_NOT_EXIST", ['ui/static/build/vendor.css' , 'ui/static/build/deepfield.css', 'ui/static/build/templates/chrome.html'], install_grunt)
        env.Alias('grunt_install', grunt_install)

    ################################################################################
    # install alias
    ################################################################################

    cert = env.Install(os.path.join(home, 'cert'), 'ui/cert/deepfieldkey.pem')

    ################################################################################
    # data-dirs
    ################################################################################

    datadirs = Split('''cache flows log tmp tmp/pids cert cache/config''')
    ddalias = []
    for ddir in datadirs:
        datadir = os.path.join(home, ddir)
        ddalias.append(env.Command(datadir, '', Mkdir(datadir)))
    env.Alias('data-dirs', ddalias)

    ################################################################################
    # record install
    ################################################################################

    current_install_fn = os.path.join(home, 'current-install.json')
    def _record_install(target, source, env):
        cmd = 'git rev-parse HEAD'
        rev = subprocess.check_output(cmd, shell=True)
        rev = rev.rstrip('\n')

        now = datetime.datetime.utcnow()

        current_install = {
            'revision': rev,
            'timestamp': calendar.timegm(now.utctimetuple()),
            'buildTime': str(now)
        }

        with open(current_install_fn, 'w') as fp:
            print >>fp, json.dumps(current_install, indent=4)

        # TEMP Clean up the old non-json file
        if os.path.isfile(os.path.join(home, 'current-install')):
            os.remove(os.path.join(home, 'current-install'))
    record_install = env.Command(current_install_fn, [], _record_install)
    env.AlwaysBuild(record_install)

    ################################################################################
    # record source dir
    ################################################################################

    code_root_fn = os.path.join(home, 'code_root')
    def _record_code_root(target, source, env):
        with open(code_root_fn, 'w') as fp:
            print >>fp, os.getcwd()
    record_code_root = env.Command(code_root_fn, [], _record_code_root)
    env.AlwaysBuild(record_code_root)

    ################################################################################
    # record pipedream user
    ################################################################################

    support_user_fn = os.path.join(home, 'support_user')
    def _record_support_user(target, source, env):
        with open(support_user_fn, 'w') as fp:
            print >>fp, os.environ.get('SUDO_USER')
    record_support_user = env.Command(support_user_fn, [], _record_support_user)
    env.AlwaysBuild(record_support_user)

    ################################################################################
    # install alias
    ################################################################################
    install_list = deepy_install_list + [SCRIPT_DIR, INSTALL_DIR, DEFINES_DIR, grunt_build, grunt_install, staging, cert, ddalias,
            record_install, record_support_user, record_code_root, pipedream_install,
            dimensions_install, dnsflow_install, bgp_install, h5flow_install, classify_install,
            h5cube_install, routemap_install, flowd_install, third_party_deps,
            jar_install, udflibs, percentile_install]
    for k,v in third_party_deps_install.iteritems():
        install_list += v
    if is_linux():
        install_list += snmpd_install

    # As the last thing, run upgrader when doing install.
    do_upgrade = env.Command('.upgrade_target', None, os.path.join(SCRIPT_DIR, 'upgrade_run.py'))
    env.Depends(do_upgrade, install_list)
    env.Alias('install', do_upgrade)

    cleanup_old_files(env, do_upgrade)

    uninstall = env.Command('.uninstall', None, Delete(FindInstalledFiles()))
    env.Alias('uninstall', uninstall)

    # Build debian package
    build_package = env.Command('debian.deb', None, "dpkg-deb --build debian/")
    env.Depends(build_package, install_list)
    env.Alias('build-package', build_package)

    # Leave this at the bottom of main() so we have all the aliases defined
    if GetOption("aliases"):
        print "Available aliases: \n\t%s" % ('\n\t'.join(sorted(SCons.Node.Alias.default_ans.keys())))
        sys.exit()


################################################################################
# remove old files
################################################################################

def cleanup_old_files(env, install):
    SCRIPT_DIR = os.path.join('/', 'usr', 'local', 'sbin')
    for d in [SCRIPT_DIR, os.path.join(PYX_INSTALL_DIR, 'deepy')]:
        remove = Delete(Glob(os.path.join(d, '*.pyc')))
        env.AddPostAction(install, remove)

    #Also, explicitly remove flowd.py to avoid conflicts
    remove = Delete(Glob(os.path.join(SCRIPT_DIR, 'flowd.py')))
    env.AddPostAction(install, remove)


################################################################################
# colors
################################################################################

def setup_colors():
    # If the output is not a terminal, remove the colors
    if not sys.stdout.isatty() or not is_linux():
        return {}

    cyan   = '\033[96m'
    purple = '\033[95m'
    blue   = '\033[94m'
    green  = '\033[92m'
    yellow = '\033[93m'
    red    = '\033[91m'
    end    = '\033[0m'

    compile_source_message = '%sCompiling %s==> %s$SOURCE%s' % \
            (blue, purple, yellow, end)

    compile_shared_source_message = '%sCompiling shared %s==> %s$SOURCE%s' % \
            (blue, purple, yellow, end)

    link_program_message = '%sLinking Program %s==> %s$TARGET%s' % \
            (red, purple, yellow, end)

    link_library_message = '%sLinking Static Library %s==> %s$TARGET%s' % \
            (red, purple, yellow, end)

    ranlib_library_message = '%sRanlib Library %s==> %s$TARGET%s' % \
            (red, purple, yellow, end)

    link_shared_library_message = '%sLinking Shared Library %s==> %s$TARGET%s' % \
            (red, purple, yellow, end)

    env_colors = {'CXXCOMSTR' : compile_source_message,
            'CCCOMSTR' : compile_source_message,
            'SHCCCOMSTR' : compile_shared_source_message,
            'SHCXXCOMSTR' : compile_shared_source_message,
            'ARCOMSTR' : link_library_message,
            'RANLIBCOMSTR' : ranlib_library_message,
            'SHLINKCOMSTR' : link_shared_library_message,
            'LINKCOMSTR' : link_program_message}

    return env_colors

def setup_pipedream_vars():
    hood = os.environ.get('PIPEDREAM_HOOD', '/')
    home = os.environ.get('PIPEDREAM_HOME', 'pipedream')
    home = os.path.join(hood, home)
    return home

def link_git_hooks(*args, **kwargs):
    # global __file__ is not set
    # $PIPEDREAM_CHECKOUT is nonstandard
    # see https://stackoverflow.com/q/9806573
    repo = Dir('.').srcnode().abspath
    if not os.path.isdir(repo):
      return

    df_hooks = os.path.join(repo, 'git-hooks')
    local_hooks = os.path.join(repo, '.git/hooks')
    remove_local = ['rm', '-rf', local_hooks]
    create_link = ['ln', '-s', df_hooks, local_hooks]

    print "[INFO    ] Removing local git hooks:", local_hooks
    subprocess.call(remove_local)

    print "[INFO    ] Linking git hooks:", df_hooks
    subprocess.call(create_link)

add_options()
VERBOSE = GetOption("verbose")
main()

