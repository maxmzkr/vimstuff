"""Used to test the jobs that are in jobs"""

import unittest
import mock
import os.path
import concurrent.futures

import testing
import builder.build
import builder.jobs
from builder.build import BuildManager
from builder.execution import ExecutionManager, ExecutionResult
from builder.tests.tests_jobs import EffectJobDefinition
from builder.tests.execution_tests import ExtendedMockExecutor

import deepy.build.deepy_jobs
import deepy.build.deepy_build
from deepy.build.deepy_build import DeepyBuildManager
import deepy.build.deepy_util
import deepy.build.deepy_jobs as deepy_jobs
import deepy.build.deepy_targets as deepy_targets
import deepy.build.deepy_execution as deepy_execution
import deepy.query_rules
import deepy.cfg
import deepy.timerange
import deepy.build.deepy_metas
arrow = deepy.timerange.arrow_factory

from testing import mock_infrastructure
from builder.tests.tests_targets import LocalFileSystemTargetTest, GlobLocalFileSystemTargetTest

class DeepyTest(unittest.TestCase):
    """Used to test the general graph construction of the deepy jobs"""

    @testing.unit
    def test_cube_sub_count_ip_version_5min(self):
        # Given
        rules_db = deepy.build.deepy_util.construct_rules()

        # When
        job = deepy.build.deepy_jobs.DeepyDictJob('cube_sub_count_ip_version_5min', rules_db)

        # Then
        self.assertEquals(job.get_type(), 'target')

    @testing.unit
    def test_drill1_hour_has_dimensions(self):
        # Given
        rules_db = deepy.build.deepy_util.construct_rules()

        # When
        job = deepy.build.deepy_jobs.DeepyDictJob('cube_drill1_hour', rules_db)

        # Then
        self.assertTrue(len(job.get_dimensions())>0)

    @testing.unit
    @mock_infrastructure('comcast2', config_only=True, exclude_dimensions=True)
    def test_get_command_with_format_args(self):
        # Given
        rules_db = deepy.build.deepy_util.construct_rules()
        t = arrow.get()
        build_context = {
            'start_time':t,
            'end_time': t,
        }
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build_graph = build_manager.make_build()

        # When
        job = deepy.build.deepy_jobs.DeepyDictJob('cube_aspaths_remote3_hour', rules_db)
        build_context['start_job'] = job.unexpanded_id
        build_graph.add_job(job.unexpanded_id, build_context, depth=1)
        states = job.expand(build_graph, build_context)


        # Then
        self.assertTrue(len(states) == 1)
        states[0].get_command()

    @testing.unit
    def test_basic_substitution(self):
        # Given
        command = ('cube_op.py $A -o '
                   '/Users/matt/env/deepfield-deploy/pipedream/cache/cubes/drill_small/minutes/cube.2014-01-27-08-55.h5 '
                   '-t 300  -A group_other(origin_asn.local,null,<c.top_origins>)  '
                   '-A group_other(aspaths.local,null,<c.top_aspaths>) -A group_other(origin_asn.remote,null,<c.top_origins>) '
                   '--arg_join c.top_origins=\'$(cubes_dir)/origin_asn.remote2/months/top_list.2014-01.json.gz\' '
                   '-A group_other(aspaths.remote,null,<c.top_aspaths>) --arg_join '
                   'c.top_aspaths=\'$(cubes_dir)/aspaths.remote2/months/top_list.2014-01.json.gz\' '
                   '-A group_other(sites,null,<c.top_sites>) -A group_other(company,null,<c.top_companies>) '
                   '--arg_join c.top_companies=\'$(cubes_dir)/company2/months/top_list.2014-01.json.gz\' '
                   '--arg_join c.top_sites=\'$(cubes_dir)/sites2/months/top_list.2014-01.json.gz\' {cube_drill1_5min}')
        ts = arrow.get("2014-01-01")
        # When
        substituted = deepy.build.deepy_util.basic_substitution(command, ts)

        # Then
        self.assertEquals(substituted, """cube_op.py $A -o /Users/matt/env/deepfield-deploy/pipedream/cache/cubes/drill_small/minutes/cube.2014-01-27-08-55.h5 -t 300  -A group_other(origin_asn.local,null,<c.top_origins>)  -A group_other(aspaths.local,null,<c.top_aspaths>) -A group_other(origin_asn.remote,null,<c.top_origins>) --arg_join c.top_origins='$(cubes_dir)/origin_asn.remote2/months/top_list.2014-01.json.gz' -A group_other(aspaths.remote,null,<c.top_aspaths>) --arg_join c.top_aspaths='$(cubes_dir)/aspaths.remote2/months/top_list.2014-01.json.gz' -A group_other(sites,null,<c.top_sites>) -A group_other(company,null,<c.top_companies>) --arg_join c.top_companies='$(cubes_dir)/company2/months/top_list.2014-01.json.gz' --arg_join c.top_sites='$(cubes_dir)/sites2/months/top_list.2014-01.json.gz' {cube_drill1_5min}""")

    @testing.unit
    def test_substitution(self):
        # Given
        fmt_str = '$(heartbeat_dir)/$(vm_uuid)/vm/vm.2014-01-06-17-25.json.gz'
        config = mock.Mock()
        config.heartbeat_dir = '/foo'
        config.vm_uuid = 'bar'

        # When
        substituted = deepy.build.deepy_util.deepy_substitution(fmt_str, config=config)

        # Then
        self.assertEquals("/foo/bar/vm/vm.2014-01-06-17-25.json.gz", substituted)

    @testing.unit
    def test_substitution_with_null(self):
        # Given
        fmt_str = '$(heartbeat_dir)/$(vm_uuid)/vm/vm.2014-01-06-17-25.json.gz'
        config = mock.Mock()
        config.heartbeat_dir = '/foo'
        config.vm_uuid = None

        # When
        substituted = deepy.build.deepy_util.deepy_substitution(fmt_str, config=config)

        # Then
        self.assertEquals("/foo/None/vm/vm.2014-01-06-17-25.json.gz", substituted)

    @testing.unit
    @mock_infrastructure('mediacom', config_only=True, exclude_dimensions=True)
    def test_drill_summary_commands(self):
        #  Given
        job_id = 'drill_cdn_summary'
        rules_db = deepy.build.deepy_util.construct_rules()
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build_graph = build_manager.make_build()
        t = arrow.get('2014-01-01')
        build_context = {
            'start_time':t,
            'end_time': t,
        }

        # When
        job = deepy.build.deepy_jobs.DeepyDictJob(job_id, rules_db)
        build_graph.add_meta(job.unexpanded_id, build_context, depth=1)
        commands = []
        for node_id, node in build_graph.node.iteritems():
            obj = node['object']
            if isinstance(obj, builder.jobs.Job):
                commands.append(obj.get_command())


        # Then
        correct = ('bundle2.py -M drill_day_cdn_summary -m ' +
                   deepy.cfg.cubes_dir + '/drill/cdn/days/markers/summary.2014-01-01.marker '
                   '-t 2014-01-01')
        self.assertEquals(commands[0], correct)
        self.assertEquals(1, len(commands))

    @testing.unit
    @mock_infrastructure('aliant', config_only=True, exclude_dimensions=True)
    def test_drill_commands(self):
        #  Given
        job_id = 'drill_cdn'
        rules_db = deepy.build.deepy_util.construct_rules()
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build_graph = build_manager.make_build()
        t = arrow.get('2014-01-01')
        build_context = {
            'start_time':t,
            'end_time': t,
        }

        # When
        job = deepy.build.deepy_jobs.DeepyDictJob(job_id, rules_db)
        build_graph.add_meta(job.unexpanded_id, build_context, depth=1)
        commands = []
        for node_id, node in build_graph.node.iteritems():
            obj = node['object']
            if isinstance(obj, builder.jobs.Job):
                commands.append(obj.get_command())


        # Then

        correct = ('bundle2.py -M drill_day_cdn -m ' +
                   deepy.cfg.cubes_dir + '/drill/cdn/days/markers/drill.2014-01-01.marker '
                   '-t 2014-01-01')
        self.assertEquals(commands[0], correct)
        self.assertEquals(1, len(commands))

    @testing.unit
    def test_cache_time_added(self):
        # Given
        job_id = "cube_drill1_day"
        rules_db = deepy.build.deepy_util.construct_rules()

        # When
        job = deepy.build.deepy_jobs.DeepyDictJob(job_id, rules_db)

        # Then
        self.assertEqual(job.cache_time, "2h")

    @testing.unit
    def test_glob_target(self):
        # Given
        job_id = "bgpdumps"
        rules_db = deepy.build.deepy_util.construct_rules()
        job = deepy.build.deepy_jobs.DeepyDictJob(job_id, rules_db)

        # When
        targets = job.get_targets()
        target = targets["produces"][0]

        target_type = target.base_class


        # Then
        self.assertEqual(target_type, deepy_targets.DeepyS3BackedGlobLocalFileSystemTarget)

    @testing.unit
    def test_h5flow_marker(self):
        # Given
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build1 = build_manager.make_build()
        build2 = build_manager.make_build()

        build_context1 = {
            "start_time": arrow.get("2015-03-12-01-05"),
            "end_time": arrow.get("2015-03-12-01-05"),
        }

        build_context2 = {
            "start_time": arrow.get("2015-03-12-01-05"),
            "end_time": arrow.get("2015-03-12-01-05"),
        }

        build1.add_job("cubes_from_h5flow_5min", build_context1, depth=1)
        build2.add_job("cubes_from_h5flow_5min", build_context2, depth=1)

        for _, target in build1.node.iteritems():
            target = target["object"]
            if isinstance(target, builder.targets.Target):
                if "marker" in target.unique_id:
                    target.mtime = arrow.get("2015-03-12-01-06").float_timestamp
                    target.cached_mtime = True
                else:
                    target.mtime = None
                    target.cached_mtime = True

        for _, target in build2.node.iteritems():
            target = target["object"]
            if isinstance(target, builder.targets.Target):
                if "marker" in target.unique_id:
                    target.mtime = arrow.get("2015-03-12-01-10").float_timestamp
                    target.cached_mtime = True
                else:
                    if build2.predecessors(target.unique_id):
                        target.mtime = arrow.get("2015-03-12-01-09").float_timestamp
                        target.cached_mtime = True
                    else:
                        target.mtime = arrow.get("2015-03-12-01-08").float_timestamp
                        target.cached_mtime = True

        expected_stale1 = False
        expected_stale2 = False

        # When
        should_run1 = build1.node["cubes_from_h5flow_5min_2015-03-12-01-05-00"]["object"].get_stale()
        should_run2 = build2.node["cubes_from_h5flow_5min_2015-03-12-01-05-00"]["object"].get_stale()

        # Then
        self.assertEqual(should_run1, expected_stale1)
        self.assertEqual(should_run2, expected_stale2)


class DeepyDictJobTest(unittest.TestCase):

    def _simple_job(self):
        rules_db = deepy.build.deepy_util.construct_rules()
        return deepy_jobs.DeepyDictJob(
            'cube_drill_small_5min', rules_db
        )

    def _multitarget_job(self):
        rules_db = deepy.build.deepy_util.construct_rules()
        return deepy_jobs.DeepyDictJob(
            'cubes_from_h5flow_5min', rules_db
        )


    def test_multitarget_job_get_targets(self):

        # Given
        job = self._multitarget_job()

        # When
        targets = job.get_targets({})

        # Then
        produced_expanders = targets['produces'] + targets['untracked']
        self.assertTrue(len(produced_expanders) > 1)
        unexpanded_ids = map(lambda x: x.unexpanded_id, produced_expanders)
        for produced in produced_expanders:
            self.assertTrue(produced.unexpanded_id in unexpanded_ids)
            self.assertTrue(produced.unexpanded_id is not None)

    def test_simple_job_get_target(self):
         # Given
        job = self._simple_job()

        # When
        targets = job.get_targets({})

        # Then
        produced_expanders = targets['produces']
        self.assertEquals(len(produced_expanders), 1)
        self.assertEquals(produced_expanders[0].unexpanded_id, '$(cubes_dir)/drill_small/minutes/cube.%Y-%m-%d-%H-%M.h5')


    def test_simple_job_get_dependencies(self):
         # Given
        job = self._simple_job()

        # When
        dependencies = job.get_dependencies({})
        depends = dependencies.get('depends')

        # Then
        self.assertTrue(len(dependencies) > 0)
        self.assertEquals(len(depends), 1)
        self.assertEquals(depends[0].unexpanded_id, '$(cubes_dir)/drill1/minutes/cube.%Y-%m-%d-%H-%M.h5')

    def test_multitarget_job_get_dependencies(self):
        # Given
        job = self._multitarget_job()

        # When
        dependencies = job.get_dependencies({})
        depends = dependencies.get('depends')

        # Then
        self.assertTrue(len(dependencies) > 0)
        self.assertEquals(len(depends), 1)
        self.assertEquals(depends[0].unexpanded_id, '$(h5flow_dir)/flow.%Y-%m-%d-%H-%M.h5')

    def test_impala_compaction_job(self):
        # Given
        job = deepy.build.deepy_jobs.DeepyImpalaCompactionJob(
                "dataset_name", "5min")

        # When
        targets = job.get_targets()
        dependencies = job.get_dependencies()
        depends_one_or_more_expander = dependencies["depends_one_or_more"][0]
        produces_expander = targets["produces"][0]

        build_context = {
            "start_time": arrow.get("2015-02-01T05:10"),
            "end_time": arrow.get("2015-02-02T06:15"),
        }
        expected_command = ("compact_cubes.py -i dataset_name -s "
                            "2015-02-01-05-10 -e 2015-02-01-05-10 "
                            "--step 300")
        actual_command = job.get_command("unique_id", build_context, None)

        # Then
        self.assertEqual(job.unexpanded_id,
                "deepfield_dataset_name_step5min_compaction")
        self.assertEqual(job.get_expandable_id(),
                "deepfield_dataset_name_step5min_compaction_%Y-%m-%d-%H-%M-%S")
        self.assertEqual(job.file_step, "1d")
        self.assertEqual(actual_command, expected_command)
        self.assertEqual(depends_one_or_more_expander.file_step, "5min")
        self.assertEqual(depends_one_or_more_expander.time_step, "5min")
        self.assertEqual(depends_one_or_more_expander.unexpanded_id,
                "deepfield_dataset_name_step5min_%Y-%m-%d-%H-%M")
        self.assertEqual(depends_one_or_more_expander.dataset_name, "dataset_name")
        self.assertEqual(depends_one_or_more_expander.compacted, False)
        self.assertEqual(produces_expander.file_step, "1d")
        self.assertEqual(produces_expander.time_step, "5min")
        self.assertEqual(produces_expander.unexpanded_id,
                "deepfield_dataset_name_step5min_compacted_%Y-%m-%d-%H-%M")
        self.assertEqual(produces_expander.dataset_name, "dataset_name")
        self.assertEqual(produces_expander.compacted, True)

    def test_impala_expander(self):
        # Given
        expander_min = deepy.build.deepy_expanders.DeepyImpalaExpander(
                "expanded_id_%Y-%m-%d-%H-%M", "5min", "5min", "dataset_name",
                compacted=False)
        expander_day = deepy.build.deepy_expanders.DeepyImpalaExpander(
                "expanded_id_%Y-%m-%d-%H-%M", "5min", "1d", "dataset_name",
                compacted=True)

        # When
        expanded_min = expander_min.expand({
                "start_time": arrow.get("2015-02-05T00:00"),
                "end_time": arrow.get("2015-02-06T00:00")
        })
        expanded_day = expander_day.expand({
                "start_time": arrow.get("2015-02-05T00:00"),
                "end_time": arrow.get("2015-02-06T00:00")
        })

        # Then
        self.assertEqual(len(expanded_min), 288)
        self.assertEqual(len(expanded_day), 1)

        for min_target in expanded_min:
            if (min_target.unexpanded_id == "expanded_id_%Y-%m-%d-%H-%M" and
                    min_target.unique_id == "expanded_id_2015-02-05-01-25" and
                    min_target.build_context == {
                            "start_time": arrow.get("2015-02-05T01:25"),
                            "end_time": arrow.get("2015-02-05T01:30"),
                    } and
                    min_target.dataset_name == "dataset_name" and
                    min_target.time_step == "5min" and
                    min_target.compacted == False):
                break
        else:
            self.assertTrue(False)

        self.assertEqual(expanded_day[0].unexpanded_id,
                "expanded_id_%Y-%m-%d-%H-%M")
        self.assertEqual(expanded_day[0].unique_id,
                "expanded_id_2015-02-05-00-00")
        self.assertEqual(expanded_day[0].build_context, {
                "start_time": arrow.get("2015-02-05T00:00"),
                "end_time": arrow.get("2015-02-06T00:00")
        })
        self.assertEqual(expanded_day[0].dataset_name, "dataset_name")
        self.assertEqual(expanded_day[0].time_step, "5min")
        self.assertEqual(expanded_day[0].compacted, True)

    def test_load_impala_jobs(self):
        # Given
        impala_config = mock.Mock()
        impala_config.slice_config = {
            "impala": {
                "load": {
                    "stream_bps": {
                        "step": "minutes",
                        "pattern": "bps/minutes",
                    },
                    "interface_hour": {
                        "step": "hours",
                        "cube": "interface",
                    },
                    "interface_day": {
                        "step": "days",
                        "cube": "interface",
                    },
                }
            }
        }

        # When
        deepy.build.deepy_util.construct_rules()
        with mock.patch("deepy.build.deepy_util.construct_rules") as dict, \
             mock.patch("deepy.cfg", impala_config):
            dict.return_value = {
                "cube_stream_bps_5min": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "target": "stream_bps_5min_target",
                    "file_step": "5min",
                },
                "cube_interface_hour": {
                    "meta": {
                        "cube_id": "interface",
                    },
                    "target": "interface_hour_target",
                    "file_step": "1h",
                },
                "cube_interface_day": {
                    "meta": {
                        "cube_id": "interface",
                    },
                    "target": "interface_day_target",
                    "file_step": "1d",
                },
            }
            build_manager = deepy.build.deepy_build.DeepyBuildManager()
            deepy_build = build_manager.make_build()

        dependency_jobs = deepy_build.rule_dependency_graph.predecessors("impala_compaction")
        dependency_views = deepy_build.rule_dependency_graph.predecessors(
                "impala_view_update")
        dependency_inserts = deepy_build.rule_dependency_graph.predecessors(
                "impala_inserts")

        # Then
        self.assertIn("deepfield_stream_bps_step5min_compaction",
                      deepy_build.rule_dependency_graph.node)
        job1 = deepy_build.rule_dependency_graph.node[
                "deepfield_stream_bps_step5min_compaction"]["object"]
        self.assertEqual(job1.dataset_name, "stream_bps")
        self.assertEqual(job1.time_step, "5min")
        self.assertEqual(job1.file_step, "1d")
        self.assertEqual(job1.curfew, "6h")

        self.assertIn("deepfield_interface_step1h_compaction",
                      deepy_build.rule_dependency_graph.node)
        job1 = deepy_build.rule_dependency_graph.node[
                "deepfield_interface_step1h_compaction"]["object"]
        self.assertEqual(job1.dataset_name, "interface")
        self.assertEqual(job1.time_step, "1h")
        self.assertEqual(job1.file_step, "1d")
        self.assertEqual(job1.curfew, "6h")

        self.assertNotIn("deepfield_interface_step1d_compaction",
                          deepy_build.rule_dependency_graph.node)

        self.assertEqual(len(dependency_jobs), 2)
        self.assertIn("deepfield_interface_step1h_compaction", dependency_jobs)
        self.assertIn("deepfield_stream_bps_step5min_compaction", dependency_jobs)

        view1 = deepy_build.rule_dependency_graph.node[
                "deepfield_stream_bps_step5min_view"]["object"]
        self.assertEqual(view1.dataset_name, "stream_bps")
        self.assertEqual(view1.time_step, "5min")

        self.assertEqual(len(dependency_views), 2)
        self.assertIn("deepfield_stream_bps_step5min_view", dependency_views)

        insert = deepy_build.rule_dependency_graph.node[
                "deepfield_interface_step1d_insert"]["object"]
        self.assertEqual(insert.dataset_name, "interface")
        self.assertEqual(insert.time_step, "1d")

        self.assertEqual(len(dependency_inserts), 3)
        self.assertIn("deepfield_interface_step1d_insert", dependency_inserts)

        insert_bps = deepy_build.rule_dependency_graph.node[
                "deepfield_stream_bps_step5min_insert"]["object"]
        self.assertEqual(insert_bps.get_dependencies()["depends"][0].unexpanded_id,
                         os.path.join("$(cache_dir)", "bps/minutes",
                                      "cube.%Y-%m-%d-%H-%M.h5"))


    def test_impala_view_update(self):
        # Given
        impala_job = deepy.build.deepy_jobs.ImpalaViewUpdate("dataset_name",
                                                             "5min")
        build_manager = builder.build.BuildManager([impala_job], [])
        build = build_manager.make_build()

        build.add_job("deepfield_dataset_name_step5min_view", {})

        # When
        job_state = build.node["deepfield_dataset_name_step5min_view"]["object"]
        should_run = job_state.get_should_run()
        expected_command = "update_view.py -i dataset_name --step 300"
        actual_command = impala_job.get_command(job_state.unique_id, {}, build)


        # Then
        self.assertTrue(should_run)
        self.assertEqual(actual_command, expected_command)

    def test_insert_cube(self):
        rules_db = {
            "cube_big_cube_5min": {
                "meta": {
                    "cube_id": "big_cube",
                },
                "depends": {
                    "cubes_from_h5flow_5min": "5min"
                },
                "time_step": "5min",
                "file_step": "5min",
                "target": "$(cubes_dir)/big_cube/minutes/cube.%Y-%m-%d-%H-%M.h5",
                "prune_ratio": 150.0
            },
        }
        job = deepy.build.deepy_jobs.InsertCube("big_cube", "5min", rules_db,
                                                None)
        job2 = deepy.build.deepy_jobs.InsertCube("stream_bps", "5min", rules_db,
                                                 "bps/minutes")


        # When
        targets = job.get_targets()
        dependencies = job.get_dependencies()
        depends_expander = dependencies["depends"][0]
        produces_expander = targets["produces"][0]

        build_context = {
            "start_time": arrow.get("2015-02-01T05:10"),
            "end_time": arrow.get("2015-02-02T06:15"),
        }

        build_context2 = {
            "start_time": arrow.get("2015-02-01T05:10"),
            "end_time": arrow.get("2015-02-02T06:15"),
        }

        build_manager = builder.build.BuildManager([job, job2], [])
        build = build_manager.make_build()

        build.add_job("deepfield_big_cube_step5min_insert", build_context)
        build.add_job("deepfield_stream_bps_step5min_insert", build_context2)

        expected_command = ("insertcube.py -i {}/big_cube/minutes/"
                            "cube.2015-02-01-05-10.h5".format(
                                    deepy.cfg.cubes_dir))
        expected_command2 = ("insertcube.py -i {}/bps/minutes/"
                             "cube.2015-02-01-05-10.h5".format(
                                    deepy.cfg.cache_dir))
        actual_command = job.get_command(
                "deepfield_big_cube_step5min_insert_2015-02-01-05-10-00",
                build_context, build)
        actual_command2 = job.get_command(
                "deepfield_stream_bps_step5min_insert_2015-02-01-05-10-00",
                build_context, build)

        # Then
        self.assertEqual(job.unexpanded_id,
                "deepfield_big_cube_step5min_insert")
        self.assertEqual(job.get_expandable_id(),
                "deepfield_big_cube_step5min_insert_%Y-%m-%d-%H-%M-%S")
        self.assertEqual(job.file_step, "5min")
        self.assertEqual(actual_command, expected_command)
        self.assertEqual(actual_command2, expected_command2)
        self.assertEqual(depends_expander.file_step, "5min")
        self.assertEqual(depends_expander.unexpanded_id,
                "$(cubes_dir)/big_cube/minutes/cube.%Y-%m-%d-%H-%M.h5")
        self.assertEqual(produces_expander.file_step, "5min")
        self.assertEqual(produces_expander.time_step, "5min")
        self.assertEqual(produces_expander.unexpanded_id,
                "deepfield_big_cube_step5min_%Y-%m-%d-%H-%M")
        self.assertEqual(produces_expander.dataset_name, "big_cube")
        self.assertEqual(produces_expander.compacted, False)

    def test_enabled(self):
        # Given
        fake_slice = {
            "enabled_jobs": {
                "slice_enabled": True,
                "slice_disabled": False,
            }
        }

        with mock.patch("deepy.cfg.slice_config", fake_slice):
            fake_rules_db = {
                "disabled_job": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "enabled": False,
                },
                "enabled_job": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "enabled": True,
                },
                "implicitly_enabled_job": {
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "time_step": "5min",
                },
                "implicit_enabled_job": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "time_step": "5min",
                },
                "slice_enabled": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "time_step": "5min",
                    "enabled": deepy.query_rules.slice_enabled("slice_enabled"),
                },
                "slice_disabled": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "time_step": "5min",
                    "enabled": deepy.query_rules.slice_enabled("slice_disabled"),
                },
                "implicit_slice_disabled": {
                    "meta": {
                        "cube_id": "stream_bps",
                    },
                    "depends": {
                        "classify_h5flow": "5min"
                    },
                    "recipe": [
                        "h5flow_bps.py $A -c vss -t %Y-%m-%d-%H-%M -r $^ -w $@"
                    ],
                    "target": "$(cache_dir)/bps/minutes/cube.%Y-%m-%d-%H-%M.h5",
                    "file_step": "5min",
                    "time_step": "5min",
                    "enabled": deepy.query_rules.slice_enabled("implicit_slice_disabled"),
                },
            }

        # When
        enabled_job = deepy.build.deepy_jobs.DeepyDictJob('enabled_job', fake_rules_db)
        disabled_job = deepy.build.deepy_jobs.DeepyDictJob('disabled_job', fake_rules_db)
        implicit_enabled_job = deepy.build.deepy_jobs.DeepyDictJob('implicit_enabled_job', fake_rules_db)
        slice_enabled = deepy.build.deepy_jobs.DeepyDictJob('slice_enabled', fake_rules_db)
        slice_disabled = deepy.build.deepy_jobs.DeepyDictJob('slice_disabled', fake_rules_db)
        implicit_slice_disabled = deepy.build.deepy_jobs.DeepyDictJob('implicit_slice_disabled', fake_rules_db)

        # Then
        self.assertTrue(enabled_job.get_enable())
        self.assertFalse(disabled_job.get_enable())
        self.assertTrue(implicit_enabled_job.get_enable())
        self.assertTrue(slice_enabled.get_enable())
        self.assertFalse(slice_disabled.get_enable())
        self.assertFalse(implicit_slice_disabled.get_enable())

    def test_extra_cron_job_enabled(self):
        # Given
        fake_empty_vm = {}
        fake_vm = {
            "extra_cron_jobs": [
                "job_id3"
            ]
        }
        job_id1 = "job_id1"
        job_id2 = "job_id2"
        job_id3 = "job_id3"


        # When
        with mock.patch("deepy.cfg.vm_config", fake_empty_vm):
            fake_rules_db = {
                "job_id1": {
                    "recipe": ["recipe"],
                    "enabled": deepy.query_rules.extra_cron_jobs_enabled("job_id1"),
                },
            }
            job1 = deepy.build.deepy_jobs.DeepyDictJob("job_id1", fake_rules_db)

        with mock.patch("deepy.cfg.vm_config", fake_vm):
            fake_rules_db = {
                "job_id2": {
                    "recipe": ["recipe"],
                    "enabled": deepy.query_rules.extra_cron_jobs_enabled("job_id2"),
                },
                "job_id3": {
                    "recipe": ["recipe"],
                    "enabled": deepy.query_rules.extra_cron_jobs.enalbed("job_id3"),
                },
            }
            job2 = deepy.build.deeepy_jobs.DeepyDictJob("job_id2", fake_rules_db)
            job3 = deepy.build.deeepy_jobs.DeepyDictJob("job_id3", fake_rules_db)

        # Then
        self.assertFalse(job1.get_enable())
        self.assertFalse(job2.get_enable())
        self.assertTrue(job3.get_enable())

class SpecificJobsTest(unittest.TestCase):

    def _make_deepy_build(self, start_job):
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build = build_manager.make_build()
        build_context = {'start_time': arrow.get('2015-01-01')}
        if build.rule_dependency_graph.is_meta(start_job):
            build.add_meta(start_job, build_context)
        else:
            build.add_job(start_job, build_context)
        return build, build_context

    @testing.unit
    @mock_infrastructure('comcast2', config_only=True, exclude_dimensions=True)
    def test_backbone_5min(self):

        # Given
        build, build_context = self._make_deepy_build("cubes_5min")
        job = build.rule_dependency_graph.node['cube_backbone_small_5min']['object']


        # When
        job_states = job.expand(build, build_context)
        commands = map(lambda x: x.get_command(), job_states)

        # Then
        self.assertEquals(1, len(commands))
        command = commands[0]
        cachedir = deepy.cfg.cache_dir

        self.assertEquals("cube_op.py  -o {cachedir}/cubes/backbone_small/minutes/cube.2015-01-01-00-00.h5 -t 300 -A group_other(origin_asn.remote,null,<c.top_origins>) --arg_join c.top_origins='{cachedir}/cubes/bgp_origin_asn.local/months/top_list.2015-01.json.gz' -A group_other(origin_asn.local,null,<c.top_origins>)   -A group_other(aspaths.remote,null,<c.top_aspaths>) --arg_join c.top_aspaths='{cachedir}/cubes/aspaths.remote2/months/top_list.2015-01.json.gz' -A group_other(aspaths.local,null,<c.top_aspaths>) -A group_other(sites,null,<c.top_sites>) -A group_other(company,null,<c.top_companies>) --arg_join c.top_companies='{cachedir}/cubes/company2/months/top_list.2015-01.json.gz' --arg_join c.top_sites='{cachedir}/cubes/sites2/months/top_list.2015-01.json.gz' -O timestamp,path,origin_asn.local,origin_asn.remote,pops.local,pops.remote,peer.local,peer.remote,aspaths.local,aspaths.remote,market.local,market.remote,router.local,router.remote,interfaces.local,interfaces.remote,class.local,class.remote,category,cdn,sites,protocol,ip_version,service,dscp,application_port {cachedir}/cubes/backbone/minutes/cube.2015-01-01-00-00.h5".format(cachedir=cachedir), command)


    @testing.unit
    @mock_infrastructure('comcast2', config_only=True, exclude_dimensions=True)
    def test_drill_small_5min(self):

        # Given
        build, build_context = self._make_deepy_build('cube_drill_small_5min')
        job = build.rule_dependency_graph.node['cube_drill_small_5min']['object']

        # When
        job_states = job.expand(build, build_context)
        commands = map(lambda x: x.get_command(), job_states)

        # Then
        self.assertEquals(1, len(commands))


    @testing.unit
    @mock_infrastructure('comcast2', config_only=True, exclude_dimensions=True)
    def test_meta(self):

        # Given
        build, build_context = self._make_deepy_build('cubes_hour')

        # When
        job_states = []
        for node_id, node in build.node.iteritems():
            node_data = node['object']
            if isinstance(node_data, builder.jobs.Job):
                job_states.append(node_data)
        commands = map(lambda x: x.get_command(), job_states)

        # Then
        self.assertGreater(len(commands), 1)

    @testing.unit
    @mock_infrastructure('comcast2', config_only=True, exclude_dimensions=True)
    def test_flow(self):
        # Given
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build = build_manager.make_build()
        job = build.rule_dependency_graph.get_job_definition('h5flow')
        build_context = {'start_time': arrow.get('2015-01-01')}
        build.add_meta("cubes_5min", build_context)

        # Create dependencies
        for dep in build.rule_dependency_graph.get_dependency_ids('h5flow'):
            substituted_path = deepy.build.deepy_util.deepy_substitution(dep, deepy.cfg)
            substituted_path = build_context['start_time'].strftime(substituted_path)
            deepy.util.ensure_directory(os.path.dirname(substituted_path))
            with open(substituted_path, 'w') as f:
                f.write("foo")

        # Create target
        with open(build_context['start_time'].strftime(deepy.build.deepy_util.deepy_substitution('$(h5flow_dir)/flow.%Y-%m-%d-%H-%M.h5', deepy.cfg)), 'w') as f:
            f.write('foo')

        # When
        job_states = job.expand(build, build_context)
        job_state = job_states[0]

        # Then
        self.assertFalse(job_state.get_should_run_immediate())


    @testing.unit
    @mock_infrastructure('comcast2', config_only=True, exclude_dimensions=True)
    def test_cubes_from_h5flow_marker(self):
        # Given
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build = build_manager.make_build()
        job = build.rule_dependency_graph.get_job_definition('cubes_from_h5flow_5min')
        build_context = {'start_time': arrow.get('2015-01-01')}
        build.add_meta("cubes_5min", build_context)

        # When
        job_states = job.expand(build, build_context)
        commands = map(lambda x: x.get_command(), job_states)

        # Then
        self.assertEquals(commands[0], 'cubes_from_h5flow.py  -B -t 2015-01-01-00-00 -m {cubedir}/cubes_from_h5flow_markers/cubes_from_h5flow_5min/2015-01-01-00-00.marker'.format(cubedir=deepy.cfg.cubes_dir))

    @testing.unit
    def test_past_dns_flow(self):
        # Given
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build = build_manager.make_build()
        jobs = build.rule_dependency_graph.get_job_definition("classify_h5flow")
        build_context = {"start_time": arrow.get("2015-01-01"),
                         "end_time": arrow.get("2015-01-01")}

        # When
        build.add_job("classify_h5flow", build_context)
        jobs_states = jobs.expand(build, build_context)
        predecessors = build.predecessors(jobs_states[0].unique_id)
        ancestors = []
        for predecessor in predecessors:
            ancestors = ancestors + build.predecessors(predecessor)

        # Then
        self.assertEqual(len(ancestors), 5)

class ImpalaTimePartitionedTargetTest(unittest.TestCase):

    def _get_test_targets(self):
        targets = [
            deepy.build.deepy_targets.ImpalaTimePartitionedTarget('foo', 'foo-12-25-20', {'start_time': arrow.get('2014-01-01'), 'end_time': arrow.get('2014-01-02')}, 'foo', '1d')
        ]
        snakebite_client = mock.Mock()
        snakebite_client.ls = mock.Mock(return_value=[{
            'modification_time': 15000,
            'length': 50
        }])

        mock_table = mock.Mock()
        mock_table.location = "location"
        def mod_target(target):
            target._get_snakebite_client = mock.Mock(return_value=snakebite_client)
            target.get_tables = mock.Mock(return_value=[mock_table])
        map(mod_target, targets)
        return targets

    def test_get_bulk_exists_mtime(self):
        # Given
        targets = self._get_test_targets()

        # When
        results = deepy.build.deepy_targets.ImpalaTimePartitionedTarget.get_bulk_exists_mtime(targets)

        # Then
        self.assertEquals( results, {
            'foo-12-25-20': {
                'exists': True,
                'mtime': 15000
            }
        })

    def test_get_mtime(self):
        # Given
        target = self._get_test_targets()[0]

        # When
        mtime = target.get_mtime()

        # Then
        self.assertEquals(15000, mtime)

    def test_get_exists(self):
        # Given
        target = self._get_test_targets()[0]

        # When
        exists = target.get_exists()

        # Then
        self.assertEquals(True, exists)


class DeepyBuildManagerTest(unittest.TestCase):

    def test_construction(self):
        # Given
        build_manager = deepy.build.deepy_build.DeepyBuildManager()

        # Then
        build_manager.rule_dependency_graph.node["cube_drill_small_5min"]

    def test_add_job(self):
        # Given
        build_manager = deepy.build.deepy_build.DeepyBuildManager()
        build_context = {
            'start_time': arrow.get('2015-01-01-00-00'),
            'end_time': arrow.get('2015-01-01-00-10')
        }
        build = build_manager.make_build()

        # When
        build.add_job('cube_drill_small_5min', build_context)

        # Then
        self.assertIn('cube_drill_small_5min_2015-01-01-00-00-00', build.node)

class S3BackedLocalFileSystemTargetTest(unittest.TestCase):
    """Used to test specifically the local file system implemention of
    a target
    """
    @staticmethod
    def mock_s3_mtime_generator(file_dict):
        """Used to generate a fake os.stat

        takes in a list of files and returns a function that will return the
        mtime corresponding to the path passed to it
        """
        def mock_s3_mtime(path):
            """Returns the mtime corresponding to the path

            raises:
                OSError: if the path is not in the file_dict
            """
            path = path[0]
            if path not in file_dict:
                return {path: None}
            return {path: file_dict[path]}
        return mock_s3_mtime

    @staticmethod
    def mock_s3_bulk_mtime_generator(file_dict):
        """Used to generate a fake os.stat

        takes in a list of files and returns a function that will return the
        mtime corresponding to the path passed to it
        """
        def mock_bulk_mtime(paths, bulk=True):
            """Returns the mtime corresponding to the path

            raises:
                OSError: if the path is not in the file_dict
            """
            mtime_dict = {}
            for path in paths:
                for file in file_dict:
                    if file.startswith(path):
                        mtime_dict[file] = file_dict[file]
            return mtime_dict
        return mock_bulk_mtime

    @testing.unit
    def test_get_exists(self):
        # given
        path1 = "local_path/1"
        path2 = "local_path/2"
        path3 = "local_path/3"
        path4 = "local_path/4"

        local_mtimes = {
            path1: 1,
            path2: 2,
        }

        remote_mtimes = {
            path1: 3,
            path4: 4,
        }

        mock_local_mtime = (LocalFileSystemTargetTest
                .mock_mtime_generator(local_mtimes))

        mock_remote_mtime = (S3BackedLocalFileSystemTargetTest
                .mock_s3_mtime_generator(remote_mtimes))

        # when
        build_context = {}
        file1 = deepy_targets.S3BackedLocalFileSystemTarget(
                path1, path1, build_context)
        file2 = deepy_targets.S3BackedLocalFileSystemTarget(
                path2, path2, build_context)
        file3 = deepy_targets.S3BackedLocalFileSystemTarget(
                path3, path3, build_context)
        file4 = deepy_targets.S3BackedLocalFileSystemTarget(
                path4, path4, build_context)

        with mock.patch("os.stat", mock_local_mtime), \
                mock.patch("deepy.store.ls_files_remote", mock_remote_mtime):
            exists1 = file1.get_exists()
            exists2 = file2.get_exists()
            exists3 = file3.get_exists()
            exists4 = file4.get_exists()

        # then
        self.assertTrue(exists1)
        self.assertTrue(exists2)
        self.assertFalse(exists3)
        self.assertTrue(exists4)

    @testing.unit
    def test_get_mtime(self):
        # given
        path1 = "local_path/1"
        path2 = "local_path/2"
        path3 = "local_path/3"
        path4 = "local_path/4"

        local_mtimes = {
            path1: 1,
            path2: 2,
        }

        remote_mtimes = {
            path1: 3,
            path4: 4,
        }

        mock_local_mtime = (LocalFileSystemTargetTest
                .mock_mtime_generator(local_mtimes))

        mock_remote_mtime = (S3BackedLocalFileSystemTargetTest
                .mock_s3_mtime_generator(remote_mtimes))

        # when
        build_context = {}
        file1 = deepy_targets.S3BackedLocalFileSystemTarget(
                path1, path1, build_context)
        file2 = deepy_targets.S3BackedLocalFileSystemTarget(
                path2, path2, build_context)
        file3 = deepy_targets.S3BackedLocalFileSystemTarget(
                path3, path3, build_context)
        file4 = deepy_targets.S3BackedLocalFileSystemTarget(
                path4, path4, build_context)

        with mock.patch("os.stat", mock_local_mtime), \
                mock.patch("deepy.store.ls_files_remote", mock_remote_mtime):
            mtime1 = file1.get_mtime()
            mtime2 = file2.get_mtime()
            mtime3 = file3.get_mtime()
            mtime4 = file4.get_mtime()

        # then
        self.assertEqual(mtime1, 3)
        self.assertEqual(mtime2, 2)
        self.assertIsNone(mtime3)
        self.assertEqual(mtime4, 4)

    @testing.unit
    def test_get_bulk_exists_mtime(self):
        # given
        path1_file = "local_path/1"
        path1 = builder.targets.LocalFileSystemTarget(path1_file, path1_file,
                                                      {})
        path2_file = "local_path/2"
        path2 = builder.targets.LocalFileSystemTarget(path2_file, path2_file,
                                                      {})
        path3_file = "local_path/3"
        path3 = builder.targets.LocalFileSystemTarget(path3_file, path3_file,
                                                      {})
        path4_file = "local_path/4"
        path4 = builder.targets.LocalFileSystemTarget(path4_file, path4_file,
                                                      {})

        local_mtimes = {
            path1_file: 1,
            path2_file: 2,
        }

        remote_mtimes = {
            path1_file: 3,
            path4_file: 4,
        }

        mock_local_mtime = (LocalFileSystemTargetTest
                .mock_mtime_generator(local_mtimes))

        mock_remote_mtime = (S3BackedLocalFileSystemTargetTest
                .mock_s3_bulk_mtime_generator(remote_mtimes))

        # when
        build_context = {}
        file1 = deepy_targets.S3BackedLocalFileSystemTarget(
                path1_file, path1_file, build_context)

        mtime_fetcher = file1.get_bulk_exists_mtime

        with mock.patch("os.stat", mock_local_mtime), \
                mock.patch("deepy.store.ls_files_remote", mock_remote_mtime):
            mtimes_exists = mtime_fetcher([path1, path2, path3, path4])
            file1_exists = mtimes_exists[path1_file]["exists"]
            file2_exists = mtimes_exists[path2_file]["exists"]
            file3_exists = mtimes_exists[path3_file]["exists"]
            file4_exists = mtimes_exists[path4_file]["exists"]
            file1_mtime = mtimes_exists[path1_file]["mtime"]
            file2_mtime = mtimes_exists[path2_file]["mtime"]
            file3_mtime = mtimes_exists[path3_file]["mtime"]
            file4_mtime = mtimes_exists[path4_file]["mtime"]

        self.assertTrue(file1_exists)
        self.assertTrue(file2_exists)
        self.assertFalse(file3_exists)
        self.assertTrue(file4_exists)
        self.assertEqual(file1_mtime, 3)
        self.assertEqual(file2_mtime, 2)
        self.assertIsNone(file3_mtime)
        self.assertEqual(file4_mtime, 4)

class S3BackedGlobLocalFileSystemTargetTest(unittest.TestCase):
    """Used to test specifically the local file system implemention of
    a target
    """
    @testing.unit
    def test_get_exists(self):
        # given
        # exists on both remote and local
        glob1 = "local_path/1/*.gz"
        glob1_path1 = "local_path/1/1.gz"
        glob1_path2 = "local_path/1/2.gz"

        # exists on neither
        glob2 = "local_path/2/*.gz"

        # exists on remote only
        glob3 = "local_path/3/*.gz"
        glob3_path1 = "local_path/3/1.gz"
        glob3_path2 = "local_path/3/2.gz"

        # exists on local only
        glob4 = "local_path/4/*.gz"
        glob4_path1 = "local_path/4/1.gz"
        glob4_path2 = "local_path/4/2.gz"

        # tests pattern matching correctness
        glob5 = "local_path/*1/5*.gz"
        glob5_path1 = "local_path/151/515.gz"
        glob5_path2 = "local_path/251/525.gz"
        close_glob5_path1 = "local_path/15/25.gz"

        local_mtimes = {
            glob1_path1: 1,
            glob1_path2: 2,
            glob4_path1: 3,
            glob4_path2: 4,
        }

        remote_mtimes = {
            glob1_path1: 3,
            glob1_path2: 5,
            glob3_path1: 2,
            glob3_path2: 3,
            glob5_path1: 4,
            glob5_path2: 5,
            close_glob5_path1: 6,
        }

        mock_local_mtime = (LocalFileSystemTargetTest
                .mock_mtime_generator(local_mtimes))

        mock_remote_mtime = (S3BackedLocalFileSystemTargetTest
                .mock_s3_bulk_mtime_generator(remote_mtimes))

        mock_glob = (GlobLocalFileSystemTargetTest
                .mock_glob_list_generator(local_mtimes))

        # when
        build_context = {}

        glob_target1 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob1, glob1, build_context)
        glob_target2 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob2, glob2, build_context)
        glob_target3 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob3, glob3, build_context)
        glob_target4 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob4, glob4, build_context)
        glob_target5 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob5, glob5, build_context)

        with mock.patch("os.stat", mock_local_mtime), \
                mock.patch("deepy.store.list_files_remote", mock_remote_mtime), \
                mock.patch("glob.glob", mock_glob):
            exists1 = glob_target1.get_exists()
            exists2 = glob_target2.get_exists()
            exists3 = glob_target3.get_exists()
            exists4 = glob_target4.get_exists()
            exists5 = glob_target5.get_exists()

        self.assertTrue(exists1)
        self.assertFalse(exists2)
        self.assertTrue(exists3)
        self.assertTrue(exists4)
        self.assertTrue(exists5)

    @testing.unit
    def test_get_mtime(self):
        # given
        # exists on both remote and local
        glob1 = "local_path/1/*.gz"
        glob1_path1 = "local_path/1/1.gz"
        glob1_path2 = "local_path/1/2.gz"

        # exists on neither
        glob2 = "local_path/2/*.gz"

        # exists on remote only
        glob3 = "local_path/3/*.gz"
        glob3_path1 = "local_path/3/1.gz"
        glob3_path2 = "local_path/3/2.gz"

        # exists on local only
        glob4 = "local_path/4/*.gz"
        glob4_path1 = "local_path/4/1.gz"
        glob4_path2 = "local_path/4/2.gz"

        # tests pattern matching correctness
        glob5 = "local_path/*1/5*.gz"
        glob5_path1 = "local_path/151/515.gz"
        glob5_path2 = "local_path/251/525.gz"
        close_glob5_path1 = "local_path/15/25.gz"

        local_mtimes = {
            glob1_path1: 1,
            glob1_path2: 2,
            glob4_path1: 3,
            glob4_path2: 4,
        }

        remote_mtimes = {
            glob1_path1: 3,
            glob1_path2: 5,
            glob3_path1: 2,
            glob3_path2: 3,
            glob5_path1: 4,
            glob5_path2: 5,
            close_glob5_path1: 6,
        }

        mock_local_mtime = (LocalFileSystemTargetTest
                .mock_mtime_generator(local_mtimes))

        mock_remote_mtime = (S3BackedLocalFileSystemTargetTest
                .mock_s3_bulk_mtime_generator(remote_mtimes))

        mock_glob = (GlobLocalFileSystemTargetTest
                .mock_glob_list_generator(local_mtimes))

        build_context = {}

        # when
        glob_target1 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob1, glob1, build_context)
        glob_target2 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob2, glob2, build_context)
        glob_target3 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob3, glob3, build_context)
        glob_target4 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob4, glob4, build_context)
        glob_target5 = deepy_targets.S3BackedGlobLocalFileSystemTarget(
                glob5, glob5, build_context)

        with mock.patch("os.stat", mock_local_mtime), \
                mock.patch("deepy.store.list_files_remote", mock_remote_mtime), \
                mock.patch("glob.glob", mock_glob):
            mtime1 = glob_target1.get_mtime()
            mtime2 = glob_target2.get_mtime()
            mtime3 = glob_target3.get_mtime()
            mtime4 = glob_target4.get_mtime()
            mtime5 = glob_target5.get_mtime()

        self.assertEqual(mtime1, 5)
        self.assertIsNone(mtime2)
        self.assertEqual(mtime3, 3)
        self.assertEqual(mtime4, 4)
        self.assertEqual(mtime5, 5)

    @testing.unit
    def test_get_bulk_exists_mtime(self):
        # given
        # exists on both remote and local
        glob1_pattern = "local_path/1/*.gz"
        glob1 = builder.targets.GlobLocalFileSystemTarget(glob1_pattern,
                                                          glob1_pattern, {})
        glob1_path1 = "local_path/1/1.gz"
        glob1_path2 = "local_path/1/2.gz"

        # exists on neither
        glob2_pattern = "local_path/2/*.gz"
        glob2 = builder.targets.GlobLocalFileSystemTarget(glob2_pattern,
                                                          glob2_pattern, {})

        # exists on remote only
        glob3_pattern = "local_path/3/*.gz"
        glob3_path1 = "local_path/3/1.gz"
        glob3_path2 = "local_path/3/2.gz"
        glob3 = builder.targets.GlobLocalFileSystemTarget(glob3_pattern,
                                                          glob3_pattern, {})

        # exists on local only
        glob4_pattern = "local_path/4/*.gz"
        glob4_path1 = "local_path/4/1.gz"
        glob4_path2 = "local_path/4/2.gz"
        glob4 = builder.targets.GlobLocalFileSystemTarget(glob4_pattern,
                                                          glob4_pattern, {})

        # tests pattern matching correctness
        glob5_pattern = "local_path/*1/5*.gz"
        glob5_path1 = "local_path/151/515.gz"
        glob5_path2 = "local_path/251/525.gz"
        close_glob5_path1 = "local_path/15/25.gz"
        glob5 = builder.targets.GlobLocalFileSystemTarget(glob5_pattern,
                                                          glob5_pattern, {})

        local_mtimes = {
            glob1_path1: 1,
            glob1_path2: 2,
            glob4_path1: 3,
            glob4_path2: 4,
        }

        remote_mtimes = {
            glob1_path1: 3,
            glob1_path2: 5,
            glob3_path1: 2,
            glob3_path2: 3,
            glob5_path1: 4,
            glob5_path2: 5,
            close_glob5_path1: 6,
        }

        mock_mtime = (LocalFileSystemTargetTest
                .mock_mtime_generator(local_mtimes))

        mock_glob = (GlobLocalFileSystemTargetTest
                .mock_glob_list_generator(local_mtimes))

        mock_remote_mtime = (S3BackedLocalFileSystemTargetTest
                .mock_s3_bulk_mtime_generator(remote_mtimes))

        build_context = {}

        glob_target1 = (deepy_targets.S3BackedGlobLocalFileSystemTarget(
                        glob1_pattern, glob1_pattern, build_context))

        mtime_fetcher = glob_target1.get_bulk_exists_mtime

        with mock.patch("os.stat", mock_mtime), \
                mock.patch("deepy.store.list_files_remote",
                        mock_remote_mtime), \
                mock.patch("glob.glob", mock_glob):
                mtimes_exists = mtime_fetcher([glob1, glob2, glob3,
                        glob4, glob5])
                glob1_exists = mtimes_exists[glob1_pattern]["exists"]
                glob2_exists = mtimes_exists[glob2_pattern]["exists"]
                glob3_exists = mtimes_exists[glob3_pattern]["exists"]
                glob4_exists = mtimes_exists[glob4_pattern]["exists"]
                glob5_exists = mtimes_exists[glob5_pattern]["exists"]
                glob1_mtime = mtimes_exists[glob1_pattern]["mtime"]
                glob2_mtime = mtimes_exists[glob2_pattern]["mtime"]
                glob3_mtime = mtimes_exists[glob3_pattern]["mtime"]
                glob4_mtime = mtimes_exists[glob4_pattern]["mtime"]
                glob5_mtime = mtimes_exists[glob5_pattern]["mtime"]

        self.assertTrue(glob1_exists)
        self.assertFalse(glob2_exists)
        self.assertTrue(glob3_exists)
        self.assertTrue(glob4_exists)
        self.assertTrue(glob5_exists)
        self.assertEqual(glob1_mtime, 5)
        self.assertIsNone(glob2_mtime)
        self.assertEqual(glob3_mtime, 3)
        self.assertEqual(glob4_mtime, 4)
        self.assertEqual(glob5_mtime, 5)



class CeleryExecutorTest(unittest.TestCase):
    def _get_execution_manager_with_effects(self, jobs):
        build_manager = BuildManager(jobs, metas=[])
        execution_manager = ExecutionManager(build_manager, ExtendedMockExecutor)
        return execution_manager

    def test_do_execute(self):

        # Given
        deepy_execution.app.conf.CELERY_ALWAYS_EAGER = True
        jobs = [EffectJobDefinition("A", command="true")]
        execution_manager = self._get_execution_manager_with_effects(jobs)
        execution_manager.executor = deepy_execution.CeleryExecutor(execution_manager)
        execution_manager.running = True
        execution_manager.submit("A", {})
        executor = execution_manager.executor
        executor.pool = mock.Mock()
        mock_future = concurrent.futures.Future()
        mock_future.set_result(("A", ExecutionResult(True, True, '', '')))

        executor.pool.submit = mock.Mock(return_value=mock_future)

        # When
        future_result = execution_manager.executor.execute(execution_manager.get_build().get_job("A"))
        job_id, result = future_result.result()

        # Then
        self.assertTrue(result.status)
        self.assertEquals(result.stdout, '')


class JobsDaemonExecutorTest(unittest.TestCase):
    def _get_execution_manager_with_effects(self, jobs):
        build_manager = DeepyBuildManager(jobs, metas=[])
        execution_manager = ExecutionManager(build_manager, deepy_execution.JobsDaemonExecutor, config=build_manager.config)
        execution_manager.executor
        return execution_manager

    def test_submit_async_job(self):

        # Given
        jobs = [EffectJobDefinition("A", command="true")]
        execution_manager = self._get_execution_manager_with_effects(jobs)
        execution_manager.running = True
        execution_manager.submit("A", {})
        executor = execution_manager.executor
        executor.pool = mock.Mock()
        mock_future = concurrent.futures.Future()
        mock_future.set_result(("A", ExecutionResult(True, True, '', '')))

        executor.pool.submit = mock.Mock(return_value=mock_future)

        # When
        future_result = execution_manager.executor.execute(execution_manager.get_build().get_job("A"))
        job_id, result = future_result.result()

        # Then
        self.assertTrue(result.status)
        self.assertEquals(result.stdout, '')
