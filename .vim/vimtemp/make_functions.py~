import copy

import deepy.cfg
import deepy.log as log
import deepy.multi_tenancy

SLICE_INCLUDE = 'include'
SLICE_EXCLUDE = 'exclude'

def is_exclude_slice(s): return s['type'] == SLICE_EXCLUDE
def is_include_slice(s): return s['type'] == SLICE_INCLUDE

# XXX OVERRIDES PYTHON BUILT-IN FIX THIS XXX
def slice(d, vs, keypath=None):
    return {'type': SLICE_INCLUDE, 'dimension': d, 'key_path': keypath, 'values': vs}

# Added this to avoid adding more references to the above slice()..
def include_slice(d, vs, keypath=None):
    return slice(d, vs, keypath=keypath)

def exclude_slice(d, vs, keypath=None):
    return {'type': SLICE_EXCLUDE, 'dimension': d, 'key_path': keypath, 'values': vs}

def query(name=None, dimensions=None, slices=None, applies=None,
          input_file_glob=None, target=None, required_measures=None,
          sum_all=False, timestep=None, use_bundle_rollup=False,
          arg_joins=None, get_fields=None):

    # create new dictionaries
    required_measures = None if required_measures is None else copy.deepcopy(required_measures)
    slices = None if slices is None else copy.deepcopy(slices)
    applies = None if applies is None else copy.deepcopy(applies)
    dimensions = None if dimensions is None else copy.deepcopy(dimensions)
    arg_joins = None if arg_joins is None else copy.deepcopy(arg_joins)
    get_fields = None if get_fields is None else copy.deepcopy(get_fields)

    q = {'required_measures': required_measures, 'slices': slices,
         'dimensions': dimensions, 'applies': applies, 'arg_joins': arg_joins}

    if input_file_glob: q['input_file_glob'] = input_file_glob
    if name: q['name'] = name
    if target: q['target'] = target
    if sum_all: q['sum_all'] = sum_all
    if timestep: q['timestep'] = timestep
    if use_bundle_rollup: q['use_bundle_rollup'] = use_bundle_rollup
    if get_fields: q['get_fields'] = get_fields

    if sum_all:
        # dimensions must be None or filled with sum_all
        # apparently ... FIXME?
        assert dimensions != []

    return q

def turnOffLocal(rule):
    rule['local_only'] = False
    return rule

def cube(recipe=None, target=None, time_step=None, depends=None,
         cube_id=None, dimensions=None, local_only=False):

    depends = {} if depends is None else copy.deepcopy(depends)

    c = {
        'depends': depends,
        'time_step': time_step,
        'target': target,
        'recipe': [recipe],
        'meta': {'cube_id': cube_id}
    }

    if dimensions:
        c['dimensions'] = copy.deepcopy(dimensions)

    if local_only:
        c['local_only'] = True

    return c

def bundle(recipe=None, queries=None, recipes=None, target=None, time_step=None, depends={}, depends_one_or_more={}, format_args=None):

    queries = None if queries is None else copy.deepcopy(queries)
    depends = None if depends is None else copy.deepcopy(depends)
    depends_one_or_more = None if depends_one_or_more is None else copy.deepcopy(depends_one_or_more)

    # FIXME checks etc
    b = {'depends': depends,
         'depends_one_or_more': depends_one_or_more,
         'queries': queries,
         'time_step': time_step,
         'prune_ratio': 500,
         'file_step': 'month',
         'target': target,
         'recipe': [recipe],
         'type': 'bundle'}

    if format_args:
        b['format_args'] = format_args

    return b

def make_bundle(name, bundle_func, rules):
    rules[name] = bundle_func()

def modify_bundle(name, rules, bundle_func):
    if name not in rules:
        # For testing, don't die on missing standard dimensions.
        # This should never happen on a deployment.
        return
    b = rules[name]
    r = bundle_func(b)
    if r is not None:
        rules[name] = r

def bundle_query(cubes):
    pass
#    b = rules[name]
#    r = bundle_func(b)
#    if r is not None:
#        rules[name] = r

def get_queries(query_names, bundle):
    return [bundle.get(qn) for qn in query_names]

def allow_infrastructure_cdn(bundle):
    for name, query in bundle['queries'].items():
        slices = query.get('slices', [])
        if not slices:
            continue
        new_slices = []
        for s in slices:
            if is_exclude_slice(s) and (
               'akamai_edgecache' in s['values'] or
               'infrastructure' in s['values']):
                # these are slices that exclude infrastructure/cdn
                pass
            else:
                new_slices.append(s)
        query['slices'] = new_slices

def remove_sub_counts(bundle):
    removals = []
    for name, query in bundle['queries'].items():
        if 'sub_count' in name:
            removals.append(name)
    for name in removals:
        del bundle['queries'][name]

    removals = []
    pd = bundle.get('prerequisites_dict')
    if pd:
        for name, _ in pd.items():
            if 'sub_count' in name:
                removals.append(name)
        for name in removals:
            del bundle['prerequisites_dict'][name]

def remove_all_sub_counts(rules):
    sub_dims = ['cdn', 'ip_version', 'service', 'sites']

    sub_bundles =['drill_day_{}',
                  'drill_day_{}_summary',
                  'drill_month_{}',
                  'drill_month_{}_summary',
                  'drill_{}',
                  'drill_{}_summary']

    for dim in sub_dims:
        for bformat in sub_bundles:
            bname = bformat.format(dim)
            modify_bundle(bname, rules, remove_sub_counts)

    modify_bundle('bundle2_backbone1_summary', rules, remove_sub_counts)

################################################################################
# applies
################################################################################

def convert_to_names(*args):
    return {'args': args, 'fn': 'convert_to_names'}

def time_dist(*args):
    return {'args': args, 'fn': 'time_dist'}

def sort(*args):
    return {'args': args, 'fn': 'sort'}

def measure_fixup(*args):
    return {'args': args, 'fn': 'measure_fixup'}

def add_prereq(bundle, key, value_list):
    bundle[key] = bundle.get(key, []) + value_list

def get_partition_dimensions():
    slice_json = deepy.cfg.slice_config
    # Assuming partition dimensions are dim_ids.
    if slice_json.get("use_multi_tenancy"):
        dimensions = deepy.multi_tenancy.get_partition_dimensions()
    else:
        dimensions = []
    log.debug('partition-dimensions %s' % (dimensions))
    return dimensions

def set_query_timestep(queries, timestep):
    for q in queries:
        q['timestep'] = timestep

def set_query_bundle_rollup(queries, val=True):
    for q in queries:
        q['use_bundle_rollup'] = val

################################################################################
# custom
################################################################################

def drill_tata(rules, dim_top, peer_remote):
    '''
    Show tata traffic grouped into on/off-net
    dim_top is local tata dimension
    '''
    template = deepy.build.deepy_util.MakeruleTemplateStandardDrill()
    dim_tops, dim_drills = template.get_dim_tops(), template.get_dim_drills()

    bundles = deepy.standard_drill_rules.make_drill_bundles(dim_top, dim_drills, drillname='tata')
    rules.update(bundles)

    dashqueries = rules['dashboard']['queries']
    deepy.standard_drill_rules.add_dashboard_query(dashqueries, dim_top, 'tata')

    queries = bundles['drill_day_tata_summary']['queries'].items()
    queries += bundles['drill_day_tata']['queries'].items()
    for name, q in queries:
        # leave summary alone, comparing tata to it for total perspective
        if name.startswith('list') or name.startswith('dash'):
            _slices = q.get('slices')
            if not _slices:
                _slices = []
            slices = [x for x in _slices] # copy so slices are shared
            slices.append(slice('peer.remote', peer_remote))
            #slices.append(exclude_slice('origin_asn.remote', [6453]))
            q['slices'] = slices

def groupby_tata(pos_id_in, pos_in):
    '''
    creates a dimension via, replace <did>:
    ./connectors/shared/groupby_attribute.py -d <did> -i origin_asn -a asn -o tata -m lib/deepy/make_functions.py:groupby_tata
    '''
    if pos_in['asn'] in [6453, 6421]:
        pos_name_out = 'tata-onnet'
    else:
        pos_name_out = 'tata-offnet'
    return pos_name_out

def drill_peer_remote_external(rules, name='peer.remote'):
    '''
    peer.remote external peers only for peer analysis tile
    '''
    template = deepy.build.deepy_util.MakeruleTemplateStandardDrill()
    _dim_tops, dim_drills = template.get_dim_tops(), template.get_dim_drills()

    dim_top = 'peer.remote'
    bundles = deepy.standard_drill_rules.make_drill_bundles(dim_top, dim_drills, drillname=name)
    rules.update(bundles)

    dashqueries = rules['dashboard']['queries']
    deepy.standard_drill_rules.add_dashboard_query(dashqueries, dim_top)

    # only modify day bundles (source for month)
    bundle_name = 'drill_day_{}'.format(name)
    bundle_name_summary = bundle_name + '_summary'
    queries = bundles[bundle_name]['queries'].items()
    queries += bundles[bundle_name_summary]['queries'].items()

    exclude_peer_internal = exclude_slice(dim_top, [True], keypath='peer.is_internal_peer')

    for name, q in queries:
        _slices = q.get('slices')
        if not _slices:
            _slices = []
        slices = [x for x in _slices] # copy so slices are shared
        slices.append(exclude_peer_internal)
        q['slices'] = slices

def slice_out_partition_members(rules):
    member_slices = deepy.multi_tenancy.get_partition_dimension_positions()
    mem_slices = {dim: slice(dim, vals) for dim, vals in member_slices.items()}

    for name, rule in rules.items():
        for dim, mem_slice in mem_slices.items():
            if (rule.get('make_time_step') == 'month') \
                                        and ('_part_' + dim in name):
                for qname, query in rule['queries'].items():
                    _slices = query.get('slices')
                    if not _slices:
                        _slices = []
                    slices = [x for x in _slices] # copy so slices are shared
                    slices.append(mem_slice)
                    query['slices'] = slices

def sub_count(rules, dimensions, step, add=True, slices=None):
    '''
    Convenience function to make simple sub count cubes.

    dimensions: list of dimensions in the cube
    step: 5min, 1h, 1d
    add: add to meta cube so it gets built by default

    Note: 1d do not get built by default even if add=True because they're added to a new
    target 'sub_count_day'. Add this target to cron_jobs to build the day sub count cubes.
    '''
    cd = ",".join(dimensions)
    ud = "_".join(dimensions)
    sd = ''
    slices_arg = ''
    if slices:
        sd = '_{}'.format('_'.join(map(lambda x: x.split('=')[-1], slices)))
        slices_arg = ' '.join(map('-S {}'.format, slices))

    cube_id = 'sub_count_{}{}'.format(ud, sd)

    if step == '5min':
        depends = "depends"
        recipe = "flow_op.py -D {} {} -t %Y-%m-%d-%H-%M -o $(cubes_dir)/{}/minutes/cube.%Y-%m-%d-%H-%M.h5".format(cd, slices_arg, cube_id)
        target = "$(cubes_dir)/{}/minutes/cube.%Y-%m-%d-%H-%M.h5".format(cube_id)
        prereq = 'cubes_5min'
        step_name = '5min'
    elif step == '1h':
        depends = "depends_one_or_more"
        recipe = "flow_op.py -D {} {} -t %Y-%m-%d-%H-55 -r 12 -o $(cubes_dir)/{}/hours/cube.%Y-%m-%d-%H.h5".format(cd, slices_arg, cube_id)
        target = "$(cubes_dir)/{}/hours/cube.%Y-%m-%d-%H.h5".format(cube_id)
        prereq = 'cubes_hour'
        step_name = 'hour'
    elif step == '1d':
        depends = "depends_one_or_more"
        recipe = "flow_op.py -D {} {} -t %Y-%m-%d-23-55 -r 288 -o $(cubes_dir)/{}/days/cube.%Y-%m-%d.h5".format(cd, slices_arg, cube_id)
        target = "$(cubes_dir)/{}/days/cube.%Y-%m-%d.h5".format(cube_id)
        prereq = 'sub_count_day'
        if 'sub_count_day' not in rules.keys():
            rules['sub_count_day'] = {
                    "__comment": [
                        "intended to run daily just before midnight"
                    ],
                    "depends": {}
                }
        step_name = 'day'
    else:
        raise ValueError('invalid sub count rule step')

    local_only = not deepy.util.vm_or_slice_config_get("archive_h5flow")

    r = {
        "meta": {
            "cube_id": cube_id
        },
        depends: {
            "classify_h5flow": "5min"
        },
        "local_only": local_only,
        "recipe": [ recipe ],
        "time_step": step,
        'prune_ratio': 500,
        "file_step": step,
        "target": target
    }

    name = "cube_{}_{}".format(cube_id, step_name)
    rules[name] = r

    if add:
        rules[prereq]['depends'][name] = step
    else:
        r['ignore_missing'] = True

