import os, re, gzip
import time
import funcy

import deepy.store

import deepy.cfg, deepy.util, deepy.validators
import deepy.log as log
import deepy.cube
import base
import pandas
import tornado.web
import cube_api
import deepy.build.deepy_util
from deepy.ui_celery.async_decorator import make_async
from deepy.make_functions import get_partition_dimensions

import tornado.gen

try: import ujson
except ImportError: import json as ujson

DASH_BOARD = 'dashboard.json.gz'
SUMMARY = 'summary.json.gz'

class BundleApiHandler(base.ApiHandler):
    # for now, path is just something under bundles dir. like a static file handler.
    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, path=''):
        self.set_header("Content-Type", "application/json; charset=UTF-8")
        result = yield bundle_api_handler(path, self.get_effective_user(), self.get_partition())
        params = self.get_argument_list_dict()
        injectors = params.get('i') or params.get('injectors')
        if injectors:
            injectors = injectors.split(',')
        run_bundle_applies(result, injectors)
        self.write_json(result, compress=True, allow_nan=False)

@tornado.gen.coroutine
def bundle_api_handler(path, effective_user, partition):

    result = {}

    try:
        b2path, is_dash = convert_to_bundle2(path)
        # Let's continue the hacks... backbone tile get's it's
        # data from timeseries file not dashboard, so is_dash doesn't work
        is_dash = is_dash and ("backbone" not in b2path)
        result = yield bundle2_handler(b2path, is_dash, effective_user, partition)

        if 'error' in result or not result['data']:
            # hack to rename
            if 'drill_router.local' in path:
                path = path.replace('drill_router.local', 'router.local')

            result = bundle1_handler(path)
    except KeyError:
        result = bundle1_handler(path)

    raise tornado.gen.Return(result)
    return

class Bundle2ApiHandler(base.ApiHandler):
    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, path=''):
        self.set_header("Content-Type", "application/json; charset=UTF-8")
        result = yield bundle2_handler(path)
        params = self.get_argument_list_dict()
        injectors = params.get('i') or params.get('injectors')
        if injectors:
            injectors = injectors.split(',')
        run_bundle_applies(result, injectors)
        self.write_json(result, compress=True, allow_nan=False)

def bundle1_handler(path):
    local_path = os.path.join(deepy.cfg.bundles_dir, path)
    deepy.store.cache_load_from_remote(local_path)

    error = None
    if not os.path.isfile(local_path):
        error = {"error": "bundle not found: %s" % (local_path)}
        local_path = local_path.replace(DASH_BOARD, SUMMARY)

    if error and not os.path.isfile(local_path):
        return error

    # XXX This is a security hole. Not checking that local_path is a
    # proper subdir (could contain ../../../ etc.)
    return ujson.load(gzip.open(local_path))

def convert_to_bundle2(path):
    result = ""
    is_dash = False
    if path.endswith(SUMMARY) or path.endswith(DASH_BOARD):
        # /drill_cdn1/months/2013-08/summary.json.gz to
        # /bundle2_drill_cdn1_summary/2013-08/summary
        bundle_rule_name, unused, timestamp, filename = path.split('/')

        result = "bundle2_%s_summary/%s/summary" % (bundle_rule_name, timestamp)
        if filename == DASH_BOARD:
            is_dash = True
    else:
        # /drill_cdn1/months/2013-08/bundle.15.json.gz to
        # /bundle2_drill_cdn1/2013-08/15
        bundle_rule_name, unused, timestamp, name = path.split('/')

        # bundle.10.json.gz --> 10
        try:
            unused, slice_val, unused, unused = name.split('.')
        except ValueError:
            # handle summary_external.json.gz
            return "", False
        result = "bundle2_%s/%s/%s" % (bundle_rule_name, timestamp, slice_val)

    return result, is_dash

# $(bundles2_dir)/drill_sites1/months/%Y-%m/ to
# .../bundles2/drill_sites1/months/2013-08/
def substitute_format_string(fmt_str, timestamp):
    # Replace $() variables
    try:
        var_sub = re.match(r'\$\(([^)]+)\)', fmt_str).group()
        var_dir = getattr(deepy.cfg, var_sub.strip("$()"))
        fmt_str = fmt_str.replace(var_sub, var_dir)
    except AttributeError:
        # Contains no $() variables, continue
        pass

    # Replace timestamps
    dt = pandas.to_datetime(timestamp)
    result = dt.strftime(fmt_str)

    return result

def get_email_address_info(email_addr):
    regex = re.compile(r"(?P<name>[^@]+)@(?P<domain>[^@]+)\.(?P<tld>[^@]+)")
    match = regex.match(email_addr)
    return (match.group("name"), match.group("domain"), match.group("tld"))

def optimize_measures(key, local_path):
    required_measures = \
    [
        "avg.recv.bps",
        "avg.sent.bps",
        "avg.total.bps",
        "max.recv.bps",
        "max.sent.bps",
        "max.total.bps"
    ]
    if "timeseries" not in key:
        required_measures += \
        [
            "pctl.recv.bps.95",
            "pctl.sent.bps.95",
            "pctl.total.bps.95"
        ]
    if "sub_count" in key:
        required_measures = \
        [
            "avg.local_host_count",
            "max.local_host_count",
        ]
        if "month.sub_count" in key:
            required_measures += \
            [
                "pctl.local_host_count.95"
            ]
    if "drill_peer.remote1" in local_path:
        required_measures = None

    if "drill_router.local" in local_path:
        return None

    return required_measures

@tornado.gen.coroutine
def run_bundle_applies(bundle, applies):
    if not applies:
        return
    applies = set(applies)
    apply_classes = deepy.cube_apply.ApplyBaseDataInjector.__subclasses__()
    for apply_class in apply_classes:
        if apply_class.apply_name in applies:
            apply_instance = apply_class([], {}, None)
            apply_instance.apply_bundle(bundle)


@tornado.gen.coroutine
def bundle2_handler(path, is_dash=False, current_user='', partition={}):
    # path should be of the format 'bundle_rule_name/timestamp/value'
    # e.g. /api/bundle2/bundle2_drill_cdn1/2013-07/10 or
    # /api/bundle2/bundle2_drill_cdn1_summary/2013-07/summary for summaries
    try:
        bundle_rule_name, timestamp, slice_value = path.split('/')
    except ValueError:
        raise tornado.gen.Return({"error": "too many arguments passed: %s" % (path)})

    if len(path.split('/')) > 3:
        # Shouldn't be an issue anymore with new rule format, but this prevents
        # accessing unintended files e.g. ../../../file.json
        raise tornado.gen.Return({"error": "bad query: %s" % (path)})

    rules = deepy.build.deepy_util.construct_rules()
    try:
        rule = rules[bundle_rule_name]
    except KeyError:
        raise tornado.gen.Return({"error": "bundle makefile rule not found: %s" % (bundle_rule_name)})

    try:
        location = rule["format_args"]["location"]
    except KeyError as e:
        raise tornado.gen.Return({"error": "%s not found in bundle rule: %s" % (e, bundle_rule_name)})

    if slice_value != "summary":
        try:
            dimension_name = rule["format_args"]["dim_top"]
        except KeyError as e:
            raise tornado.gen.Return({"error": "%s not found in bundle rule: %s" % (e, bundle_rule_name)})

    # Multi-tenancy stuff
    name, domain, tld = get_email_address_info(current_user)
    slice_json = deepy.cfg.slice_config
    use_multi_tenancy = slice_json.get("use_multi_tenancy") and partition.get('slices')
    if use_multi_tenancy:
        multi_slices = partition['slices']
        location = location.replace("$(bundles2_dir)", "$(bundles2_partition_dir)")

    # Requires strip() because (putting this here because it took me a while to find this bug):
    # -- "If any component is an absolute path, all previous components are thrown away,
    # -- and joining continues."
    location = substitute_format_string(location, timestamp).rstrip('/')

    loc_glob = os.path.join(location, '*.h5')
    local_paths = deepy.store.ls_glob_simple(loc_glob)

    result = {}
    result["meta_data"] = {"version": 3}
    result["data"] = {}
    if slice_value == "summary":
        slice_defs = []
    else:
        slice_defs = \
        [
            {
                "dimension": dimension_name,
                "type": "include",
                "values": [int(slice_value)]
            }
        ]
    if use_multi_tenancy:
        for dimension, slice_value in multi_slices.iteritems():
            slice_defs.append(\
                {
                    "dimension": dimension,
                    "type": "include",
                    "values": [slice_value]
                }
            )

    qd = {"slices": slice_defs}
    ddb = deepy.dimensions.DimensionsDB(None, redis_backed=True)
    cq = deepy.cube.CubeQuery(qd, ddb=ddb)

    for local_path in local_paths:
        # /this/is/a/path/this.is.a.file.h5 --> this.is.a.file
        key, ext = os.path.splitext(os.path.basename(local_path))

        # Skip all non-dashboard when requesting the dashboard
        if is_dash and not key.startswith('dashboard'):
            continue

        # NOTE This does not work well with the new cube contexts (input/output, ingress/egress).
        # We'll need to come up with a separate solution; probably examine the bundle and set as needed.
        #required_measures = optimize_measures(key, local_path)
        #if required_measures:
        #    cq.set_required_measures(required_measures)

        try:
            query_cube = yield make_async(deepy.cube.cube_map_queries, [cq],
                cube_files=[local_path],
                dimensions_db=None)
            if len(query_cube) < 1:
                log.info('drill-reports-query-error:')
                log.info('bad-file:')
                log.info(local_path)
                log.info(cq.query_dict)
                continue
            query, cube = query_cube[0]
        except (IndexError, KeyError, deepy.cube.QueryError) as e:
            log.info('query-error %s' % (e))
            continue
        result["data"][key] = cube.get_dict()

        drill_cubes = ('drill_small', 'interface', 'backbone_small',
                       'datacenter')
        for cube_name, url in cube.get_meta().get('urls', []):
            # HACK! FIXME make list of allowed drillable cubes
            if (cube_name and
                (cube_name in drill_cubes or
                 cube_name.startswith('sub_count'))):
                result['meta_data'][query.name] = {'cube': cube_name, 'url':url}
                break

    raise tornado.gen.Return(result)


class BGPBoundaryHandler(base.TileHandler):
    template = 'templates/bgp_boundary.html'
    template_args = {"title": "BGP Boundary"}


class NetworkHandler(base.TileHandler):
    template = 'templates/network.html'
    template_args = {"title": "Network"}


class DrillHandler(base.TileHandler):
    template = None # Override for special case drill.
    template_args = {"title": "Drill"}

    def get(self, *path_args, **path_kwargs):
        # Normalize path args and pass to template.
        drill_base = path_args[0]
        drill_args = path_args[1].strip('/').split('/')
        drill_args = [x for x in drill_args if x != '']
        self.template_args['drill_href_base'] = base.json_encode(drill_base)
        self.template_args['drill_args_json'] = base.json_encode(drill_args)

        if self.template is None:
            l = len(drill_args)
            if l == 1 or l == 3:
                # list page
                self.template = 'templates/drill_default_list.html'
            elif l == 2:
                # dash page
                self.template = 'templates/drill_default_dash.html'
            else:
                # TEMP catch all -- should redirect to query perhaps
                self.template = 'templates/drill_default_dash.html'

        return super(DrillHandler, self).get(*path_args, **path_kwargs)


class PeerDrillHandler(DrillHandler):
    template = 'templates/drill_peer_dash.html'
    template_args = {"title": "Peer"}

class DataExplorerHandler(base.TileHandler):
    template = 'templates/data_explorer.html'
    template_args = {"title": "Data Explorer"}


#In order to pickle this function as a celery argument we need it at the top level of the file
#   eventually refactor to only pass data through celery and we can move this back into setup_partition_slices
#   which is definetly cleaner
def updater(query):
    query['target'] = query['target'].replace("$(bundles2_dir)", "$(bundles2_partition_dir)")

class Bundle2aApiHandler(base.ApiHandler):

    required_permissions = ['cube_api']

#    def match_time_range(self, s):
#        match = cube_api.CubeApiUtil.slice_time_stmt.match(s)
#        if match:
#            try:
#                return cube_api.CubeApiUtil._cons_time_slice_def(s, match)
#            except ValueError as ex:
#                self.api_error(ex.message, 'Invalid time format.')
#                return ex

    def post(self, *args, **kwargs):
        raise tornado.web.HTTPError(405)

    def setup_partition_slices(self):
        partition = self.get_partition()
        use_multi_tenancy = deepy.cfg.slice_config.get("use_multi_tenancy")
        multi_slices = partition.get('slices')

        slice_defs = []
        updater_func = None
        if use_multi_tenancy and multi_slices:
            for dimension, slice_value in multi_slices.iteritems():
                 slice_defs.append( {"dimension": dimension,
                                     "type": "include",
                                     "values": [slice_value] })
            updater_func = updater

        return slice_defs, updater_func

    def get_timestep(self, params):
        # only supports one apply timestep
        a = params.get('a') or params.get('apply')
        if a:
            timestep = a[a.find('(')+1:a.find(')')]
            return timestep

    @tornado.gen.coroutine
    def bundle2a(self, kwargs):
        info = self.parse_url_args(kwargs)
        if not info:
            return
        path, dimension, is_summary, is_drill, timestep, timeslices, non_time_slices, subquery, measures, injectors = info
        pslices, part_loc_updater = self.setup_partition_slices()

        # is partitioned
        part = ''
        if pslices:
            # XXX Only support one slice per user for now
            part = '_part_' + pslices[0]['dimension']

        if is_drill:
            # FIXME normalize bundle names?
            src_bundle_id = 'drill_'
            if timestep == 'day' or timestep == 'days':
                pass
            elif timestep == 'month' or timestep == 'months':
                src_bundle_id += 'month_'
            else:
                assert False

            src_bundle_id += dimension
            src_bundle_id += part

            if is_summary:
                src_bundle_id += '_summary'
        else:
            src_bundle_id = dimension
            src_bundle_id += part

        log.info(src_bundle_id)

        #The caching function will populate the dim_db if there is a cache miss
        out = yield make_async(deepy.cube.bundle_query, src_bundle_id, timeslices,
                non_time_slices + pslices, None,
                partition_query_updates=part_loc_updater, subquery=subquery,
                include_measures=measures)
        out['2a'] = True
        raise tornado.gen.Return(out)
        return

    def fixup_dash(self, _data):
        delete_keys = []
        replace = {'dash.month': 'summary', 'dash.timeseries': 'timeseries'}
        for key, val in _data.items():
            repl = replace.get(key)
            if repl:
                delete_keys.append(key)
                _data[repl] = val
        for dk in delete_keys:
            del _data[dk]

    def fixup(self, _data):
        delete_keys = []
        for key, val in _data.items():
            for rkey in 'month list timeseries.dim timeseries'.split():
                if key.startswith(rkey + '.'):
                    # month -> summary
                    _k = 'summary' if rkey == 'month' else rkey
                    _data[_k] = val
                    delete_keys.append(key)
                    break
        for dk in delete_keys:
            del _data[dk]

    def set_error(self, name, msg):
        self.error = name, msg

    @tornado.gen.coroutine
    def bundle2(self, kwargs):
        info = self.parse_url_args(kwargs)
        if not info:
            return
        path, dim, is_summary, is_drill, timestep, timeslices, non_time_slices, subquery, measures, injectors = info

        # take the first timeslice for now
        ts = list(timeslices[0]['values'])[0]
        t = time.strftime('%Y-%m', time.gmtime(ts))
        pos = None

        if 'backbone1' in self.request.uri:
            # /api/bundle/backbone1/months/2014-01/summary.json.gz
            p = 'backbone1/months/{}/summary.json.gz'.format(t)

        elif 'h5backbone' in self.request.uri:
            # /api/bundle/h5backbone/months/2014-01/summary.json.gz
            p = 'h5backbone/months/{}/summary.json.gz'.format(t)

        elif dim == 'dashboard':
            # /api/bundle/drill_aspaths.remote1/months/2014-01/dashboard.json.gz
            p = 'drill_{}1/months/{}/dashboard.json.gz'.format(dim, t)

        # /bundle/drill/summary/cdn.json?slice=timestamp(2013-11-01:2013-11-05)&a=timestep(day)
        elif is_summary:
            # /api/bundle/drill_service1/months/2014-01/summary.json.gz
            p = 'drill_{}1/months/{}/summary.json.gz'.format(dim, t)

        # /bundle/drill/summary/cdn.json?slice=timestamp(2013-11)&a=timestep(day)&slice=cdn(1222)
        elif is_drill:
            if non_time_slices:
                pos = list(non_time_slices[0]['values'])[0]
            # /api/bundle/drill_service1/months/2014-01/bundle.1222.json.gz
            p = 'drill_{}1/months/{}/bundle.{}.json.gz'.format(dim, t, pos)

        else:
            return

        result = yield bundle_api_handler(p, self.get_effective_user(), self.get_partition())
        if result and 'error' not in result:
            data = result['data']
            meta_data = result['meta_data']
            if is_summary:
                self.fixup(data)
                self.fixup(meta_data)
            elif is_drill:
                self.fixup_dash(data)
                self.fixup_dash(meta_data)
        raise tornado.gen.Return(result)

    def parse_url_args(self, kwargs):
        # args
        path = kwargs.get('path', '')
        dimension = kwargs['source_bundle']
        resp_format = kwargs['format'] if kwargs['format'] else 'json'

        # FIXME hack cloud -> service
        dimension = 'service' if dimension == 'cloud' else dimension
        dimension = 'sys.market.local' if dimension == 'market.local' or dimension == 'member.local' else dimension

        is_summary = bool(kwargs.get('summary'))
        is_drill = bool(kwargs.get('drill'))

        # convert to bundle1 type path
        params = self.get_argument_list_dict()
        timestep = self.get_timestep(params)

        if resp_format != 'json':
            self.set_error('InvalidFormat', 'Invalid output format, use json.')
            return

        slices = params.get('slice', []) or params.get('s', [])
        if type(slices) != type([]):
            slices = [slices]
        eslices, error = cube_api.extract_slice_defs(slices)
        if error:
            self.set_error(error[0], error[1])
            return

        # copied from cube_api.py
        measures = params['m'] if 'm' in params else params['measures'] if 'measures' in params else None
        measures = funcy.distinct(measures.split(',')) if measures is not None else None

        timeslices, non_time_slices, slice_defs = eslices

        if not slice_defs:
            self.set_error('InvalidSlice', 'Bad slice')
            return

        subquery = params.get('query', [])
        if subquery:
            subquery = subquery.split(',')

        injectors = params.get('i') or params.get('injectors')
        if injectors:
            injectors = injectors.split(',')

        return path, dimension, is_summary, is_drill, timestep, timeslices, non_time_slices, subquery, measures, injectors

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, *args, **kwargs):
        self.error = None
        log.info("bundle-request-started")
        result = yield self.bundle2a(kwargs)

        if self.error:
            name, msg = self.error
            self.api_error(name, msg)
            return

        if not result or not result.get('data'):
            log.info('BUNDLE <2> START')
            try:
                result = yield self.bundle2(kwargs)
            except Exception as e:
                log.error('bundle2-exception {}'.format(str(e)))

        if self.error:
            name, msg = self.error
            self.api_error(name, msg)
            return

        info = self.parse_url_args(kwargs)
        if info:
            path, dim, is_summary, is_drill, timestep, timeslices, non_time_slices, subquery, measures, injectors = info
            run_bundle_applies(result, injectors)

        log.info("bundle-request-finished")

        self.set_header("Content-Type", "application/json; charset=UTF-8")
        self.write_json(result, compress=True, allow_nan=False)

class BundleListHandler(base.ApiHandler):

    required_permissions = ['cube_api']

    def post(self, *args, **kwargs):
        raise tornado.web.HTTPError(405)

    def get(self, *args, **kwargs):
        self.set_header("Content-Type", "application/json; charset=UTF-8")
        rules = deepy.build.deepy_util.construct_rules()
        bundles = [k for k,v in rules.items() if v.get('type') == 'bundle']
        self.write_json(bundles, compress=True, indent=2)

class DataIndexHandler(base.ApiHandler):

    required_permissions = ['cube_api']

    def post(self, *args, **kwargs):
        raise tornado.web.HTTPError(405)

    # XXX
    def update_name(self, name):
        for good, bad in [('service', 'cloud'),
                          ('sys.market.local', 'market.local'),
                          ('sys.market.local', 'member'),
                          ('_router.local_', '_router_')]:
            if bad in name:
                return name.replace(bad, good)
        return name

    def get(self, *args, **kwargs):
        self.set_header("Content-Type", "application/json; charset=UTF-8")
        src_data = kwargs['source_data']
        index = deepy.store.simple_load_json(deepy.cfg.data_index, force_remote='s3')
        if not index:
            index = {}

        # FIXME hack cloud -> service
        src_data = self.update_name(src_data)

        res = index.get(src_data, {})
        self.write_json(res, compress=True, indent=2)

class BundleDataIndexHandler(base.ApiHandler):

    required_permissions = ['cube_api']

    def post(self, *args, **kwargs):
        raise tornado.web.HTTPError(405)

    # XXX
    def update_name(self, name):
        for good, bad in [('service', 'cloud'),
                          ('sys.market.local', 'market.local'),
                          ('sys.market.local', 'member'),
                          ('_router.local_', '_router_'),
                          ('aspaths.remote', 'aspaths_remote')]:
            if bad in name:
                return name.replace(bad, good)
        return name

    def get(self, *args, **kwargs):
        self.set_header("Content-Type", "application/json; charset=UTF-8")
        src_data = kwargs['source_data']
        index = deepy.store.simple_load_json(deepy.cfg.data_index, force_remote='s3')
        if not index:
            index = {}

        # FIXME hack cloud -> service
        src_data = self.update_name(src_data)

        # XXX I don't think this does what the author indended... or I don't
        # understand
        part = ''
        if get_partition_dimensions():
            part = '_part'
        bundle_name = 'drill_day_{}{}_summary'.format(src_data, part)

        res = index.get(bundle_name, {})
        self.write_json(res, compress=True, indent=2)

class ASNDashboardHandler(base.TileHandler):
    template = "templates/asn_dash.html"
    template_args = {"title": "ASN Evaluation BETA"}

class ASNDrillHandler(base.TileHandler):
    template = "templates/asn_detail.html"
    template_args = {"title": "ASN Detail BETA"}

    def get(self, *path_args, **path_kwargs):
        self.template_args['asn_id'] = path_kwargs["asn_id"]
        return super(ASNDrillHandler, self).get(*path_args, **path_kwargs)
